[
{
	"uri": "//localhost:1313/vi/5-workshop/5.1-workshop-overview/",
	"title": "Tổng quan Workshop",
	"tags": [],
	"description": "",
	"content": "Tổng quan Nền tảng InsightHR InsightHR là một nền tảng tự động hóa HR serverless toàn diện, minh họa phát triển ứng dụng cloud-native hiện đại trên AWS. Workshop này sẽ hướng dẫn bạn xây dựng một ứng dụng sẵn sàng production từ đầu.\nPhạm vi Dự án Nền tảng InsightHR cung cấp:\nHệ thống Quản lý Nhân viên: Các thao tác CRUD hoàn chỉnh cho hồ sơ nhân viên với bộ lọc nâng cao theo phòng ban, vị trí và trạng thái Theo dõi Hiệu suất: Điểm hiệu suất theo quý với tính toán tự động dựa trên KPI, nhiệm vụ hoàn thành và phản hồi 360 độ Quản lý Chấm công: Hệ thống check-in/check-out thời gian thực với theo dõi lịch sử và giám sát trạng thái Chatbot hỗ trợ AI: Giao diện truy vấn ngôn ngữ tự nhiên sử dụng AWS Bedrock (Claude 3 Haiku) cho thông tin dữ liệu thông minh Dashboard Phân tích: Trực quan hóa tương tác với biểu đồ, bảng và khả năng xuất dữ liệu Kiểm soát Truy cập Dựa trên Vai trò: Hệ thống truy cập ba cấp (Admin, Manager, Employee) với lọc dữ liệu phù hợp Xác thực Bảo mật: Tích hợp Email/password và Google OAuth qua AWS Cognito Tổng quan Kiến trúc ┌─────────────────────────────────────────────────────────────────┐\r│ User Browser │\r└────────────────────────┬────────────────────────────────────────┘\r│\r▼\r┌─────────────────────────────────────────────────────────────────┐\r│ CloudFront CDN │\r│ Custom Domain: insight-hr.io.vn │\r└────────────────────────┬────────────────────────────────────────┘\r│\r▼\r┌─────────────────────────────────────────────────────────────────┐\r│ S3 Static Website │\r│ React SPA (Vite + TypeScript) │\r└─────────────────────────────────────────────────────────────────┘\r│\r▼\r┌─────────────────────────────────────────────────────────────────┐\r│ API Gateway (REST) │\r│ Cognito Authorizer │\r└────────────────────────┬────────────────────────────────────────┘\r│\r┌───────────────┼───────────────┐\r▼ ▼ ▼\r┌─────────────┐ ┌─────────────┐ ┌─────────────┐\r│ Lambda │ │ Lambda │ │ Lambda │\r│ Auth │ │ Employees │ │ Chatbot │\r└──────┬───────┘ └──────┬───────┘ └──────┬───────┘\r│ │ │\r▼ ▼ ▼\r┌─────────────────────────────────────────────────────────────────┐\r│ DynamoDB │\r│ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ │\r│ │ Users │ │Employees │ │ Scores │ │Attendance│ │\r│ └──────────┘ └──────────┘ └──────────┘ └──────────┘ │\r└─────────────────────────────────────────────────────────────────┘\r│\r▼\r┌─────────────────────────────────────────────────────────────────┐\r│ AWS Bedrock │\r│ (Claude 3 Haiku Model) │\r└─────────────────────────────────────────────────────────────────┘ Stack Công nghệ Frontend:\nReact 18 với TypeScript Vite 7.2 (công cụ build) Tailwind CSS 3.4 (theme Frutiger Aero) Zustand 5.0 (quản lý state) React Hook Form + Zod (validation form) Recharts 3.4 (trực quan hóa dữ liệu) Backend:\nPython 3.11 (Lambda runtime) AWS Lambda (serverless compute) AWS API Gateway (REST API) AWS DynamoDB (NoSQL database) AWS Cognito (authentication) AWS Bedrock (AI/ML) Infrastructure:\nAWS S3 (static hosting) AWS CloudFront (CDN) AWS Route53 (DNS) AWS CloudWatch (monitoring) AWS IAM (security) Tính năng Chính 1. Kiến trúc Serverless Hoàn toàn Không có EC2 instances cần quản lý Tự động scaling dựa trên nhu cầu Mô hình giá pay-per-use High availability tích hợp sẵn 2. Stack Phát triển Hiện đại TypeScript cho type safety React cho UI responsive Python cho logic backend Nguyên tắc Infrastructure as Code 3. Sẵn sàng Production Custom domain với SSL Giám sát CloudWatch Synthetic canaries cho testing Kiểm soát truy cập dựa trên vai trò 4. Tiết kiệm Chi phí DynamoDB on-demand pricing Lambda free tier eligible Chi phí hàng tháng tối thiểu (~$2-5) Không có phí tài nguyên idle Cấu trúc Workshop Workshop này được chia thành 11 modules:\nTổng quan Workshop (Hiện tại) - Hiểu phạm vi dự án Yêu cầu tiên quyết - Thiết lập môi trường của bạn Kiến trúc Dự án - Tìm hiểu sâu về thiết kế hệ thống Thiết lập Môi trường AWS - Cấu hình tài khoản AWS và credentials Thiết lập Database - Tạo và điền dữ liệu vào bảng DynamoDB Dịch vụ Xác thực - Triển khai Cognito và auth Lambda functions Dịch vụ Backend - Xây dựng employee, performance và chatbot APIs Phát triển Frontend - Tạo ứng dụng React Triển khai - Deploy lên S3 và CloudFront Kiểm thử \u0026amp; Giám sát - Thiết lập CloudWatch và canaries Dọn dẹp - Xóa tài nguyên để tránh phí Mục tiêu Học tập Sau khi hoàn thành workshop này, bạn sẽ có thể:\nThiết kế và triển khai kiến trúc serverless trên AWS Xây dựng RESTful APIs sử dụng Lambda và API Gateway Mô hình hóa dữ liệu hiệu quả trong DynamoDB Triển khai xác thực với AWS Cognito Tích hợp khả năng AI sử dụng AWS Bedrock Deploy static websites với S3 và CloudFront Giám sát ứng dụng với CloudWatch Áp dụng các phương pháp bảo mật tốt nhất với IAM Tối ưu hóa chi phí cho ứng dụng serverless Kiểm tra Yêu cầu tiên quyết Trước khi tiếp tục, đảm bảo bạn có:\n✅ Tài khoản AWS với quyền admin ✅ AWS CLI đã cài đặt và cấu hình ✅ Node.js 18+ và npm đã cài đặt ✅ Python 3.11+ đã cài đặt ✅ Hiểu biết cơ bản về React và TypeScript ✅ Quen thuộc với REST APIs ✅ Text editor hoặc IDE (khuyến nghị VS Code) Ước tính Chi phí Chạy workshop này sẽ phát sinh chi phí tối thiểu:\nDịch vụ Ước tính Chi phí DynamoDB $0.50/tháng Lambda Free tier S3 + CloudFront $1-2/tháng API Gateway $0.10/tháng Bedrock $0.0004/truy vấn Tổng cộng $2-5/tháng Nhớ hoàn thành module dọn dẹp ở cuối để tránh phí tiếp tục.\nBước tiếp theo Sẵn sàng bắt đầu? Hãy chuyển đến phần Yêu cầu tiên quyết để thiết lập môi trường phát triển của bạn.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Đỗ Đăng Khoa\nSố điện thoại: 0783759971\nEmail: khoado7577@gmail.com\nTrường: Đại Học FPT\nNgành: Kỹ thuật phần mềm/ Thiết kế vi mạch\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Xây dựng các ứng dụng RAG hiệu quả về chi phí với Knowledge Bases của Amazon Bedrock và Amazon S3 Vectors bởi Vaibhav Sabharwal, Ashish Lal, Dani Mitchell, và Irene Marban\nvào ngày 17 THÁNG 7 NĂM 2025\ntrong Amazon Bedrock, Amazon Bedrock Knowledge Bases, Amazon Machine Learning, Trí tuệ nhân tạo\nNhúng véc-tơ (vector embeddings) đã trở nên thiết yếu cho các ứng dụng Sinh dữ liệu tăng cường truy xuất (RAG) hiện đại, nhưng các tổ chức phải đối mặt với những thách thức đáng kể về chi phí khi mở rộng quy mô. Khi các cơ sở tri thức phát triển và yêu cầu các nhúng chi tiết hơn, nhiều cơ sở dữ liệu véc-tơ dựa trên lưu trữ hiệu suất cao như SSD hoặc giải pháp trong bộ nhớ trở nên đắt đỏ đến mức không thể chi trả. Rào cản chi phí này thường buộc các tổ chức phải giới hạn phạm vi của các ứng dụng RAG của họ hoặc thỏa hiệp về mức độ chi tiết của các biểu diễn véc-tơ, có khả năng ảnh hưởng đến chất lượng kết quả. Ngoài ra, đối với các trường hợp sử dụng liên quan đến dữ liệu lịch sử hoặc lưu trữ vẫn cần có thể tìm kiếm được, việc lưu trữ véc-tơ trong các cơ sở dữ liệu véc-tơ chuyên dụng được tối ưu hóa cho khối lượng công việc thông lượng cao là một khoản chi phí liên tục không cần thiết.\nBắt đầu từ ngày 15 tháng 7, khách hàng của Amazon Bedrock Knowledge Bases có thể chọn Amazon S3 Vectors (bản xem trước), dịch vụ lưu trữ đối tượng đám mây đầu tiên có hỗ trợ tích hợp để lưu trữ và truy vấn véc-tơ với chi phí thấp, làm kho lưu trữ véc-tơ. Người dùng Amazon Bedrock Knowledge Bases giờ đây có thể giảm chi phí tải lên, lưu trữ và truy vấn véc-tơ lên đến 90%. Được thiết kế để lưu trữ bền vững và tối ưu hóa chi phí cho các bộ dữ liệu véc-tơ lớn với hiệu suất truy vấn dưới một giây, S3 Vectors là lựa chọn lý tưởng cho các ứng dụng RAG yêu cầu lưu trữ dài hạn khối lượng véc-tơ khổng lồ và có thể chấp nhận sự đánh đổi về hiệu suất so với các cơ sở dữ liệu véc-tơ có số truy vấn mỗi giây (QPS) cao và độ trễ mili giây. Việc tích hợp với Amazon Bedrock có nghĩa là bạn có thể xây dựng các ứng dụng RAG tiết kiệm hơn trong khi vẫn duy trì hiệu suất tìm kiếm ngữ nghĩa cần thiết cho kết quả chất lượng.\nTrong bài đăng này, chúng tôi trình bày cách tích hợp Amazon S3 Vectors với Amazon Bedrock Knowledge Bases cho các ứng dụng RAG. Bạn sẽ học được một phương pháp thực tế để mở rộng quy mô cơ sở tri thức của mình để xử lý hàng triệu tài liệu trong khi vẫn duy trì chất lượng truy xuất và sử dụng bộ lưu trữ hiệu quả về chi phí của S3 Vectors.\nTổng quan về tích hợp Amazon Bedrock Knowledge Bases và Amazon S3 Vectors Khi tạo một knowledge base trong Amazon Bedrock, bạn có thể chọn S3 Vectors làm tùy chọn lưu trữ véc-tơ của mình. Sử dụng phương pháp này, bạn có thể xây dựng các ứng dụng RAG có thể mở rộng, hiệu quả về chi phí mà không cần cấp phép hoặc quản lý cơ sở hạ tầng phức tạp. Việc tích hợp mang lại sự tiết kiệm chi phí đáng kể trong khi vẫn duy trì hiệu suất truy vấn dưới một giây, làm cho nó trở nên lý tưởng để làm việc với các bộ dữ liệu véc-tơ lớn hơn được tạo ra từ khối lượng lớn dữ liệu phi cấu trúc bao gồm văn bản, hình ảnh, âm thanh và video. Sử dụng mô hình định giá trả theo mức sử dụng với các mức giá thấp, S3 Vectors cung cấp khả năng tối ưu hóa chi phí hàng đầu trong ngành, giúp giảm chi phí tải lên, lưu trữ và truy vấn véc-tơ lên đến 90% so với các giải pháp thay thế. Các khả năng tìm kiếm nâng cao bao gồm lọc siêu dữ liệu phong phú, vì vậy bạn có thể tinh chỉnh các truy vấn theo thuộc tính tài liệu như ngày tháng, danh mục và nguồn. Sự kết hợp giữa S3 Vectors và Amazon Bedrock là lý tưởng cho các tổ chức xây dựng các cơ sở tri thức quy mô lớn đòi hỏi cả hiệu quả chi phí và khả năng truy xuất hiệu quả—từ việc quản lý các kho tài liệu mở rộng đến các kho lưu trữ lịch sử và các ứng dụng yêu cầu biểu diễn véc-tơ chi tiết. Hướng dẫn này bao gồm các bước cấp cao sau:\nTạo một knowledge base mới Cấu hình nguồn dữ liệu Cấu hình nguồn dữ liệu và xử lý Đồng bộ hóa nguồn dữ liệu Kiểm tra knowledge base Điều kiện tiên quyết Trước khi bắt đầu, hãy đảm bảo rằng bạn có các điều kiện tiên quyết sau:\nMột tài khoản AWS có quyền truy cập dịch vụ phù hợp. Một vai trò AWS Identity and Access Management (IAM) với các quyền phù hợp để truy cập Amazon Bedrock và Amazon Simple Storage Service (Amazon S3). Bật quyền truy cập mô hình cho các mô hình nhúng và suy luận như Amazon Titan Text Embeddings V2 và Amazon Nova Pro. Hướng dẫn tích hợp Amazon Bedrock Knowledge Bases và Amazon S3 Vectors Trong phần này, chúng tôi sẽ hướng dẫn quy trình từng bước để tạo một knowledge base với Amazon S3 Vectors bằng cách sử dụng Bảng điều khiển quản lý AWS. Chúng tôi sẽ bao quát toàn bộ quy trình từ việc cấu hình kho lưu trữ véc-tơ đến việc nhập tài liệu và kiểm tra khả năng truy xuất của bạn.\nĐối với những người thích cấu hình knowledge base của họ theo chương trình thay vì sử dụng bảng điều khiển, kho lưu trữ Amazon Bedrock Knowledge Bases with S3 Vectors trên GitHub cung cấp một sổ tay hướng dẫn mà bạn có thể làm theo để triển khai thiết lập trong tài khoản của riêng mình.\nTạo một knowledge base mới Để tạo một knowledge base mới, hãy làm theo các bước sau:\nTrên bảng điều khiển Amazon Bedrock trong ngăn điều hướng bên trái, chọn Knowledge Bases. Để bắt đầu quá trình tạo, trong danh sách thả xuống Create, chọn Knowledge Base with vector store. Trên trang Provide Knowledge Base details, nhập tên mô tả cho knowledge base của bạn và một mô tả tùy chọn để xác định mục đích của nó. Chọn phương pháp cấp quyền IAM của bạn—tạo một vai trò dịch vụ mới hoặc sử dụng một vai trò hiện có—để cấp các quyền cần thiết để truy cập các dịch vụ AWS, như được hiển thị trong ảnh chụp màn hình sau. ![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-1.jpeg)\nChọn Amazon S3. Tùy chọn, thêm các thẻ để giúp tổ chức và phân loại tài nguyên của bạn và cấu hình các đích đến để gửi nhật ký như một bucket S3 hoặc Amazon CloudWatch để theo dõi và khắc phục sự cố. Chọn Next để tiếp tục đến phần cấu hình nguồn dữ liệu. Cấu hình nguồn dữ liệu Để cấu hình nguồn dữ liệu, hãy làm theo các bước sau:\nGán một tên mô tả cho dữ liệu knowledge base của bạn. Trong Data source location, chọn xem bucket S3 tồn tại trong tài khoản AWS hiện tại của bạn hay một tài khoản khác, sau đó chỉ định vị trí lưu trữ tài liệu của bạn, như được hiển thị trong ảnh chụp màn hình sau. ![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-2.png)\nTrong bước này, hãy cấu hình chiến lược phân tích cú pháp của bạn để xác định cách Amazon Bedrock xử lý tài liệu của bạn. Chọn Amazon Bedrock default parser cho các tài liệu chỉ có văn bản mà không mất thêm chi phí. Chọn Amazon Bedrock Data Automation as parser or Foundation models as a parser để xử lý các tài liệu phức tạp có các yếu tố trực quan.\nCấu hình chiến lược phân đoạn cũng quan trọng không kém vì nó xác định cách nội dung của bạn được phân đoạn thành các đơn vị có ý nghĩa để nhúng véc-tơ, ảnh hưởng trực tiếp đến chất lượng truy xuất và bảo toàn ngữ cảnh. Chúng tôi đã chọn Fixed-size chunking cho ví dụ này do kích thước token có thể dự đoán và sự đơn giản của nó. Vì cả quyết định phân tích cú pháp và phân đoạn đều không thể sửa đổi sau khi tạo, hãy chọn các tùy chọn phù hợp nhất với cấu trúc nội dung và nhu cầu truy xuất của bạn. Đối với dữ liệu nhạy cảm, bạn có thể sử dụng cài đặt nâng cao để triển khai mã hóa AWS Key Management Service (AWS KMS) hoặc áp dụng các hàm chuyển đổi tùy chỉnh để tối ưu hóa tài liệu của bạn trước khi nhập. Theo mặc định, S3 Vectors sẽ sử dụng mã hóa phía máy chủ (SSE-S3).\nCấu hình lưu trữ và xử lý dữ liệu Để cấu hình lưu trữ và xử lý dữ liệu, trước tiên hãy chọn mô hình nhúng, như được hiển thị trong ảnh chụp màn hình sau. Mô hình nhúng sẽ chuyển đổi các đoạn văn bản của bạn thành các biểu diễn véc-tơ số cho khả năng tìm kiếm ngữ nghĩa. Nếu kết nối với một S3 Vector hiện có làm kho lưu trữ véc-tơ, hãy đảm bảo rằng kích thước của mô hình nhúng khớp với kích thước được sử dụng khi tạo kho lưu trữ véc-tơ của bạn vì sự không khớp về kích thước sẽ gây ra lỗi nhập. Amazon Bedrock cung cấp một số mô hình nhúng để lựa chọn, mỗi mô hình có các kích thước véc-tơ và đặc điểm hiệu suất khác nhau được tối ưu hóa cho các trường hợp sử dụng khác nhau. Hãy xem xét cả sự phong phú về ngữ nghĩa của mô hình và các tác động về chi phí của nó khi đưa ra lựa chọn của bạn.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-3.jpeg)\nTiếp theo, cấu hình kho lưu trữ véc-tơ. Đối với việc lựa chọn lưu trữ véc-tơ, hãy chọn cách Amazon Bedrock Knowledge Bases sẽ lưu trữ và quản lý các nhúng véc-tơ được tạo từ tài liệu của bạn trong Amazon S3 Vectors, bằng một trong hai tùy chọn sau:\nTùy chọn 1. Nhanh chóng tạo một kho lưu trữ véc-tơ mới Tùy chọn được khuyến nghị này, được hiển thị trong ảnh chụp màn hình sau, tự động tạo một bucket S3 vector trong tài khoản của bạn trong quá trình tạo knowledge base. Hệ thống sẽ tối ưu hóa việc lưu trữ véc-tơ của bạn để lưu trữ các bộ dữ liệu véc-tơ quy mô lớn một cách bền vững và hiệu quả về chi phí, tạo ra một bucket S3 vector và một chỉ mục véc-tơ cho bạn.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-4.png)\nTùy chọn 2. Sử dụng một kho lưu trữ véc-tơ hiện có Khi tạo chỉ mục Amazon S3 Vector làm kho lưu trữ véc-tơ để sử dụng với Amazon Bedrock Knowledge Bases, bạn có thể đính kèm siêu dữ liệu (chẳng hạn như năm, tác giả, thể loại và vị trí) dưới dạng các cặp khóa-giá trị cho mỗi véc-tơ. Theo mặc định, các trường siêu dữ liệu có thể được sử dụng làm bộ lọc trong các truy vấn tương tự trừ khi được chỉ định là siêu dữ liệu không thể lọc tại thời điểm tạo chỉ mục véc-tơ. Các chỉ mục S3 Vector hỗ trợ các loại chuỗi, số và Boolean lên đến 40 KB mỗi véc-tơ, với siêu dữ liệu có thể lọc được giới hạn ở mức 2 KB mỗi véc-tơ.\nĐể chứa các đoạn văn bản lớn hơn và siêu dữ liệu phong phú hơn trong khi vẫn cho phép lọc trên các thuộc tính quan trọng khác, hãy thêm \u0026ldquo;AMAZON_BEDROCK_TEXT\u0026rdquo; vào danh sách nonFilterableMetadataKeys trong cấu hình chỉ mục của bạn. Phương pháp này tối ưu hóa việc phân bổ bộ nhớ của bạn cho nội dung tài liệu trong khi vẫn duy trì khả năng lọc cho các thuộc tính có ý nghĩa như danh mục hoặc ngày tháng. Hãy nhớ rằng các trường được thêm vào mảng nonFilterableMetadataKeys không thể được sử dụng với tính năng lọc siêu dữ liệu trong các truy vấn và không thể sửa đổi sau khi chỉ mục được tạo.\nĐây là một ví dụ về việc tạo một chỉ mục Amazon S3 Vector với cấu hình siêu dữ liệu phù hợp:\ncode CSS\ndownloadcontent_copy\nexpand_less\ns3vectors.create_index(\nvectorBucketName=\u0026ldquo;my-first-vector-bucket\u0026rdquo;,\nindexName=\u0026ldquo;my-first-vector-index\u0026rdquo;,\ndimension=1024,\ndistanceMetric=\u0026ldquo;cosine\u0026rdquo;,\ndataType=\u0026ldquo;float32\u0026rdquo;, metadataConfiguration={\u0026ldquo;nonFilterableMetadataKeys\u0026rdquo;: [\u0026ldquo;AMAZON_BEDROCK_TEXT\u0026rdquo;]}\n)\nĐể biết chi tiết về cách tạo kho lưu trữ véc-tơ, hãy tham khảo Giới thiệu Amazon S3 Vectors trong Blog Tin tức của AWS.\nSau khi bạn có một bucket và chỉ mục S3 Vector, bạn có thể kết nối nó với knowledge base của mình. Bạn sẽ cần cung cấp cả Tên tài nguyên Amazon (ARN) của bucket S3 Vector và ARN của chỉ mục véc-tơ, như được hiển thị trong ảnh chụp màn hình sau, để liên kết chính xác knowledge base của bạn với chỉ mục S3 Vector hiện có.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-5.jpeg)\nĐồng bộ hóa nguồn dữ liệu Sau khi bạn đã cấu hình knowledge base của mình với S3 Vectors, bạn cần đồng bộ hóa nguồn dữ liệu của mình để tạo và lưu trữ các nhúng véc-tơ. Từ bảng điều khiển Amazon Bedrock Knowledge Bases, hãy mở knowledge base đã tạo của bạn và tìm nguồn dữ liệu đã cấu hình của bạn và chọn Sync để bắt đầu quá trình, như được hiển thị trong ảnh chụp màn hình sau. Trong quá trình đồng bộ hóa, hệ thống sẽ xử lý tài liệu của bạn theo cấu hình phân tích cú pháp và phân đoạn của bạn, tạo các nhúng bằng mô hình bạn đã chọn và lưu trữ chúng trong chỉ mục S3 vector của bạn. Bạn có thể theo dõi tiến trình đồng bộ hóa trong thời gian thực nếu bạn đã cấu hình Nhật ký Amazon CloudWatch và xác minh trạng thái hoàn thành trước khi kiểm tra khả năng truy xuất của knowledge base.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-6.jpeg)\nKiểm tra knowledge base Sau khi cấu hình thành công knowledge base của bạn với S3 Vectors, bạn có thể xác thực chức năng của nó bằng giao diện kiểm tra tích hợp. Bạn có thể sử dụng bảng điều khiển tương tác này để thử nghiệm với các loại truy vấn khác nhau và xem cả kết quả truy xuất và các phản hồi được tạo ra. Chọn giữa chế độ Chỉ truy xuất (API Retrieve) để kiểm tra các đoạn nguồn thô hoặc Truy xuất và tạo phản hồi (API RetrieveandGenerate) để tìm hiểu cách các mô hình nền tảng (FM) như Amazon Nova sử dụng nội dung được truy xuất của bạn. Giao diện kiểm tra cung cấp những hiểu biết có giá trị về cách knowledge base của bạn xử lý các truy vấn, hiển thị các đoạn nguồn, điểm liên quan của chúng và siêu dữ liệu liên quan.\nBạn cũng có thể cấu hình cài đặt truy vấn cho knowledge base của mình giống như với các tùy chọn lưu trữ véc-tơ khác, bao gồm các bộ lọc để lựa chọn dựa trên siêu dữ liệu, các rào cản để có phản hồi phù hợp, khả năng xếp hạng lại và các tùy chọn sửa đổi truy vấn. Những công cụ này giúp tối ưu hóa chất lượng truy xuất và đảm bảo thông tin phù hợp nhất được trình bày cho các FM của bạn. S3 Vectors hiện hỗ trợ chức năng tìm kiếm ngữ nghĩa. Sử dụng việc xác thực thực hành này, bạn có thể tinh chỉnh cấu hình của mình trước khi tích hợp knowledge base với các ứng dụng sản xuất.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-7.jpeg)\nTạo knowledge base Amazon Bedrock của bạn theo chương trình Trong các phần trước, chúng tôi đã hướng dẫn cách tạo một knowledge base với Amazon S3 Vectors bằng Bảng điều khiển quản lý AWS. Đối với những người thích tự động hóa quy trình này hoặc tích hợp nó vào các quy trình làm việc hiện có, bạn cũng có thể tạo knowledge base của mình theo chương trình bằng cách sử dụng AWS SDK.\nSau đây là một đoạn mã mẫu cho thấy lệnh gọi API trông như thế nào khi tạo một knowledge base Amazon Bedrock theo chương trình với một chỉ mục Amazon S3 Vector hiện có:\ncode CSS\ndownloadcontent_copy\nexpand_less\nresponse = bedrock.create_knowledge_base(\ndescription=\u0026lsquo;Amazon Bedrock Knowledge Base integrated with Amazon S3 Vectors\u0026rsquo;,\nknowledgeBaseConfiguration={\n\u0026rsquo;type\u0026rsquo;: \u0026lsquo;VECTOR\u0026rsquo;,\n\u0026lsquo;vectorKnowledgeBaseConfiguration\u0026rsquo;: {\n\u0026rsquo;embeddingModelArn\u0026rsquo;: f\u0026rsquo;arn:aws:bedrock:{region}::foundation-model/amazon.titan-embed-text-v2:0\u0026rsquo;,\n\u0026rsquo;embeddingModelConfiguration\u0026rsquo;: {\n\u0026lsquo;bedrockEmbeddingModelConfiguration\u0026rsquo;: {\n\u0026lsquo;dimensions\u0026rsquo;: vector_dimension, #Verify this is the same value as S3 vector index configuration\n\u0026rsquo;embeddingDataType\u0026rsquo;: \u0026lsquo;FLOAT32\u0026rsquo;\n}\n},\n},\n},\nname=knowledge_base_name,\nroleArn=roleArn,\nstorageConfiguration={\n\u0026lsquo;s3VectorsConfiguration\u0026rsquo;: {\n\u0026lsquo;indexArn\u0026rsquo;: vector_index_arn\n},\n\u0026rsquo;type\u0026rsquo;: \u0026lsquo;S3_VECTORS\u0026rsquo;\n}\n)\nVai trò được gắn với knowledge base nên có một số chính sách được đính kèm, bao gồm quyền truy cập vào API S3 Vectors, các mô hình được sử dụng để nhúng, tạo và xếp hạng lại (nếu được sử dụng), và bucket S3 được sử dụng làm nguồn dữ liệu. Nếu bạn đang sử dụng khóa do khách hàng quản lý cho S3 Vector làm kho lưu trữ véc-tơ, bạn sẽ cần cung cấp một chính sách bổ sung để cho phép giải mã dữ liệu. Sau đây là chính sách cần thiết để truy cập Amazon S3 Vector làm kho lưu trữ véc-tơ:\ncode Code\ndownloadcontent_copy\nexpand_less\n{\n\u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;,\n\u0026ldquo;Statement\u0026rdquo;: [\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;BedrockInvokeModelPermission\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;bedrock:InvokeModel\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: [\n\u0026ldquo;arn:aws:bedrock:{REGION}::foundation-model/amazon.titan-embed-text-v2:0\u0026rdquo;\n]\n},\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;KmsPermission\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;kms:GenerateDataKey\u0026rdquo;,\n\u0026ldquo;kms:Decrypt\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: [\n\u0026ldquo;arn:aws:kms:{REGION}:{ACCOUNT_ID}:key/{KMS_KEY_ID}\u0026rdquo;\n]\n},\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;S3ListBucketPermission\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;s3:ListBucket\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: [\n\u0026ldquo;arn:aws:s3:::{SOURCE_BUCKET_NAME}\u0026rdquo;\n],\n\u0026ldquo;Condition\u0026rdquo;: {\n\u0026ldquo;StringEquals\u0026rdquo;: {\n\u0026ldquo;aws:ResourceAccount\u0026rdquo;: [\n\u0026ldquo;{ACCOUNT_ID}\u0026rdquo;\n]\n}\n}\n},\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;S3GetObjectPermission\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;s3:GetObject\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: [\n\u0026ldquo;arn:aws:s3:::{SOURCE_BUCKET_NAME}/{PREFIX}/*\u0026rdquo;\n],\n\u0026ldquo;Condition\u0026rdquo;: {\n\u0026ldquo;StringEquals\u0026rdquo;: {\n\u0026ldquo;aws:ResourceAccount\u0026rdquo;: [\n\u0026ldquo;{ACCOUNT_ID}\u0026rdquo;\n]\n}\n}\n},\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;S3VectorsAccessPermission\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;s3vectors:GetIndex\u0026rdquo;,\n\u0026ldquo;s3vectors:QueryVectors\u0026rdquo;,\n\u0026ldquo;s3vectors:PutVectors\u0026rdquo;,\n\u0026ldquo;s3vectors:GetVectors\u0026rdquo;,\n\u0026ldquo;s3vectors:DeleteVectors\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;arn:aws:s3vectors:{REGION}:{ACCOUNT_ID}:bucket/{VECTOR_BUCKET_NAME}/index/{VECTOR_INDEX_NAME}\u0026rdquo;,\n\u0026ldquo;Condition\u0026rdquo;: {\n\u0026ldquo;StringEquals\u0026rdquo;: {\n\u0026ldquo;aws:ResourceAccount\u0026rdquo;: \u0026ldquo;{ACCOUNT_ID}\u0026rdquo;\n}\n}\n}\n]\n}\nDọn dẹp Để dọn dẹp tài nguyên của bạn, hãy hoàn thành các bước sau. Để xóa knowledge base:\nTrên bảng điều khiển Amazon Bedrock, chọn Knowledge Bases Chọn Knowledge Base của bạn và ghi lại cả tên vai trò dịch vụ IAM và ARN chỉ mục S3 Vector Chọn Delete và xác nhận Để xóa S3 Vector làm kho lưu trữ véc-tơ, hãy sử dụng các lệnh sau của Giao diện dòng lệnh AWS (AWS CLI):\ncode Code\ndownloadcontent_copy\nexpand_less\naws s3vectors delete-index --vector-bucket-name YOUR_VECTOR_BUCKET_NAME --index-name YOUR_INDEX_NAME --region YOUR_REGION\naws s3vectors delete-vector-bucket --vector-bucket-name YOUR_VECTOR_BUCKET_NAME --region YOUR_REGION\nTrên bảng điều khiển IAM, tìm vai trò đã ghi chú trước đó Chọn và xóa vai trò Để xóa bộ dữ liệu mẫu:\nTrên bảng điều khiển Amazon S3, tìm bucket S3 của bạn Chọn và xóa các tệp bạn đã tải lên cho hướng dẫn này Kết luận Sự tích hợp giữa Amazon Bedrock Knowledge Bases và Amazon S3 Vectors đại diện cho một bước tiến đáng kể trong việc làm cho các ứng dụng RAG trở nên dễ tiếp cận và khả thi về mặt kinh tế hơn ở quy mô lớn. Bằng cách sử dụng bộ lưu trữ được tối ưu hóa chi phí của Amazon S3 Vectors, các tổ chức giờ đây có thể xây dựng các cơ sở tri thức ở quy mô lớn với hiệu quả chi phí được cải thiện. Điều này có nghĩa là khách hàng có thể đạt được sự cân bằng tối ưu giữa hiệu suất và kinh tế, và bạn có thể tập trung vào việc tạo ra giá trị thông qua các ứng dụng do AI cung cấp thay vì quản lý cơ sở hạ tầng lưu trữ véc-tơ phức tạp.\nĐể bắt đầu với việc tích hợp Amazon Bedrock Knowledge Bases và Amazon S3 Vectors, hãy tham khảo Sử dụng S3 Vectors với Amazon Bedrock Knowledge Bases trong Hướng dẫn sử dụng Amazon S3.\nVề các tác giả ![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-8.jpeg)\nVaibhav Sabharwal là một Kiến trúc sư Giải pháp Cấp cao của Amazon Web Services (AWS) có trụ sở tại New York. Anh đam mê học hỏi các công nghệ đám mây mới và hỗ trợ khách hàng xây dựng chiến lược áp dụng đám mây, thiết kế các giải pháp sáng tạo và thúc đẩy sự xuất sắc trong vận hành. Là một thành viên của Cộng đồng Kỹ thuật Dịch vụ Tài chính tại AWS, anh tích cực đóng góp vào các nỗ lực hợp tác trong ngành.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/12/09/ML-17210-dani.jpg)\nDani Mitchell là một Kiến trúc sư Giải pháp Chuyên gia về AI Tạo sinh tại Amazon Web Services (AWS). Anh tập trung vào việc giúp các doanh nghiệp trên toàn thế giới đẩy nhanh hành trình AI tạo sinh của họ với Amazon Bedrock.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ml-19266-image-10-1.png)\nIrene Marban là một Kiến trúc sư Giải pháp Chuyên gia về AI Tạo sinh tại Amazon Web Services (AWS), làm việc với các khách hàng trên khắp EMEA để thiết kế và triển khai các giải pháp AI tạo sinh nhằm thúc đẩy hoạt động kinh doanh của họ. Với nền tảng về kỹ thuật y sinh và AI, công việc của cô tập trung vào việc giúp các tổ chức tận dụng các công nghệ AI mới nhất để thúc đẩy sự đổi mới và tăng trưởng. Khi rảnh rỗi, cô thích đọc sách và nấu ăn cho bạn bè.\n![alt text](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/22/Ashish.jpg)\nAshish Lal là Giám đốc Tiếp thị Sản phẩm Cấp cao về AI/ML cho Amazon Bedrock. Anh có hơn 11 năm kinh nghiệm trong lĩnh vực tiếp thị sản phẩm và thích giúp khách hàng đẩy nhanh thời gian tạo ra giá trị và giảm chi phí vòng đời AI của họ.\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối và làm quen với các thành viên trong First Cloud Journey. Thiết lập môi trường phát triển và hiểu quy trình làm việc của chương trình FCJ. Tạo tài khoản AWS Free Tier và khám phá các dịch vụ AWS cốt lõi. Thiết lập quy trình tài liệu hóa cho hành trình thực tập. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Làm quen với các thành viên FCJ - Hiểu quy trình làm việc và quy định của chương trình FCJ - Định hướng và giới thiệu ban đầu 08/09/2025 08/09/2025 2 - Cài đặt Linux Fedora KDE Plasma 42 - Học cách thiết lập và cấu hình Linux cơ bản - Khắc phục sự cố cài đặt 09/09/2025 09/09/2025 3 - Tạo tài khoản AWS Free Tier - Khám phá các dịch vụ AWS Free Tier - Hoàn thành các nhiệm vụ để nhận $200 tín dụng AWS 10/09/2025 10/09/2025 https://aws.amazon.com/free/ 4 - Tiếp tục khám phá AWS Free Tier - Xem xét các dịch vụ có sẵn: EC2, RDS, Lambda, VPC - Hiểu giới hạn dịch vụ và ràng buộc free tier 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Khám phá S3 buckets và các tùy chọn lưu trữ - Học quản lý ngân sách AWS - Thiết lập cảnh báo ngân sách hàng ngày và hàng tháng - Tiếp tục khắc phục sự cố Linux 12/09/2025 12/09/2025 https://aws.amazon.com/s3/ 6 - Hoàn thiện cấu hình ngân sách - Xem xét bảng điều khiển Billing \u0026amp; Cost Management - Hoàn tất khắc phục sự cố cài đặt Linux - Thiết lập GitHub repos cho tài liệu 13/09/2025 13/09/2025 Kết quả đạt được tuần 1: Đã tích hợp thành công với đội ngũ First Cloud Journey và hiểu được cấu trúc chương trình, quy trình làm việc và kỳ vọng.\nCài đặt và cấu hình Linux Fedora KDE Plasma 42 làm môi trường phát triển chính:\nHoàn thành thiết lập Linux cơ bản Giải quyết các vấn đề cài đặt và cấu hình Làm quen với môi trường desktop KDE Plasma Tạo và cấu hình tài khoản AWS Free Tier:\nĐăng ký thành công AWS Free Tier Hoàn thành các nhiệm vụ cần thiết để nhận $200 tín dụng AWS Khám phá các dịch vụ free tier có sẵn Có kinh nghiệm thực hành với các dịch vụ AWS cốt lõi:\nEC2 - Elastic Compute Cloud cho máy chủ ảo RDS - Relational Database Service Lambda - Dịch vụ tính toán serverless VPC - Virtual Private Cloud networking S3 - Simple Storage Service cho lưu trữ đối tượng Triển khai các phương pháp quản lý chi phí AWS tốt nhất:\nThiết lập AWS Budgets để giám sát chi phí Cấu hình cảnh báo ngân sách hàng ngày Cấu hình ngưỡng ngân sách hàng tháng Khám phá bảng điều khiển Billing \u0026amp; Cost Management Thiết lập quy trình tài liệu hóa:\nTạo các repository GitHub cho tài liệu hành trình AWS FCJ Thiết lập các template để quản lý worklog hiệu quả Tổ chức cấu trúc dự án cho tài liệu liên tục Đạt được kiến thức nền tảng:\nQuản lý và điều hướng tài khoản AWS cơ bản Quy tắc và quy trình hoạt động của chương trình FCJ Kiến thức cơ bản về quản trị hệ thống Linux Chiến lược tối ưu hóa chi phí cho tài nguyên đám mây Tổng quan các dịch vụ AWS Free Tier\nCấu hình cảnh báo ngân sách hàng ngày và hàng tháng\nThách thức gặp phải: Một số vấn đề nhỏ khi cài đặt Linux cần khắc phục và điều chỉnh cấu hình. Đường cong học tập ban đầu với việc điều hướng AWS console và khám phá dịch vụ. Bài học chính: Hiểu tầm quan trọng của quản lý chi phí ngay từ ngày đầu tiên trong môi trường đám mây. Giá trị của tài liệu hóa đúng cách và các template quy trình làm việc cho sự thành công dự án dài hạn. Kỹ năng quản trị hệ thống Linux cơ bản là cần thiết cho công việc điện toán đám mây. Mục tiêu tuần tới: Tìm hiểu sâu về các dịch vụ AWS cụ thể dựa trên yêu cầu dự án. Tiếp tục xây dựng tài liệu và tinh chỉnh quy trình làm việc. Khám phá các tính năng và phương pháp hay nhất của AWS nâng cao hơn. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "AWS First Cloud Journey - Chương trình 12 tuần Nhật ký này ghi chép hành trình 12 tuần của tôi qua chương trình AWS First Cloud Journey, từ ngày 6 tháng 9 năm 2025 đến ngày 30 tháng 11 năm 2025. Trong chương trình chuyên sâu này, tôi đã có được kiến thức toàn diện về các dịch vụ AWS cloud, tham dự các sự kiện AWS lớn, hoàn thành dự án nhóm, và xây dựng nền tảng vững chắc cho sự nghiệp trong cloud computing.\nTổng quan chương trình Chương trình kết hợp học AWS cá nhân, các bài lab thực hành, cộng tác nhóm, và tham gia các sự kiện cộng đồng AWS. Mặc dù đối mặt với thách thức bao gồm chấn thương tay ở Tuần 10, tôi đã hoàn thành thành công tất cả yêu cầu chương trình và thể hiện sự kiên cường và khả năng thích ứng trong suốt hành trình.\nTiến độ từng tuần Tuần 1: Onboarding và Nền tảng AWS\nKhởi động chương trình, sự kiện AWS FCJ tại Bitexco, AWS fundamentals, thiết lập tài khoản\nTuần 2: Thiết lập Môi trường Phát triển và AWS Cloud Day 2025\nAWS Cloud Day 2025 (GenAI track), công cụ phát triển, IAM cơ bản\nTuần 3: Cơ bản về VPC và EC2 với Triển khai Website Tĩnh\nCác khái niệm networking, EC2 instances, triển khai website tĩnh\nTuần 4: Tìm hiểu sâu về AWS Networking và Storage\nKiến trúc VPC, S3 storage, giới thiệu RDS\nTuần 5: Bài Lab thực hành và Bắt đầu dịch Blog\nVPC/S3 labs, RDS thực hành, giới thiệu Lambda, bản dịch blog đầu tiên\nTuần 6: Workshop Data Science on AWS\nWorkshop Data Science tại Đại học FPT, AWS Glue, SageMaker, API Gateway\nTuần 7: Container Services và Xuất bản Blog\nXuất bản blog đầu tiên, ECS/ECR, security best practices, bắt đầu blog thứ hai\nTuần 8: Tuần thi giữa kỳ\nChuẩn bị và hoàn thành thi AWS Cloud Practitioner\nTuần 9: Khởi động Dự án Nhóm\nThành lập nhóm, lập kế hoạch dự án, thiết kế kiến trúc\nTuần 10: Phát triển Dự án và AWS Cloud Mastery #1\nSprint dự án, chấn thương tay (14/11), AWS Cloud Mastery #1 về AI/ML/GenAI (15/11)\nTuần 11: AWS Cloud Mastery #2 và Phục hồi\nAWS Cloud Mastery #2 về DevOps (17/11), quy trình điều chỉnh, tái khám bác sĩ (21/11)\nTuần 12: Hoàn thành Dự án và AWS Cloud Mastery #3\nGiao dự án cuối, AWS Cloud Mastery #3 về Security (29/11), kết thúc chương trình\nThành tựu chính ✅ Hoàn thành chương trình AWS First Cloud Journey 12 tuần ✅ Tham dự 6 sự kiện và workshop AWS lớn ✅ Vượt qua kỳ thi giữa kỳ AWS Cloud Practitioner ✅ Dịch 2+ blog kỹ thuật AWS ✅ Hoàn thành dự án nhóm thành công ✅ Tham dự cả 3 workshop AWS Cloud Mastery Series ✅ Vượt qua chấn thương và điều chỉnh quy trình làm việc ✅ Xây dựng nền tảng kiến thức AWS toàn diện Các sự kiện đã tham dự AWS FCJ Kick-off (6/9/2025) - Tòa nhà Bitexco Financial Tower AWS Cloud Day 2025 - GenAI and Data Track Workshop Data Science on AWS (16/10/2025) - Đại học FPT AWS Cloud Mastery Series #1 - AI/ML/GenAI (15/11/2025) AWS Cloud Mastery Series #2 - DevOps (17/11/2025) AWS Cloud Mastery Series #3 - Security (29/11/2025) Kỹ năng đã phát triển Các dịch vụ AWS cốt lõi: EC2, S3, VPC, RDS, Lambda Kiến trúc Serverless và Ứng dụng GenAI Data Science và ML trên AWS (SageMaker, Bedrock) Thực hành DevOps và CI/CD Pipelines Security Best Practices và Well-Architected Framework Cộng tác Nhóm và Quản lý Dự án Tài liệu Kỹ thuật và Thuyết trình Kiên cường và Khả năng Thích ứng "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders - GenAI and Data Track Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian: Thứ Năm, ngày 18 tháng 09 năm 2025\nBài thu hoạch “Vietnam Cloud Day 2025: GenAI and Data Track” Mục Đích Của Sự Kiện Cung cấp cái nhìn tổng quan về (Agentic AI) và tầm nhìn chiến lược của AWS. Tìm hiểu cách xây dựng Nền tảng dữ liệu đồng nhất (Unified Data Foundation) nhằm hỗ trợ hiệu quả cho các hoạt động AI và Phân tích Dữ liệu (Analytics) trên AWS. Phân tích chi tiết lộ trình triển khai GenAI, các mô hình Kiến trúc AI Agent và những khó khăn trong việc đưa chúng vào môi trường sản xuất (production). Nghiên cứu về mô hình Chu trình Phát triển Hướng Dẫn bởi AI (AI-Driven Development Lifecycle - AI-DLC). Nắm vững các nguyên tắc cốt lõi về Bảo mật, Quản trị Rủi ro và AI có Trách nhiệm (Responsible AI) trong lĩnh vực Generative AI. Giới thiệu các Dịch vụ AWS mới được thiết kế để hỗ trợ AI Agents và tối đa hóa năng suất làm việc cho doanh nghiệp. Danh Sách Diễn Giả Jun Kai Loke - Chuyên gia Kiến trúc Giải pháp AI/ML, AWS Kien Nguyen - Kiến trúc sư Giải pháp, AWS Tamelly Lim - Chuyên gia Kiến trúc Giải pháp Lưu trữ, AWS Binh Tran - Kiến trúc sư Giải pháp Cấp cao, AWS Taiki Dang - Kiến trúc sư Giải pháp, AWS Christal Poon - Chuyên gia Kiến trúc Giải pháp, AWS Nội Dung Nổi Bật Tổng quan về AI Tác Tử (Agentic AI) – Jun Kai Loke Agentic AI là một xu hướng chiến lược quan trọng, tập trung vào việc tạo ra các hệ thống có khả năng tự vận hành, giảm thiểu sự can thiệp của con người và tự động hóa các quy trình phức tạp ở mức độ sâu. Các ví dụ thực tế về việc áp dụng thành công: Katalon, Apero, Techcom Securities. Amazon Bedrock đóng vai trò là nền tảng cốt lõi để phát triển AI, hỗ trợ: Triển khai bảo mật ở quy mô lớn. Tích hợp các công cụ (tools) và khả năng ghi nhớ (memory). Giám sát toàn diện từ đầu đến cuối (end-to-end monitoring). Xây dựng Nền tảng Dữ liệu Thống nhất trên AWS – Kien Nguyen Thách thức hiện tại: Nhiều doanh nghiệp gặp khó khăn trong triển khai GenAI do nền tảng dữ liệu chưa sẵn sàng (chỉ 52% CDO đánh giá nền tảng dữ liệu đã sẵn sàng, theo HBR), chủ yếu do dữ liệu bị cô lập (data silos), đội ngũ bị chia rẽ (people silos) và các phân khu kinh doanh riêng biệt (business silos). Chiến lược dữ liệu toàn diện (End-to-End) bao gồm ba thành phần tương tác: Nhà sản xuất dữ liệu (Producers), Nền tảng cốt lõi (Foundations) và Người tiêu thụ dữ liệu (Consumers). Các dịch vụ dữ liệu trọng yếu của AWS: Amazon Bedrock (nền tảng GenAI). Cơ sở dữ liệu (RDS và các dịch vụ chuyên dụng hỗ trợ tìm kiếm vector). Analytics \u0026amp; ML (SageMaker, Unified Studio). Quản trị Dữ liệu và AI (Data \u0026amp; AI Governance). Kiến trúc Lake House (S3, Redshift Managed Storage, Iceberg Open API). Amazon DataZone (Quản lý và chia sẻ dữ liệu). Lộ trình GenAI \u0026amp; Kiến trúc AI Agents – Jun Kai Loke \u0026amp; Tamelly Lim Bản thiết kế (Blueprint) xây dựng AI Agents gồm: Mô hình (Model) \u0026amp; năng lực ứng dụng (application capabilities), và khung công cụ (tool framework). AWS giới thiệu Amazon Bedrock AgentCore để khắc phục các khó khăn khi đưa Agents vào môi trường sản xuất. AgentCore bao gồm: Agent Core Runtime, Agent Core Gateway, Memory, Agent Browser và Code Interpreter, nhằm mục đích tăng cường bảo mật và khả năng mở rộng. Chu trình Phát triển Hướng Dẫn bởi AI (AI-DLC) – Binh Tran AI-DLC là mô hình phát triển phần mềm mới, được tự động hóa tối đa bởi AI, gồm 3 giai đoạn:\nKhởi tạo (Inception): Xác định bối cảnh (context), phác thảo yêu cầu người dùng (user stories), và lên kế hoạch bằng các đơn vị công việc (work units). Xây dựng (Construction): Viết mã (Code) + kiểm thử (test), bổ sung kiến trúc, triển khai Cơ sở hạ tầng dưới dạng Mã (IaC) và kiểm thử. Vận hành (Operation): Triển khai lên môi trường production bằng IaC và quản lý sự cố. Bảo mật Ứng dụng Generative AI – Taiki Dang Các yếu tố bảo mật thiết yếu: Tuân thủ \u0026amp; Quản trị (Compliance \u0026amp; Governance), Pháp lý \u0026amp; Quyền riêng tư (Legal \u0026amp; Privacy), Các Biện pháp kiểm soát (Controls), Quản lý rủi ro (Risk Management) và Khả năng phục hồi (Resilience). Phân tích Rủi ro theo Lớp: Rủi ro đối với người dùng cuối (Hallucination, IP, Legal), rủi ro đối với người tinh chỉnh mô hình (data retention) và rủi ro đối với nhà cung cấp mô hình (training data, model construction). Chiến lược Giảm thiểu rủi ro: Sử dụng Prompt engineering, Fine-tuning, Kỹ thuật Tăng cường Truy xuất (RAG), điều chỉnh tham số, Bedrock Guardrails và bảo mật đầu vào (prompt security). Cần áp dụng các tiêu chuẩn như AWS Well-Architected, MITRE ATLAS, OWASP Top 10 for LLM Apps, NIST AI 600-1, ISO 42001 và EU AI Act. AI Agents: Tăng cường Năng suất Doanh nghiệp – Christal Poon Giới thiệu các dạng AI Agents: Agents chuyên biệt (Specialized Agents), Agents được quản lý hoàn toàn (Fully-managed Agents) và Agents tự xây dựng (DIY Agents). Các dịch vụ hỗ trợ năng suất: Amazon QuickSight (cho phân tích kinh doanh) và Amazon Q (cung cấp Dashboards, Reports, Executive summaries và các Kịch bản AI Agent). Những Gì Học Được Tư Duy \u0026amp; Chiến Lược Agentic AI là bước phát triển tiếp theo của tự động hóa, hướng tới các hệ thống tự chủ, giảm sự giám sát của con người. Nền tảng dữ liệu vững chắc (dựa trên S3, Lake House, Bedrock, SageMaker) là yêu cầu tiên quyết để triển khai GenAI thành công. AI-DLC cung cấp một phương pháp luận hiện đại, tự động hóa toàn bộ chu trình phát triển từ lập kế hoạch, viết code, kiểm thử đến triển khai. Kiến Trúc \u0026amp; Kỹ Thuật Nắm bắt được kiến trúc AI Agents và giải pháp Amazon Bedrock AgentCore giúp giải quyết các thách thức về bảo mật và khả năng mở rộng trong môi trường sản xuất. Bảo mật phải được tích hợp ở mọi cấp độ của AI stack, từ dữ liệu, mô hình đến ứng dụng đầu cuối, đồng thời tuân thủ các chuẩn mực và quy định quốc tế. Ứng Dụng Công Nghệ AWS đang đầu tư và mở rộng mạnh mẽ hệ sinh thái AI Agents \u0026amp; Enterprise AI thông qua các dịch vụ như Amazon Q và QuickSuite (sắp ra mắt). Ứng Dụng Vào Công Việc Tối ưu hóa quy trình: Nghiên cứu và tích hợp các AI Agents vào các tác vụ nghiệp vụ có tính lặp lại để tăng hiệu suất. Quản lý chất lượng: Sử dụng Amazon Bedrock, Amazon Q và Guardrails để kiểm soát chất lượng, tính an toàn và giảm thiểu hiện tượng \u0026ldquo;hallucination\u0026rdquo; của mô hình. Xây dựng hạ tầng: Đảm bảo xây dựng một nền tảng dữ liệu thống nhất và có quản trị rõ ràng trước khi triển khai các dự án GenAI. Áp dụng AI-DLC: Thử nghiệm áp dụng mô hình phát triển phần mềm AI-DLC vào các dự án nội bộ để tăng tốc độ triển khai. Phân tích nghiệp vụ: Sử dụng QuickSight và Amazon Q để tạo nhanh các dashboard và insight phục vụ ban lãnh đạo và đội ngũ nghiệp vụ. Trải nghiệm trong event Workshop đã mang lại cái nhìn rõ ràng và thực tế về sự chuyển đổi từ tự động hóa truyền thống sang kỷ nguyên Agentic AI. Các bài trình bày của diễn giả đã định hướng cụ thể cho hành trình áp dụng GenAI tại Việt Nam. Sự kết hợp giữa AgentCore, Bedrock, AI-DLC và Amazon Q đã phác họa nên một bức tranh toàn diện và mạnh mẽ về thế hệ AI tiếp theo dành cho doanh nghiệp, từ nền tảng dữ liệu, phát triển ứng dụng, đến bảo mật và vận hành.\nThêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật chuyên sâu mà còn giúp thay đổi tư duy về cách tích hợp AI một cách chiến lược, có trách nhiệm và an toàn vào mọi khía cạnh của doanh nghiệp.\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.2-prerequisite/",
	"title": "Yêu cầu tiên quyết",
	"tags": [],
	"description": "",
	"content": "Yêu cầu tiên quyết cho Workshop InsightHR Trước khi bắt đầu workshop này, hãy đảm bảo bạn đã thiết lập các công cụ và tài khoản sau.\n1. Tài khoản AWS Bạn cần một tài khoản AWS với quyền phù hợp để tạo và quản lý tài nguyên.\nQuyền truy cập Dịch vụ AWS Yêu cầu:\nIAM (Identity and Access Management) DynamoDB Lambda API Gateway S3 CloudFront Cognito Bedrock CloudWatch Route53 (tùy chọn, cho custom domain) Ước tính Chi phí: $2-5/tháng trong quá trình phát triển\nNếu bạn đang sử dụng AWS Free Tier, nhiều dịch vụ trong workshop này được bao phủ. Tuy nhiên, một số dịch vụ như Bedrock có thể phát sinh phí nhỏ.\n2. AWS CLI Cài đặt và cấu hình AWS Command Line Interface.\nCài đặt:\nWindows:\nmsiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi macOS:\ncurl \u0026#34;https://awscli.amazonaws.com/AWSCLI2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; sudo installer -pkg AWSCLIV2.pkg -target / Linux:\ncurl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Cấu hình:\naws configure Nhập thông tin:\nAWS Access Key ID AWS Secret Access Key Default region (ví dụ: ap-southeast-1) Default output format (ví dụ: json) Xác minh Cài đặt:\naws --version # Kết quả mong đợi: aws-cli/2.x.x Python/3.x.x ... 3. Node.js và npm Yêu cầu cho phát triển frontend.\nPhiên bản Tối thiểu: Node.js 18+\nCài đặt:\nTải từ nodejs.org hoặc sử dụng version manager:\nSử dụng nvm (khuyến nghị):\n# Cài đặt nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash # Cài đặt Node.js nvm install 18 nvm use 18 Xác minh Cài đặt:\nnode --version # Mong đợi: v18.x.x hoặc cao hơn npm --version # Mong đợi: 9.x.x hoặc cao hơn 4. Python Yêu cầu cho phát triển Lambda function.\nPhiên bản Tối thiểu: Python 3.11+\nCài đặt:\nTải từ python.org hoặc sử dụng package manager của hệ thống.\nXác minh Cài đặt:\npython --version # hoặc python3 --version # Mong đợi: Python 3.11.x hoặc cao hơn Cài đặt pip (nếu chưa có):\npython -m ensurepip --upgrade 5. Text Editor / IDE Chọn môi trường phát triển ưa thích của bạn:\nKhuyến nghị: Visual Studio Code\nTải từ code.visualstudio.com Cài đặt các extension khuyến nghị: AWS Toolkit Python ESLint Prettier Tailwind CSS IntelliSense Lựa chọn khác:\nPyCharm Sublime Text Atom WebStorm 6. Git (Tùy chọn nhưng Khuyến nghị) Cho version control và truy cập code repositories.\nCài đặt:\nTải từ git-scm.com\nXác minh Cài đặt:\ngit --version # Mong đợi: git version 2.x.x 7. Kiến thức Yêu cầu JavaScript/TypeScript:\nCú pháp cơ bản và tính năng ES6+ Async/await và Promises React cơ bản (components, hooks, state) Python:\nCú pháp cơ bản và cấu trúc dữ liệu Functions và xử lý lỗi Làm việc với JSON Khái niệm AWS:\nHiểu biết cơ bản về cloud computing Quen thuộc với AWS Console Hiểu về kiến trúc serverless (hữu ích nhưng không bắt buộc) Web Development:\nHTML/CSS cơ bản Khái niệm REST API HTTP methods (GET, POST, PUT, DELETE) 8. Thiết lập Tài khoản AWS Tạo IAM User Để tuân thủ phương pháp bảo mật tốt nhất, tạo IAM user thay vì sử dụng root credentials:\nĐăng nhập vào AWS Console\nĐiều hướng đến dịch vụ IAM\nClick \u0026ldquo;Users\u0026rdquo; → \u0026ldquo;Add users\u0026rdquo;\nNhập username (ví dụ: insighthr-admin)\nChọn \u0026ldquo;Programmatic access\u0026rdquo; và \u0026ldquo;AWS Management Console access\u0026rdquo;\nGắn policies:\nAdministratorAccess (cho mục đích workshop) Hoặc tạo custom policy với quyền yêu cầu Tải credentials (Access Key ID và Secret Access Key)\nCấu hình AWS CLI với credentials này\nKích hoạt Dịch vụ Yêu cầu Đảm bảo các dịch vụ sau có sẵn trong region của bạn:\n✅ AWS Lambda ✅ Amazon DynamoDB ✅ Amazon API Gateway ✅ Amazon S3 ✅ Amazon CloudFront ✅ Amazon Cognito ✅ Amazon Bedrock (kiểm tra tính khả dụng theo region) ✅ Amazon CloudWatch Region Khuyến nghị: ap-southeast-1 (Singapore) - Tất cả dịch vụ đều có sẵn và độ trễ tốt cho Đông Nam Á.\n9. Quyền truy cập Bedrock Model AWS Bedrock yêu cầu yêu cầu quyền truy cập model rõ ràng.\nCác bước Kích hoạt:\nVào AWS Console → Amazon Bedrock Điều hướng đến \u0026ldquo;Model access\u0026rdquo; ở sidebar bên trái Click \u0026ldquo;Manage model access\u0026rdquo; Tìm \u0026ldquo;Claude 3 Haiku\u0026rdquo; của Anthropic Đánh dấu checkbox và click \u0026ldquo;Request model access\u0026rdquo; Chờ phê duyệt (thường là ngay lập tức cho Haiku) Không có quyền truy cập Bedrock, tính năng AI chatbot sẽ không hoạt động. Tuy nhiên, bạn vẫn có thể hoàn thành phần còn lại của workshop.\n10. Tùy chọn: Tên miền Nếu bạn muốn sử dụng custom domain (như insight-hr.io.vn):\nMua domain từ registrar (ví dụ: Route53, GoDaddy, Namecheap) Có quyền truy cập quản lý DNS Ngân sách cho SSL certificate (miễn phí với AWS Certificate Manager) Checklist Trước Workshop Trước khi tiếp tục phần tiếp theo, xác minh bạn có:\nTài khoản AWS với quyền admin AWS CLI đã cài đặt và cấu hình Node.js 18+ và npm đã cài đặt Python 3.11+ đã cài đặt Text editor/IDE đã thiết lập Git đã cài đặt (tùy chọn) Kiến thức cơ bản về JavaScript/TypeScript và Python Hiểu biết về REST APIs Đã yêu cầu quyền truy cập AWS Bedrock model Quen thuộc với AWS Console Khắc phục Sự cố Vấn đề Cấu hình AWS CLI:\n# Kiểm tra cấu hình hiện tại aws configure list # Test quyền truy cập AWS aws sts get-caller-identity Vấn đề Phiên bản Node.js:\n# Kiểm tra các phiên bản đã cài đặt nvm list # Chuyển sang phiên bản đúng nvm use 18 Vấn đề Phiên bản Python:\n# Kiểm tra đường dẫn Python which python3 # Tạo virtual environment python3 -m venv venv source venv/bin/activate # Trên Windows: venv\\Scripts\\activate Bước tiếp theo Sau khi hoàn thành tất cả yêu cầu tiên quyết, tiếp tục đến Kiến trúc Dự án để hiểu thiết kế hệ thống.\nTài nguyên Bổ sung Tài liệu AWS CLI Tài liệu Node.js Tài liệu Python AWS Free Tier Tài liệu AWS Bedrock "
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Đánh giá các mô hình AI tạo sinh với Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI bởi Surya Kari, Joel Carlson, Michael Cai, Morteza Ziyadi, Pradeep Natarajan, và Saurabh Sahu | vào ngày 17 tháng 7 2025 | trong Amazon Nova, Amazon SageMaker, Amazon SageMaker AI, Thông báo, Trí tuệ nhân tạo, Các mô hình nền tảng | Permalink | Bình luận | Chia sẻ\nViệc đánh giá hiệu suất của các mô hình ngôn ngữ lớn (LLM) vượt ra ngoài các chỉ số thống kê như độ phức tạp (perplexity) hay điểm đánh giá song ngữ (BLEU). Đối với hầu hết các kịch bản AI tạo sinh trong thế giới thực, điều quan trọng là phải hiểu liệu một mô hình có đang tạo ra các kết quả đầu ra tốt hơn so với một mô hình cơ sở hoặc một phiên bản trước đó hay không. Điều này đặc biệt quan trọng đối với các ứng dụng như tóm tắt, tạo nội dung, hoặc các tác tử thông minh, nơi các phán đoán chủ quan và tính đúng đắn tinh tế đóng một vai trò trung tâm.\nKhi các tổ chức đẩy mạnh việc triển khai các mô hình này trong môi trường sản xuất, chúng tôi nhận thấy nhu cầu ngày càng tăng từ khách hàng muốn đánh giá chất lượng mô hình một cách có hệ thống, vượt qua các phương pháp đánh giá truyền thống. Các phương pháp hiện tại như đo lường độ chính xác và đánh giá dựa trên quy tắc, mặc dù hữu ích, không thể giải quyết hoàn toàn các nhu cầu đánh giá tinh tế này, đặc biệt khi các tác vụ đòi hỏi phán đoán chủ quan, hiểu biết theo ngữ cảnh, hoặc sự phù hợp với các yêu cầu kinh doanh cụ thể. Để thu hẹp khoảng cách này, LLM-như-một-giám-khảo đã nổi lên như một phương pháp đầy hứa hẹn, sử dụng khả năng lý luận của các LLM để đánh giá các mô hình khác một cách linh hoạt hơn và ở quy mô lớn.\nHôm nay, chúng tôi vui mừng giới thiệu một phương pháp toàn diện để đánh giá mô hình thông qua khả năng Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI, một dịch vụ được quản lý toàn phần của Amazon Web Services (AWS) để xây dựng, huấn luyện và triển khai các mô hình học máy (ML) ở quy mô lớn. Amazon Nova LLM-as-a-Judge được thiết kế để cung cấp các đánh giá mạnh mẽ, không thiên vị về kết quả đầu ra của AI tạo sinh trên các họ mô hình. Nova LLM-as-a-Judge có sẵn dưới dạng các quy trình công việc được tối ưu hóa trên SageMaker AI, và với nó, bạn có thể bắt đầu đánh giá hiệu suất mô hình so với các trường hợp sử dụng cụ thể của mình trong vài phút. Không giống như nhiều bộ đánh giá thể hiện sự thiên vị về mặt kiến trúc, Nova LLM-as-a-Judge đã được xác thực nghiêm ngặt để đảm bảo tính khách quan và đã đạt được hiệu suất hàng đầu trên các bộ tiêu chuẩn đánh giá chính trong khi phản ánh sát sao sở thích của con người. Với độ chính xác vượt trội và độ thiên vị tối thiểu, nó đặt ra một tiêu chuẩn mới cho việc đánh giá LLM đáng tin cậy, cấp độ sản xuất.\nKhả năng Nova LLM-as-a-Judge cung cấp các so sánh cặp đôi giữa các phiên bản mô hình, để bạn có thể tự tin đưa ra các quyết định dựa trên dữ liệu về việc cải tiến mô hình.\nCách Nova LLM-as-a-Judge được huấn luyện Nova LLM-as-a-Judge được xây dựng thông qua một quy trình huấn luyện nhiều bước bao gồm các giai đoạn huấn luyện có giám sát và học tăng cường, sử dụng các bộ dữ liệu công khai được gán nhãn với sở thích của con người. Đối với thành phần độc quyền, nhiều người gán nhãn đã độc lập đánh giá hàng ngàn ví dụ bằng cách so sánh các cặp phản hồi LLM khác nhau cho cùng một câu lệnh. Để xác minh tính nhất quán và công bằng, tất cả các gán nhãn đều trải qua các cuộc kiểm tra chất lượng nghiêm ngặt, với các phán quyết cuối cùng được hiệu chỉnh để phản ánh sự đồng thuận rộng rãi của con người thay vì một quan điểm cá nhân.\nDữ liệu huấn luyện được thiết kế để vừa đa dạng vừa mang tính đại diện. Các câu lệnh bao trùm một loạt các hạng mục, bao gồm kiến thức thực tế, sáng tạo, lập trình, toán học, các lĩnh vực chuyên ngành, và độc tính, để mô hình có thể đánh giá các kết quả đầu ra trên nhiều kịch bản thực tế. Dữ liệu huấn luyện bao gồm dữ liệu từ hơn 90 ngôn ngữ và chủ yếu bao gồm tiếng Anh, Nga, Trung, Đức, Nhật và Ý. Điều quan trọng là, một nghiên cứu về độ thiên vị nội bộ đánh giá hơn 10.000 phán đoán ưu tiên của con người so với 75 mô hình của bên thứ ba đã xác nhận rằng Amazon Nova LLM-as-a-Judge chỉ cho thấy độ thiên vị tổng hợp là 3% so với các chú thích của con người. Mặc dù đây là một thành tựu đáng kể trong việc giảm thiểu sự thiên vị có hệ thống, chúng tôi vẫn khuyến nghị thỉnh thoảng kiểm tra tại chỗ để xác thực các so sánh quan trọng.\nTrong hình dưới đây, bạn có thể thấy độ thiên vị của Nova LLM-as-a-Judge so với sở thích của con người khi đánh giá các kết quả đầu ra của Amazon Nova so với các kết quả đầu ra từ các mô hình khác. Ở đây, độ thiên vị được đo bằng sự khác biệt giữa sở thích của giám khảo và sở thích của con người qua hàng ngàn ví dụ. Giá trị dương cho thấy giám khảo hơi thiên vị các mô hình Amazon Nova, và giá trị âm cho thấy điều ngược lại. Để định lượng độ tin cậy của các ước tính này, các khoảng tin cậy 95% đã được tính toán bằng cách sử dụng sai số chuẩn cho sự khác biệt của các tỷ lệ, giả định các phân phối nhị thức độc lập.\nAmazon Nova LLM-as-a-Judge đạt được hiệu suất tiên tiến trong số các mô hình đánh giá, thể hiện sự tương đồng cao với các phán đoán của con người trên một loạt các tác vụ. Ví dụ, nó đạt độ chính xác 45% trên JudgeBench (so với 42% của Meta J1 8B) và 68% trên PPE (so với 60% của Meta J1 8B). Dữ liệu từ J1 8B của Meta được lấy từ bài viết Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning.\nNhững kết quả này làm nổi bật sức mạnh của Amazon Nova LLM-as-a-Judge trong các đánh giá liên quan đến chatbot, như được thể hiện trong bộ tiêu chuẩn PPE. Việc đo lường hiệu suất của chúng tôi tuân theo các thực tiễn tốt nhất hiện nay, báo cáo kết quả đã được đối chiếu cho các phản hồi được hoán đổi vị trí trên JudgeBench, CodeUltraFeedback, Eval Bias, và LLMBar, trong khi sử dụng kết quả một lượt cho PPE.\nMô hình Eval Bias Judge Bench LLM Bar PPE CodeUltraFeedback Nova LLM-as-a-Judge 0.76 0.45 0.67 0.68 0.64 Meta J1 8B – 0.42 – 0.60 – Nova Micro 0.56 0.37 0.55 0.6 – Trong bài đăng này, chúng tôi trình bày một phương pháp tinh gọn để triển khai các đánh giá Amazon Nova LLM-as-a-Judge bằng SageMaker AI, diễn giải các chỉ số kết quả, và áp dụng quy trình này để cải thiện các ứng dụng AI tạo sinh của bạn.\nTổng quan về quy trình công việc đánh giá Quy trình đánh giá bắt đầu bằng việc chuẩn bị một bộ dữ liệu trong đó mỗi ví dụ bao gồm một câu lệnh và hai kết quả đầu ra thay thế của mô hình. Định dạng JSONL trông như sau:\n{\n\u0026ldquo;prompt\u0026rdquo;:\u0026ldquo;Explain photosynthesis.\u0026rdquo;,\n\u0026ldquo;response_A\u0026rdquo;:\u0026ldquo;Answer A\u0026hellip;\u0026rdquo;,\n\u0026ldquo;response_B\u0026rdquo;:\u0026ldquo;Answer B\u0026hellip;\u0026rdquo;\n}\n{\n\u0026ldquo;prompt\u0026rdquo;:\u0026ldquo;Summarize the article.\u0026rdquo;,\n\u0026ldquo;response_A\u0026rdquo;:\u0026ldquo;Answer A\u0026hellip;\u0026rdquo;,\n\u0026ldquo;response_B\u0026rdquo;:\u0026ldquo;Answer B\u0026hellip;\u0026rdquo;\n}\nSau khi chuẩn bị bộ dữ liệu này, bạn sử dụng công thức đánh giá được cung cấp của SageMaker, công thức này định cấu hình chiến lược đánh giá, chỉ định mô hình nào sẽ được sử dụng làm giám khảo, và xác định các cài đặt suy luận như nhiệt độ (temperature) và top_p.\nViệc đánh giá chạy bên trong một công việc huấn luyện của SageMaker sử dụng các container Amazon Nova dựng sẵn. SageMaker AI cung cấp tài nguyên tính toán, điều phối việc đánh giá, và ghi các chỉ số đầu ra cùng các hình ảnh trực quan hóa vào Amazon Simple Storage Service (Amazon S3).\nKhi hoàn tất, bạn có thể tải xuống và phân tích kết quả, bao gồm các phân phối ưu tiên, tỷ lệ thắng, và các khoảng tin cậy.\nTìm hiểu cách hoạt động của Amazon Nova LLM-as-a-Judge Amazon Nova LLM-as-a-Judge sử dụng một phương pháp đánh giá gọi là giám khảo ưu tiên tổng thể nhị phân. Giám khảo ưu tiên tổng thể nhị phân là một phương pháp trong đó một mô hình ngôn ngữ so sánh hai kết quả đầu ra cạnh nhau và chọn ra cái tốt hơn hoặc tuyên bố hòa. Đối với mỗi ví dụ, nó đưa ra một sự ưu tiên rõ ràng. Khi bạn tổng hợp các phán đoán này trên nhiều mẫu, bạn sẽ nhận được các chỉ số như tỷ lệ thắng và khoảng tin cậy. Phương pháp này sử dụng khả năng lý luận của chính mô hình để đánh giá các phẩm chất như sự liên quan và độ rõ ràng một cách trực tiếp và nhất quán.\nMô hình giám khảo này nhằm cung cấp các ưu tiên tổng thể chung có độ trễ thấp trong các tình huống mà phản hồi chi tiết không cần thiết Kết quả đầu ra của mô hình này là một trong hai [[A\u0026gt;B]] hoặc [[B\u0026gt;A]] Các trường hợp sử dụng cho mô hình này chủ yếu là những trường hợp yêu cầu các ưu tiên cặp đôi chung, tự động và có độ trễ thấp, chẳng hạn như chấm điểm tự động để lựa chọn điểm kiểm tra (checkpoint) trong các quy trình huấn luyện Tìm hiểu các chỉ số đánh giá của Amazon Nova LLM-as-a-Judge Khi sử dụng khung Amazon Nova LLM-as-a-Judge để so sánh các kết quả đầu ra từ hai mô hình ngôn ngữ, SageMaker AI tạo ra một bộ toàn diện các chỉ số định lượng. Bạn có thể sử dụng các chỉ số này để đánh giá mô hình nào hoạt động tốt hơn và độ tin cậy của việc đánh giá. Kết quả được chia thành ba loại chính: các chỉ số ưu tiên cốt lõi, các chỉ số tin cậy thống kê, và các chỉ số sai số chuẩn.\nCác chỉ số ưu tiên cốt lõi báo cáo tần suất kết quả đầu ra của mỗi mô hình được mô hình giám khảo ưa thích. Chỉ số a_scores đếm số lượng ví dụ mà Mô hình A được ưu tiên, và b_scores đếm các trường hợp Mô hình B được chọn là tốt hơn. Chỉ số ties ghi lại các trường hợp mà mô hình giám khảo đánh giá cả hai phản hồi đều bằng nhau hoặc không thể xác định một sự ưu tiên rõ ràng. Chỉ số inference_error đếm các trường hợp mà giám khảo không thể tạo ra một phán đoán hợp lệ do dữ liệu bị định dạng sai hoặc lỗi nội bộ.\nCác chỉ số tin cậy thống kê định lượng khả năng các ưu tiên quan sát được phản ánh sự khác biệt thực sự về chất lượng mô hình thay vì biến thiên ngẫu nhiên. Chỉ số winrate báo cáo tỷ lệ trên tất cả các so sánh hợp lệ mà trong đó Mô hình B được ưa thích. lower_rate và upper_rate xác định các giới hạn dưới và trên của khoảng tin cậy 95% cho tỷ lệ thắng này. Ví dụ, một winrate là 0.75 với khoảng tin cậy từ 0.60 đến 0.85 cho thấy rằng, ngay cả khi tính đến sự không chắc chắn, Mô hình B vẫn được ưa thích hơn Mô hình A một cách nhất quán. Trường score thường khớp với số lần thắng của Mô hình B nhưng cũng có thể được tùy chỉnh cho các chiến lược đánh giá phức tạp hơn.\nCác chỉ số sai số chuẩn cung cấp một ước tính về sự không chắc chắn thống kê trong mỗi lần đếm. Chúng bao gồm a_scores_stderr, b_scores_stderr, ties_stderr, inference_error_stderr, và score_stderr. Các giá trị sai số chuẩn nhỏ hơn cho thấy kết quả đáng tin cậy hơn. Các giá trị lớn hơn có thể chỉ ra sự cần thiết phải có thêm dữ liệu đánh giá hoặc kỹ thuật câu lệnh nhất quán hơn.\nViệc diễn giải các chỉ số này đòi hỏi sự chú ý đến cả các ưu tiên quan sát được và các khoảng tin cậy:\nNếu winrate cao hơn đáng kể so với 0.5 và khoảng tin cậy không bao gồm 0.5, thì Mô hình B được ưu tiên hơn về mặt thống kê so với Mô hình A. Ngược lại, nếu winrate thấp hơn 0.5 và khoảng tin cậy hoàn toàn nằm dưới 0.5, thì Mô hình A được ưa thích hơn. Khi khoảng tin cậy chồng lấp với 0.5, kết quả là không có kết luận và nên tiến hành đánh giá thêm. Các giá trị cao trong inference_error hoặc sai số chuẩn lớn cho thấy có thể đã có vấn đề trong quá trình đánh giá, chẳng hạn như sự không nhất quán trong định dạng câu lệnh hoặc kích thước mẫu không đủ. Sau đây là một ví dụ về kết quả chỉ số từ một lần chạy đánh giá:\n{\n\u0026ldquo;a_scores\u0026rdquo;: 16.0,\n\u0026ldquo;a_scores_stderr\u0026rdquo;: 0.03,\n\u0026ldquo;b_scores\u0026rdquo;: 10.0,\n\u0026ldquo;b_scores_stderr\u0026rdquo;: 0.09,\n\u0026ldquo;ties\u0026rdquo;: 0.0,\n\u0026ldquo;ties_stderr\u0026rdquo;: 0.0,\n\u0026ldquo;inference_error\u0026rdquo;: 0.0,\n\u0026ldquo;inference_error_stderr\u0026rdquo;: 0.0,\n\u0026ldquo;score\u0026rdquo;: 10.0,\n\u0026ldquo;score_stderr\u0026rdquo;: 0.09,\n\u0026ldquo;winrate\u0026rdquo;: 0.38,\n\u0026ldquo;lower_rate\u0026rdquo;: 0.23,\n\u0026ldquo;upper_rate\u0026rdquo;: 0.56\n}\nTrong ví dụ này, Mô hình A được ưa thích 16 lần, Mô hình B được ưa thích 10 lần, và không có trường hợp hòa hoặc lỗi suy luận nào. Tỷ lệ thắng 0.38 cho thấy Mô hình B được ưa thích trong 38% các trường hợp, với khoảng tin cậy 95% dao động từ 23% đến 56%. Vì khoảng này bao gồm 0.5, kết quả này cho thấy việc đánh giá không có kết luận, và có thể cần thêm dữ liệu để làm rõ mô hình nào hoạt động tốt hơn về tổng thể.\nCác chỉ số này, được tạo tự động như một phần của quá trình đánh giá, cung cấp một nền tảng thống kê nghiêm ngặt để so sánh các mô hình và đưa ra các quyết định dựa trên dữ liệu về việc triển khai mô hình nào.\nTổng quan về giải pháp Giải pháp này trình bày cách đánh giá các mô hình AI tạo sinh trên Amazon SageMaker AI bằng cách sử dụng khả năng Nova LLM-as-a-Judge. Mã Python được cung cấp sẽ hướng dẫn bạn qua toàn bộ quy trình công việc.\nĐầu tiên, nó chuẩn bị một bộ dữ liệu bằng cách lấy mẫu các câu hỏi từ SQuAD và tạo ra các phản hồi ứng viên từ Qwen2.5 và Claude 3.7 của Anthropic. Những kết quả đầu ra này được lưu trong một tệp JSONL chứa câu lệnh và cả hai phản hồi.\nChúng tôi đã truy cập Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock bằng client bedrock-runtime. Chúng tôi đã truy cập Qwen2.5 1.5B bằng một điểm cuối (endpoint) Hugging Face được lưu trữ trên SageMaker.\nTiếp theo, một Trình ước tính PyTorch (PyTorch Estimator) khởi chạy một công việc đánh giá bằng cách sử dụng một công thức Amazon Nova LLM-as-a-Judge. Công việc này chạy trên các phiên bản GPU như ml.g5.12xlarge và tạo ra các chỉ số đánh giá, bao gồm tỷ lệ thắng, khoảng tin cậy, và số lần ưu tiên. Kết quả được lưu vào Amazon S3 để phân tích.\nCuối cùng, một hàm trực quan hóa sẽ hiển thị các biểu đồ và bảng, tóm tắt mô hình nào được ưa thích hơn, mức độ ưu tiên mạnh như thế nào, và độ tin cậy của các ước tính. Thông qua phương pháp từ đầu đến cuối này, bạn có thể đánh giá các cải tiến, theo dõi các sự suy giảm hiệu suất, và đưa ra các quyết định dựa trên dữ liệu về việc triển khai các mô hình tạo sinh—tất cả mà không cần gán nhãn thủ công.\nCác điều kiện tiên quyết Bạn cần hoàn thành các điều kiện tiên quyết sau đây trước khi có thể chạy sổ tay:\nThực hiện các yêu cầu tăng hạn ngạch sau đây cho SageMaker AI. Đối với trường hợp sử dụng này, bạn cần yêu cầu tối thiểu 1 phiên bản g5.12xlarge. Trên bảng điều khiển Service Quotas, hãy yêu cầu các hạn ngạch SageMaker AI sau, 1 phiên bản G5 (g5.12xlarge) để sử dụng cho công việc huấn luyện (Tùy chọn) Bạn có thể tạo một miền Amazon SageMaker Studio (tham khảo Sử dụng thiết lập nhanh cho Amazon SageMaker AI) để truy cập các sổ tay Jupyter với vai trò nói trên. (Bạn cũng có thể sử dụng JupyterLab trong môi trường cục bộ của mình.) Tạo một vai trò AWS Identity and Access Management (IAM) với các chính sách được quản lý là AmazonSageMakerFullAccess, AmazonS3FullAccess, và AmazonBedrockFullAccess để cấp quyền truy cập cần thiết cho SageMaker AI và Amazon Bedrock để chạy các ví dụ.\nGán mối quan hệ tin cậy sau đây cho vai trò IAM của bạn:\n{\r\u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;,\n\u0026ldquo;Statement\u0026rdquo;: [\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;,\n\u0026ldquo;Principal\u0026rdquo;: {\n\u0026ldquo;Service\u0026rdquo;: [\n\u0026ldquo;bedrock.amazonaws.com\u0026rdquo;,\n\u0026ldquo;sagemaker.amazonaws.com\u0026rdquo;\n]\n},\n\u0026ldquo;Action\u0026rdquo;: \u0026ldquo;sts:AssumeRole\u0026rdquo;\n}\n]\n}\nSao chép (Clone) kho lưu trữ GitHub với các tài sản cho việc triển khai này. Kho lưu trữ này bao gồm một sổ tay tham chiếu đến các tài sản huấn luyện: git clone https://github.com/aws-samples/amazon-nova-samples.git\ncd customization/SageMakerTrainingJobs/Amazon-Nova-LLM-As-A-Judge/\n4. Tiếp theo, chạy sổ tay Nova Amazon-Nova-LLM-as-a-Judge-Sagemaker-AI.ipynb để bắt đầu sử dụng việc triển khai Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI.\nThiết lập mô hình Để tiến hành một cuộc đánh giá Amazon Nova LLM-as-a-Judge, bạn cần tạo ra các kết quả đầu ra từ các mô hình ứng viên mà bạn muốn so sánh. Trong dự án này, chúng tôi đã sử dụng hai phương pháp khác nhau: triển khai mô hình Qwen2.5 1.5B trên Amazon SageMaker và gọi mô hình Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock. Đầu tiên, chúng tôi đã triển khai Qwen2.5 1.5B, một mô hình ngôn ngữ đa ngôn ngữ có trọng số mở, trên một điểm cuối (endpoint) SageMaker chuyên dụng. Điều này được thực hiện bằng cách sử dụng giao diện triển khai HuggingFaceModel. Để triển khai mô hình Qwen2.5 1.5B, chúng tôi đã cung cấp một tập lệnh tiện lợi để bạn gọi: python3 deploy_sm_model.py\nKhi đã được triển khai, việc suy luận có thể được thực hiện bằng một hàm trợ giúp bao bọc API dự đoán của SageMaker:\n# Khởi tạo predictor một lần\npredictor = HuggingFacePredictor(endpoint_name=\u0026ldquo;qwen25-\u0026lt;endpoint_name_here\u0026gt;\u0026rdquo;)\ndef generate_with_qwen25(prompt: str, max_tokens: int = 500, temperature: float = 0.9) -\u0026gt; str:\n\u0026quot;\u0026quot;\u0026quot;\nGửi một câu lệnh đến mô hình Qwen2.5 đã triển khai trên SageMaker và trả về phản hồi được tạo ra.\nArgs:\nprompt (str): Câu lệnh/câu hỏi đầu vào để gửi đến mô hình.\nmax_tokens (int): Số lượng token tối đa để tạo ra.\ntemperature (float): Nhiệt độ lấy mẫu cho việc tạo ra.\nReturns:\nstr: Văn bản do mô hình tạo ra.\n\u0026quot;\u0026quot;\u0026quot;\nresponse = predictor.predict({\n\u0026ldquo;inputs\u0026rdquo;: prompt,\n\u0026ldquo;parameters\u0026rdquo;: {\n\u0026ldquo;max_new_tokens\u0026rdquo;: max_tokens,\n\u0026ldquo;temperature\u0026rdquo;: temperature\n}\n})\nreturn response[0][\u0026ldquo;generated_text\u0026rdquo;]\nanswer = generate_with_qwen25(\u0026ldquo;What is the Grotto at Notre Dame?\u0026rdquo;)\nprint(answer)\nSong song đó, chúng tôi đã tích hợp mô hình Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock. Amazon Bedrock cung cấp một lớp API được quản lý để truy cập các mô hình nền tảng (FM) độc quyền mà không cần quản lý cơ sở hạ tầng. Hàm tạo của Claude đã sử dụng client bedrock-runtime của AWS SDK for Python (Boto3), nhận một câu lệnh từ người dùng và trả về phần hoàn thành văn bản của mô hình:\n# Khởi tạo client Bedrock một lần\nbedrock = boto3.client(\u0026ldquo;bedrock-runtime\u0026rdquo;, region_name=\u0026ldquo;us-east-1\u0026rdquo;)\n# ID mô hình (Claude 3.7 Sonnet) thông qua Bedrock\nMODEL_ID = \u0026ldquo;us.anthropic.claude-3-7-sonnet-20250219-v1:0\u0026rdquo;\ndef generate_with_claude4(prompt: str, max_tokens: int = 512, temperature: float = 0.7, top_p: float = 0.9) -\u0026gt; str:\n\u0026quot;\u0026quot;\u0026quot;\nGửi một câu lệnh đến mô hình Claude 4-tier qua Amazon Bedrock và trả về phản hồi được tạo ra.\nArgs:\nprompt (str): Tin nhắn người dùng hoặc câu lệnh đầu vào.\nmax_tokens (int): Số lượng token tối đa để tạo ra.\ntemperature (float): Nhiệt độ lấy mẫu cho việc tạo ra.\ntop_p (float): Lấy mẫu hạt nhân top-p.\nReturns:\nstr: Nội dung văn bản do Claude tạo ra.\n\u0026quot;\u0026quot;\u0026quot;\npayload = {\n\u0026ldquo;anthropic_version\u0026rdquo;: \u0026ldquo;bedrock-2023-05-31\u0026rdquo;,\n\u0026ldquo;messages\u0026rdquo;: [{\u0026ldquo;role\u0026rdquo;: \u0026ldquo;user\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: prompt}],\n\u0026ldquo;max_tokens\u0026rdquo;: max_tokens,\n\u0026ldquo;temperature\u0026rdquo;: temperature,\n\u0026ldquo;top_p\u0026rdquo;: top_p\n}\nresponse = bedrock.invoke_model(\nmodelId=MODEL_ID,\nbody=json.dumps(payload),\ncontentType=\u0026ldquo;application/json\u0026rdquo;,\naccept=\u0026ldquo;application/json\u0026rdquo;\n)\nresponse_body = json.loads(response[\u0026lsquo;body\u0026rsquo;].read())\nreturn response_body[\u0026ldquo;content\u0026rdquo;][0][\u0026ldquo;text\u0026rdquo;]\nanswer = generate_with_claude4(\u0026ldquo;What is the Grotto at Notre Dame?\u0026rdquo;)\nprint(answer)\nKhi bạn đã tạo và kiểm tra cả hai hàm, bạn có thể chuyển sang tạo dữ liệu đánh giá cho Nova LLM-as-a-Judge.\nChuẩn bị bộ dữ liệu Để tạo một bộ dữ liệu đánh giá thực tế nhằm so sánh các mô hình Qwen và Claude, chúng tôi đã sử dụng Bộ dữ liệu Trả lời câu hỏi Stanford (SQuAD), một bộ tiêu chuẩn được áp dụng rộng rãi trong lĩnh vực hiểu ngôn ngữ tự nhiên được phân phối theo giấy phép CC BY-SA 4.0. SQuAD bao gồm hàng ngàn cặp câu hỏi-trả lời được đóng góp từ cộng đồng, bao trùm một loạt các bài viết trên Wikipedia. Bằng cách lấy mẫu từ bộ dữ liệu này, chúng tôi đảm bảo rằng các câu lệnh đánh giá của mình phản ánh các tác vụ trả lời câu hỏi thực tế, chất lượng cao, đại diện cho các ứng dụng trong thế giới thực.\nChúng tôi bắt đầu bằng cách tải một tập hợp con nhỏ các ví dụ để giữ cho quy trình công việc nhanh chóng và có thể tái tạo. Cụ thể, chúng tôi đã sử dụng thư viện datasets của Hugging Face để tải xuống và tải 20 ví dụ đầu tiên từ phần huấn luyện của SQuAD:\nfrom datasets import load_dataset\nsquad = load_dataset(\u0026ldquo;squad\u0026rdquo;, split=\u0026ldquo;train[:20]\u0026rdquo;)\nLệnh này truy xuất một lát cắt của bộ dữ liệu đầy đủ, chứa 20 mục với các trường có cấu trúc bao gồm ngữ cảnh, câu hỏi, và câu trả lời. Để xác minh nội dung và kiểm tra một ví dụ, chúng tôi đã in ra một câu hỏi mẫu và câu trả lời đúng của nó:\nprint(squad[3][\u0026ldquo;question\u0026rdquo;])\nprint(squad[3][\u0026ldquo;answers\u0026rdquo;][\u0026ldquo;text\u0026rdquo;][0])\nĐối với bộ đánh giá, chúng tôi đã chọn sáu câu hỏi đầu tiên từ tập hợp con này:\nquestions = [squad[i][\u0026ldquo;question\u0026rdquo;] for i in range(6)]\nTạo bộ dữ liệu đánh giá Amazon Nova LLM-as-a-Judge Sau khi chuẩn bị một bộ câu hỏi đánh giá từ SQuAD, chúng tôi đã tạo ra các kết quả đầu ra từ cả hai mô hình và tập hợp chúng vào một bộ dữ liệu có cấu trúc để được sử dụng bởi quy trình công việc Amazon Nova LLM-as-a-Judge. Bộ dữ liệu này đóng vai trò là đầu vào cốt lõi cho các công thức đánh giá của SageMaker AI. Để làm điều này, chúng tôi lặp qua từng câu lệnh hỏi và gọi hai hàm tạo đã được xác định trước đó:\ngenerate_with_qwen25() cho các phần hoàn thành từ mô hình Qwen2.5 được triển khai trên SageMaker generate_with_claude() cho các phần hoàn thành từ Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock Đối với mỗi câu lệnh, quy trình công việc đã cố gắng tạo ra một phản hồi từ mỗi mô hình. Nếu một lệnh gọi tạo phản hồi thất bại do lỗi API, hết thời gian chờ, hoặc vấn đề khác, hệ thống đã bắt ngoại lệ và lưu trữ một thông báo lỗi rõ ràng cho biết sự thất bại. Điều này đảm bảo rằng quá trình đánh giá có thể tiến hành một cách trơn tru ngay cả khi có lỗi tạm thời:\nimport json\noutput_path = \u0026ldquo;llm_judge.jsonl\u0026rdquo;\nwith open(output_path, \u0026ldquo;w\u0026rdquo;) as f:\nfor q in questions:\ntry:\nresponse_a = generate_with_qwen25(q)\nexcept Exception as e:\nresponse_a = f\u0026quot;[Qwen2.5 generation failed: {e}]\u0026quot;\ntry: response\\_b \\= generate\\_with\\_claude4(q) except Exception as e: response\\_b \\= f\u0026quot;\\[Claude 3.7 generation failed: {e}\\]\u0026quot; row \\= { \u0026quot;prompt\u0026quot;: q, \u0026quot;response\\_A\u0026quot;: response\\_a, \u0026quot;response\\_B\u0026quot;: response\\_b } f.write(json.dumps(row) \\+ \u0026quot;\\\\n\u0026quot;) print(f\u0026quot;JSONL file created at: {output_path}\u0026quot;)\nQuy trình công việc này đã tạo ra một tệp JSON Lines có tên là llm_judge.jsonl. Mỗi dòng chứa một bản ghi đánh giá duy nhất được cấu trúc như sau:\n{\n\u0026ldquo;prompt\u0026rdquo;: \u0026ldquo;What is the capital of France?\u0026rdquo;,\n\u0026ldquo;response_A\u0026rdquo;: \u0026ldquo;The capital of France is Paris.\u0026rdquo;,\n\u0026ldquo;response_B\u0026rdquo;: \u0026ldquo;Paris is the capital city of France.\u0026rdquo;\n}\nSau đó, tải tệp llm_judge.jsonl này lên một bucket S3 mà bạn đã xác định trước:\nupload_to_s3(\n\u0026ldquo;llm_judge.jsonl\u0026rdquo;,\n\u0026ldquo;s3://\u0026lt;YOUR_BUCKET_NAME\u0026gt;/datasets/byo-datasets-dev/custom-llm-judge/llm_judge.jsonl\u0026rdquo;\n)\nKhởi chạy công việc đánh giá Nova LLM-as-a-Judge Sau khi chuẩn bị bộ dữ liệu và tạo công thức đánh giá, bước cuối cùng là khởi chạy công việc huấn luyện SageMaker thực hiện việc đánh giá Amazon Nova LLM-as-a-Judge. Trong quy trình công việc này, công việc huấn luyện hoạt động như một quy trình tự khép kín, được quản lý toàn phần, tải mô hình, xử lý bộ dữ liệu, và tạo ra các chỉ số đánh giá tại vị trí Amazon S3 được chỉ định của bạn.\nChúng tôi sử dụng lớp trình ước tính PyTorch từ SageMaker Python SDK để đóng gói cấu hình cho lần chạy đánh giá. Trình ước tính xác định các tài nguyên tính toán, hình ảnh container, công thức đánh giá, và các đường dẫn đầu ra để lưu trữ kết quả:\nestimator = PyTorch(\noutput_path=output_s3_uri,\nbase_job_name=job_name,\nrole=role,\ninstance_type=instance_type,\ntraining_recipe=recipe_path,\nsagemaker_session=sagemaker_session,\nimage_uri=image_uri,\ndisable_profiler=True,\ndebugger_hook_config=False,\n)\nKhi trình ước tính được cấu hình, bạn khởi tạo công việc đánh giá bằng phương thức fit(). Lệnh gọi này gửi công việc đến mặt phẳng điều khiển của SageMaker, cung cấp cụm máy tính, và bắt đầu xử lý bộ dữ liệu đánh giá:\nestimator.fit(inputs={\u0026ldquo;train\u0026rdquo;: evalInput})\nKết quả từ công việc đánh giá Amazon Nova LLM-as-a-Judge Đồ họa sau đây minh họa kết quả của công việc đánh giá Amazon Nova LLM-as-a-Judge.\nĐể giúp các chuyên gia nhanh chóng diễn giải kết quả của một cuộc đánh giá Nova LLM-as-a-Judge, chúng tôi đã tạo ra một hàm tiện ích sản xuất một hình ảnh trực quan duy nhất, toàn diện, tóm tắt các chỉ số chính. Hàm này, plot_nova_judge_results, sử dụng Matplotlib và Seaborn để hiển thị một hình ảnh với sáu bảng, mỗi bảng làm nổi bật một khía cạnh khác nhau của kết quả đánh giá.\nHàm này nhận vào từ điển chỉ số đánh giá—được tạo ra khi công việc đánh giá hoàn tất—và tạo ra các thành phần trực quan sau:\nBiểu đồ cột phân phối điểm – Cho thấy Mô hình A được ưa thích bao nhiêu lần, Mô hình B được ưa thích bao nhiêu lần, có bao nhiêu trường hợp hòa, và tần suất giám khảo không đưa ra được quyết định (lỗi suy luận). Điều này cung cấp một cảm nhận tức thì về mức độ quyết đoán của cuộc đánh giá và liệu có mô hình nào đang chiếm ưu thế hay không. Tỷ lệ thắng với khoảng tin cậy 95% – Vẽ biểu đồ tỷ lệ thắng tổng thể của Mô hình B so với Mô hình A, bao gồm một thanh lỗi phản ánh các giới hạn dưới và trên của khoảng tin cậy 95%. Một đường tham chiếu dọc tại 50% đánh dấu điểm không có sự ưu tiên. Nếu khoảng tin cậy không cắt qua đường này, bạn có thể kết luận rằng kết quả có ý nghĩa thống kê. Biểu đồ tròn về sở thích – Hiển thị trực quan tỷ lệ số lần Mô hình A, Mô hình B, hoặc không mô hình nào được ưa thích. Điều này giúp nhanh chóng hiểu được sự phân phối ưu tiên trong số các phán đoán hợp lệ. Biểu đồ cột so sánh điểm số của A và B – So sánh số lượng ưu tiên thô cho mỗi mô hình cạnh nhau. Một nhãn rõ ràng chú thích biên độ chênh lệch để nhấn mạnh mô hình nào có nhiều chiến thắng hơn. Đồng hồ đo tỷ lệ thắng – Mô tả tỷ lệ thắng dưới dạng một đồng hồ đo hình bán nguyệt với một kim chỉ vào hiệu suất của Mô hình B so với phạm vi lý thuyết 0–100%. Hình ảnh trực quan này giúp các bên liên quan không chuyên về kỹ thuật hiểu được tỷ lệ thắng trong nháy mắt. Bảng thống kê tóm tắt – Tổng hợp các chỉ số số học—bao gồm tổng số lần đánh giá, số lỗi, tỷ lệ thắng, và khoảng tin cậy—vào một bảng nhỏ gọn, sạch sẽ. Điều này giúp dễ dàng tham chiếu các giá trị số chính xác đằng sau các biểu đồ. Vì hàm này xuất ra một hình ảnh Matplotlib tiêu chuẩn, bạn có thể nhanh chóng lưu hình ảnh, hiển thị nó trong các sổ tay Jupyter, hoặc nhúng nó vào các tài liệu khác.\nDọn dẹp Hoàn thành các bước sau để dọn dẹp tài nguyên của bạn:\nXóa Điểm cuối (Endpoint) Qwen 2.5 1.5B của bạn\nimport boto3\n# Tạo một client dịch vụ SageMaker cấp thấp.\nsagemaker_client = boto3.client(\u0026lsquo;sagemaker\u0026rsquo;, region_name=\u0026lt;region\u0026gt;)\n# Xóa điểm cuối\nsagemaker_client.delete_endpoint(EndpointName=endpoint_name)\nNếu bạn đang sử dụng một sổ tay JupyterLab của SageMaker Studio, hãy tắt phiên bản sổ tay JupyterLab. Làm thế nào bạn có thể sử dụng khung đánh giá này Quy trình công việc Amazon Nova LLM-as-a-Judge cung cấp một cách thức đáng tin cậy, có thể lặp lại để so sánh hai mô hình ngôn ngữ trên dữ liệu của riêng bạn. Bạn có thể tích hợp điều này vào các quy trình lựa chọn mô hình để quyết định phiên bản nào hoạt động tốt nhất, hoặc bạn có thể lên lịch nó như một phần của việc đánh giá liên tục để phát hiện sự suy giảm hiệu suất theo thời gian.\nĐối với các đội ngũ xây dựng các hệ thống có tính tác tử hoặc chuyên biệt theo lĩnh vực, phương pháp này cung cấp cái nhìn sâu sắc hơn so với chỉ riêng các chỉ số tự động. Bởi vì toàn bộ quy trình chạy trên các công việc huấn luyện của SageMaker, nó có thể mở rộng nhanh chóng và tạo ra các báo cáo trực quan rõ ràng có thể được chia sẻ với các bên liên quan.\nKết luận Bài đăng này trình bày cách Nova LLM-as-a-Judge—một mô hình đánh giá chuyên biệt có sẵn thông qua Amazon SageMaker AI—có thể được sử dụng để đo lường một cách có hệ thống hiệu suất tương đối của các hệ thống AI tạo sinh. Hướng dẫn này chỉ ra cách chuẩn bị các bộ dữ liệu đánh giá, khởi chạy các công việc huấn luyện SageMaker AI với các công thức Nova LLM-as-a-Judge, và diễn giải các chỉ số kết quả, bao gồm tỷ lệ thắng và phân phối ưu tiên. Giải pháp SageMaker AI được quản lý toàn phần giúp đơn giản hóa quy trình này, để bạn có thể chạy các cuộc đánh giá mô hình có thể mở rộng, lặp lại và phù hợp với sở thích của con người.\nChúng tôi khuyến nghị bạn bắt đầu hành trình đánh giá LLM của mình bằng cách khám phá tài liệu và các ví dụ chính thức của Amazon Nova. Cộng đồng AWS AI/ML cung cấp các tài nguyên phong phú, bao gồm các hội thảo và hướng dẫn kỹ thuật, để hỗ trợ hành trình triển khai của bạn.\nĐể tìm hiểu thêm, hãy truy cập:\nTài liệu Amazon Nova Tổng quan về Amazon Bedrock Nova Tinh chỉnh các mô hình Amazon Nova Hướng dẫn tùy chỉnh Amazon Nova Về các tác giả Surya Kari là một Nhà khoa học dữ liệu AI tạo sinh cấp cao tại AWS, chuyên phát triển các giải pháp tận dụng các mô hình nền tảng tiên tiến. Anh có kinh nghiệm sâu rộng làm việc với các mô hình ngôn ngữ tiên tiến bao gồm DeepSeek-R1, họ Llama, và Qwen, tập trung vào việc tinh chỉnh và tối ưu hóa chúng. Chuyên môn của anh mở rộng đến việc triển khai các quy trình huấn luyện hiệu quả và các chiến lược triển khai bằng AWS SageMaker. Anh hợp tác với khách hàng để thiết kế và triển khai các giải pháp AI tạo sinh, giúp họ điều hướng việc lựa chọn mô hình, các phương pháp tinh chỉnh, và các chiến lược triển khai để đạt được hiệu suất tối ưu cho các trường hợp sử dụng cụ thể của họ.\nJoel Carlson là một Nhà khoa học ứng dụng cấp cao trong đội ngũ mô hình hóa nền tảng Amazon AGI. Anh chủ yếu làm việc về việc phát triển các phương pháp mới để cải thiện khả năng LLM-as-a-Judge của họ mô hình Nova.\nSaurabh Sahu là một nhà khoa học ứng dụng trong đội ngũ mô hình hóa Nền tảng Amazon AGI. Anh nhận bằng Tiến sĩ Kỹ thuật Điện từ Đại học Maryland College Park vào năm 2019. Anh có nền tảng về học máy đa phương thức, làm việc về nhận dạng giọng nói, phân tích tình cảm và hiểu âm thanh/video. Hiện tại, công việc của anh tập trung vào việc phát triển các công thức để cải thiện hiệu suất của các mô hình LLM-as-a-judge cho các tác vụ khác nhau.\nMorteza Ziyadi là một Quản lý Khoa học Ứng dụng tại Amazon AGI, nơi anh lãnh đạo nhiều dự án về các công thức sau huấn luyện và các mô hình ngôn ngữ lớn (Đa phương thức) trong đội ngũ mô hình hóa Nền tảng Amazon AGI. Trước khi gia nhập Amazon AGI, anh đã có bốn năm làm việc tại Microsoft Cloud và AI, nơi anh lãnh đạo các dự án tập trung vào việc phát triển các mô hình tạo mã từ ngôn ngữ tự nhiên cho các sản phẩm khác nhau. Anh cũng đã từng là giảng viên thỉnh giảng tại Đại học Northeastern. Anh nhận bằng Tiến sĩ từ Đại học Nam California (USC) vào năm 2017 và từ đó đã tích cực tham gia với tư cách là người tổ chức hội thảo và người phản biện cho nhiều hội nghị NLP, Thị giác máy tính và học máy.\nPradeep Natarajan là một Nhà khoa học chính cấp cao trong đội ngũ mô hình hóa Nền tảng Amazon AGI, làm việc về các công thức sau huấn luyện và các mô hình ngôn ngữ lớn Đa phương thức. Anh có hơn 20 năm kinh nghiệm trong việc phát triển và ra mắt nhiều hệ thống học máy quy mô lớn. Anh có bằng Tiến sĩ Khoa học Máy tính từ Đại học Nam California.\nMichael Cai là một Kỹ sư phần mềm trong Đội ngũ Tùy chỉnh Amazon AGI, hỗ trợ việc phát triển các giải pháp đánh giá. Anh nhận bằng Thạc sĩ Khoa học Máy tính từ Đại học New York vào năm 2024. Trong thời gian rảnh, anh thích in 3D và khám phá công nghệ đổi mới.\n"
},
{
	"uri": "//localhost:1313/vi/2-proposal/",
	"title": "Đề Xuất",
	"tags": [],
	"description": "",
	"content": "AWS First Cloud AI Journey – Kế Hoạch Dự Án [Project team] – [University] – [Project Name]\n[Date]\nMục Lục BACKGROUND và MOTIVATION\n1.1 Executive Summary 1.2 Project Success Criteria 1.3 Assumptions SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM\n2.1 Technical Architecture Diagram 2.2 Technical Plan 2.3 Project Plan 2.4 Security Considerations Activities AND Deliverables\n3.1 Activities and deliverables 3.2 Out of Scope 3.3 Path to Production EXPECTED AWS COST BREAKDOWN BY SERVICES\nTEAM\nRESOURCES \u0026amp; COST ESTIMATES\nACCEPTANCE\nBACKGROUND AND MOTIVATION 1.1 Executive Summary Tổ chức đối mặt với các vấn đề về hiệu quả đánh giá nhân sự do xử lý dữ liệu thủ công, thiếu tính minh bạch trong các quy trình đánh giá và theo dõi chỉ số.\nInsightHR cung cấp tự động hóa HR thông qua quản lý đánh giá linh hoạt, tính điểm tự động và AI insights. AWS cung cấp khả năng mở rộng serverless, hiệu quả chi phí, bảo mật cho dữ liệu nhạy cảm, AI Chatbot thông qua Bedrock và triển khai nhanh chóng.\nCustom KPI, tính điểm hiệu suất tự động, bảng điều khiển đa cấp, trợ lý AI cho truy vấn ngôn ngữ tự nhiên, thông báo tự động, quyền truy cập dựa trên vai trò (Admin/Manager/Employee), hỗ trợ đa thuê.\nCung cấp toàn diện bao gồm thiết kế Well-Architected, backend serverless (Lambda, DynamoDB, API Gateway), frontend (S3 + CloudFront), xác thực/bảo mật (Cognito, IAM), KPI/formula builder, chatbot AI (Bedrock + Lambda truy vấn dữ liệu từ bảng thông tin), thông báo (SNS, SES), CI/CD, giám sát và chuyển giao kiến thức.\n1.2 Project Success Criteria Thành công được định nghĩa bằng việc chứng minh một MVP chức năng chứng tỏ khả năng của nền tảng tự động hóa các đánh giá HR và cung cấp giá trị kinh doanh có thể đo lường được.\n1. Functional Criteria:\nXác thực với quyền truy cập dựa trên vai trò (Admin/HR, Manager, Employee) HR tạo KPIs tùy chỉnh mà không cần hỗ trợ kỹ thuật Tải lên CSV kích hoạt tính điểm Lambda tự động Bảng điều khiển hiển thị hiệu suất cá nhân/nhóm với biểu đồ Chatbot AI trả lời các truy vấn ngôn ngữ tự nhiên từ dữ liệu DynamoDB SES gửi thông báo email tự động 2. Technical Criteria:\n99.9%+ uptime \u0026lt;300ms API latency (95th percentile) 95%+ scoring accuracy vs tính toán thủ công 90%+ AI response relevance Zero critical security vulnerabilities 3. Performance \u0026amp; Cost:\n~$33.14/month AWS cost End-to-end workflow (tải lên → điểm → hình dung) hoàn tất trong \u0026lt;5 phút 4. Business Impact:\nChứng minh khả năng giảm thời gian HR 60%+ Người dùng không kỹ thuật vận hành KPI builder và chatbot độc lập 5. Delivery:\nWeek 8: MVP (xác thực, quản lý KPI/công thức, tính điểm, bảng điều khiển cơ bản) Week 12: Tính năng đầy đủ (chatbot, thông báo, bảng điều khiển nâng cao) 1.3 Assumptions 1. Assumptions:\nƯớc tính chi phí AWS hiện tại khoảng $33.14/tháng là chính xác cho tải và sử dụng ban đầu được dự báo. Định dạng dữ liệu cần thiết và logic ánh xạ cho dữ liệu hiệu suất nhân viên có thể được định rõ ràng và do Nhóm HR cung cấp cho engine tính điểm tự động. Large Language Model được cung cấp bởi Amazon Bedrock hỗ trợ HR. Hệ thống tính điểm tự động được huấn luyện cục bộ. Các tệp đánh giá kỹ thuật của mỗi nhóm được đánh giá theo tiêu chí của công ty và phải tuân theo định dạng do khách hàng cung cấp. 2. Constraints:\nViệc cung cấp dự án phải tuân thủ lịch trình 12 tuần sử dụng framework Agile Scrum. Giải pháp phải được xây dựng hoàn toàn trên các dịch vụ AWS serverless để đáp ứng các mục tiêu về khả năng mở rộng, hiệu quả chi phí và giảm chi phí hoạt động. Chi phí AWS sản xuất cuối cùng phải ở mức ~$33.14/tháng. 3. Risks:\nData Security/Compliance: Không thể hiểu đầy đủ hoặc triển khai tất cả các yêu cầu xác nhận kiểm soát quy định cụ thể của khách hàng có thể ảnh hưởng đến khả năng của dự án đáp ứng các mục tiêu bảo mật. Feature Creep: Yêu cầu các tính năng được xác định là \u0026ldquo;Out of Scope\u0026rdquo; có thể làm trật khỏi lịch trình cung cấp MVP 12 tuần. SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM 2.1 Technical Architecture Diagram Nền tảng InsightHR được xây dựng trên kiến trúc serverless sử dụng các dịch vụ AWS, cung cấp khả năng mở rộng, hiệu quả chi phí và tính khả dụng cao. Kiến trúc bao gồm:\n1. Frontend \u0026amp; Content Delivery:\nAmazon S3: Lưu trữ trang web tĩnh và lưu trữ các tệp do người dùng tải lên (CSV, mô hình AI). S3 Vector để lưu trữ vector (embeddings cho dữ liệu văn bản), S3 Standard để lưu trữ các tài liệu thô. Amazon CloudFront: Phân phối nội dung tĩnh và động trên toàn cầu với độ trễ thấp. 2. Backend \u0026amp; Compute:\nAWS Lambda: Thực thi tất cả logic kinh doanh, bao gồm xác thực, tính điểm tùy chỉnh và chức năng chatbot. Amazon API Gateway: Quản lý API làm cổng giao tiếp giữa frontend và backend. 3. Data Storage:\nAmazon DynamoDB: Lưu trữ dữ liệu có cấu trúc như thông tin người dùng/nhân viên, KPI công ty, công thức tính điểm và kết quả đánh giá hiệu suất. 4. AI \u0026amp; Machine Learning:\nAmazon Bedrock: Cung cấp Large Language Models (LLMs) cho chatbot trợ lý HR. The ML Model system is trained locally for scoring function. 5. Security \u0026amp; Identity:\nAmazon Cognito: Quản lý xác thực người dùng, đăng ký và quy trình xác định danh tính. AWS IAM: Quản lý kiểm soát truy cập và quyền cho các dịch vụ AWS. AWS KMS: Mã hóa dữ liệu nhạy cảm trong DynamoDB và S3. 6. Monitoring \u0026amp; Notifications:\nAmazon CloudWatch \u0026amp; CloudWatch Logs: Giám sát các hàm Lambda, API Gateway và quyền truy cập cơ sở dữ liệu. Amazon SNS: Gửi thông báo (ví dụ: nhắc nhở, thông báo kết quả) cho nhân viên. 7. Architecture Benefits:\nServerless: Không quản lý máy chủ và tự động mở rộng. Cost-Effective: Hầu hết các dịch vụ theo kiểu trả tiền khi sử dụng. High Availability: Dự phòng tích hợp trên các vùng AWS. Scalable: Có thể xử lý tăng trưởng từ các nhóm nhỏ đến các doanh nghiệp lớn. Flexible: Dễ dàng sửa đổi và mở rộng chức năng. 8. Proposed Architecture Diagram:\n9. Tools Proposed for This Project:\nAmazon CloudFront: Để phân phối nội dung toàn cầu và lưu trữ nội dung web tĩnh và động. Amazon S3: Để lưu trữ tài sản web tĩnh và lưu trữ tài liệu, embeddings vector và các tệp khác được xử lý bởi hệ thống. Amazon API Gateway: Để cung cấp giao diện RESTful an toàn, hoạt động như lớp giao tiếp giữa các máy khách frontend và các dịch vụ backend. AWS Lambda: Để chạy logic kinh doanh backend bao gồm bảng điều khiển người dùng, tính điểm tự động, trợ lý HR và quy trình quản lý dữ liệu. Amazon DynamoDB: Để lưu trữ dữ liệu ứng dụng như thông tin người dùng, hồ sơ HR, kết quả tính điểm và siêu dữ liệu vector với hiệu suất độ trễ thấp. Amazon Cognito: Để quản lý xác thực người dùng, ủy quyền, đăng ký, MFA và truy cập an toàn vào API và các ứng dụng frontend. AWS Identity and Access Management (IAM): Để xác định các chính sách truy cập chi tiết và kiểm soát quyền giữa các dịch vụ và người dùng. AWS Key Management Service (KMS): Để quản lý các khóa mã hóa được sử dụng để bảo mật dữ liệu nhạy cảm được lưu trữ trong S3, DynamoDB và nhật ký. Amazon ECR: Để lưu trữ các tài sản mô hình container hóa và phụ thuộc ứng dụng trong kho lưu trữ an toàn và có kiểm soát phiên bản. Amazon Bedrock / Large Language Model (LLM): Để cung cấp các khả năng AI cho trò chuyện, trích xuất dữ liệu, tóm tắt và quy trình làm việc HR thông minh. Amazon Simple Email Service (SES): Để gửi thông báo email tự động như cảnh báo onboarding và giao tiếp HR. Amazon Simple Notification Service (SNS): Để xuất bản thông báo và kích hoạt các quy trình hạ lưu; tích hợp với email, SMS và microservices. Amazon CloudWatch \u0026amp; CloudWatch Logs: Để giám sát hiệu suất, ghi nhật ký, theo dõi và khắc phục sự cố hoạt động trên Lambda, API Gateway và các thành phần AI. 2.2 Technical Plan Đối tác sẽ phát triển các tập lệnh triển khai tự động bằng AWS CloudFormation và các quy trình IaC (Infrastructure as Code).\nĐiều này sẽ cho phép triển khai nhanh chóng và có thể lặp lại vào các tài khoản AWS. Một số cấu hình bổ sung như quy tắc WAF trên CloudFront để tăng cường bảo mật có thể yêu cầu phê duyệt và sẽ tuân theo các quy trình quản lý thay đổi DevOps tiêu chuẩn.\nApplication Feature Implementation:\n1. Authentication \u0026amp; Security Module\nUser Management: Cognito quản lý vòng đời người dùng Đăng ký, đăng nhập, quy trình đặt lại mật khẩu Access Control: IAM và RBAC thực thi các quyền dựa trên vai trò Admin/HR, Manager, Employee access levels API Security: API Gateway triển khai các endpoint được bảo vệ JWT Xác thực mã thông báo trước khi xử lý Lambda 2. Administration Module (HR Panel)\nKPI Management: HR tạo, chỉnh sửa và xóa các số liệu tùy chỉnh Ví dụ: Công việc đã hoàn thành, Chất lượng mã, Sự hài lòng của khách hàng Các định nghĩa được lưu trữ trong DynamoDB Auto scoring by employee\u0026rsquo;s technical score for each team with ML model. 3. Core User Functions\nData Upload \u0026amp; Mapping: Tải lên các tệp dữ liệu hiệu suất (CSV) vào DynamoDB Scoring Engine: Lambda được kích hoạt khi tải lên Lấy công thức hoạt động từ DynamoDB Tính điểm nhân viên Lưu trữ kết quả trong DynamoDB Flow: Tải lên → Xác thực → Ánh xạ → Tính toán → Lưu trữ Dashboard: Hình dung hiệu suất cá nhân và bộ phận Biểu đồ dòng, biểu đồ thanh, phân tích xu hướng AI Chatbot: Tích hợp Bedrock (LLM) Truy vấn ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;Tóm tắt hiệu suất Q4 của Nhóm A\u0026rdquo;) Truy vấn và tóm tắt dữ liệu DynamoDB Notifications: SES gửi cảnh báo tự động Các mốc hiệu suất, nhắc nhở xem xét, các kích hoạt tùy chỉnh 2.3 Project Plan Đối tác sẽ áp dụng framework Agile Scrum trong 12 sprint một tuần tạo thành lịch trình cung cấp 12 tuần.\n1. Team Responsibilities\nProduct Owner: Ưu tiên backlog (KPIs, công thức, phân tích) Thẩm quyền cuối cùng về chấp nhận tính năng Development Team: Triển khai xác thực Cognito Xây dựng cổng thông tin quản trị và trình xây dựng công thức Phát triển engine tính điểm và bảng điều khiển Tích hợp chatbot Bedrock và SNS với thông báo SES qua Email. QA Personnel: Tiến hành kiểm tra chức năng, hiệu suất và bảo mật Hỗ trợ UAT Đảm bảo tuân thủ và tiêu chuẩn chất lượng 2. Communication Cadences\nDaily Standups (30 phút - 1 giờ): Xem xét tiến độ và xác định rào cản Retrospectives (Hàng tuần, 1 giờ): Cải thiện quy trình và tối ưu hóa cung cấp Executive Updates (Hàng tuần): Báo cáo bằng văn bản về tiến độ, rủi ro, KPIs, lộ trình Các quyết định lãnh đạo được yêu cầu 3. Knowledge Transfer\nCác phiên do nhóm phát triển thực hiện bao gồm kiến thức cơ bản về serverless AWS Cấu hình KPI và công thức Quy trình dữ liệu và ánh xạ cột Điều hướng bảng điều khiển và phân tích Giám sát hệ thống (CloudWatch, Cognito, DynamoDB) 2.4 Security Considerations Đối tác sẽ triển khai các phương pháp bảo mật AWS tốt nhất dựa trên Well-Architected Framework, ưu tiên bảo vệ dữ liệu HR nhạy cảm trong khi đảm bảo tính khả dụng hoạt động cao. Triển khai bảo mật bao gồm năm danh mục chính:\n1. Access Control\nCognito quản lý nhận dạng người dùng Thực thi các chính sách mật khẩu mạnh và hỗ trợ MFA IAM triển khai RBAC Admin/HR access Admin Panel và cấu hình KPI/Công thức Nhân viên chỉ xem dữ liệu hiệu suất của riêng họ API Gateway xác thực các mã thông báo JWT Các mã thông báo do Cognito cấp được xác minh trước khi xử lý Lambda 2. Infrastructure Security\nKiến trúc serverless giảm bề mặt tấn công Không cần vá OS hoặc máy chủ Các hàm Lambda giao tiếp thông qua các mạng AWS riêng tư Chỉ các endpoint cần thiết được tiếp xúc thông qua API Gateway 3. Data Protection\nKMS mã hóa dữ liệu khi chưa hoạt động DynamoDB và S3 được mã hóa Dữ liệu không thể sử dụng được mà không có các khóa giải mã TLS/SSL (HTTPS) mã hóa dữ liệu khi đang truyền Tất cả giao tiếp frontend-backend được bảo mật 4. Detection \u0026amp; Monitoring\nCloudWatch Logs ghi lại các chi tiết thực thi Hoạt động Lambda và API Gateway được ghi lại Giám sát thời gian thực và phát hiện bất thường được bật AWS Config theo dõi các thay đổi cấu hình Đảm bảo tuân thủ tài nguyên với các mục tiêu bảo mật 5. Incident Management\nCloudWatch Alarms kích hoạt cảnh báo tự động thông qua SES Lỗi vượt ngưỡng đăng nhập Bất thường tài nguyên Lambda Security Hub cung cấp chế độ xem bảo mật tập trung Các phát hiện tuân thủ thống nhất trên môi trường AWS Đơn giản hóa xác định sự cố và phản ứng AWS CloudTrail và AWS Config sẽ được định cấu hình để giám sát liên tục các hoạt động và trạng thái tuân thủ của các tài nguyên. Khách hàng sẽ chia sẻ các yêu cầu xác nhận kiểm soát quy định cụ thể của họ làm đầu vào để đối tác đảm bảo tất cả các mục tiêu bảo mật được đáp ứng.\nACTIVITIES AND DELIVERABLES 3.1 Activities and Deliverables NOTE: Some Project Phases overlap each other.\nProject Phase Timeline Activities Deliverables/Milestones Total man-day Phase 1: Foundation \u0026amp; Scoring Model Week 1-8 • Nghiên cứu kiến trúc cơ sở hạ tầng cá nhân • Tạo dữ liệu cho đào tạo mô hình cục bộ • Xây dựng mô hình tính điểm • Sơ đồ kiến trúc cá nhân hoàn thiện • Bộ dữ liệu sẵn sàng cho đào tạo Mô hình cục bộ • Scoring Model MVP (Minimum Viable Product) 80 Phase 2: Project Setup \u0026amp; Dashboard Week 9-10 • Thiết lập dự án với các chức năng cơ bản: IAM Role, CRUD function, Static web • Web UI Demo • Triển khai Dashboard • Sửa mô hình • Cấu hình IAM Roles cơ bản • Các hàm CRUD hoạt động • Trang web tĩnh được triển khai (S3/CloudFront) • Web UI Demo hoàn tất • Dashboard hiển thị dữ liệu được triển khai 40 Phase 3: AI Agent \u0026amp; Absence Mgmt Week 11 • Xây dựng Bedrock Agent • Triển khai quản lý Absence • Bedrock Agent được xây dựng • Quy trình theo dõi Absence hoạt động được triển khai 15 Phase 4: Integration, Testing \u0026amp; Handover Week 12 • Triển khai Chatbot vào Ứng dụng • Kiểm tra và thiết lập Giám sát • Chatbot được tích hợp vào ứng dụng • Kiểm tra chức năng, hiệu suất và bảo mật hoàn tất • Giám sát (CloudWatch) được cấu hình và hoạt động • Báo cáo Hoàn thành Dự án \u0026amp; Kế hoạch hỗ trợ sau triển khai được cung cấp 15 3.2 Out Of Scope 1. AI Enhancements\nAI-Powered Insights:\nKhi có đủ dữ liệu, phát triển các mô hình AI có khả năng: Chatbot truy cập cơ sở dữ liệu trực tiếp và truy xuất cửa sổ nhắc nhở -\u0026gt; Giá rất nhiều mã thông báo và khóa cao, trong tương lai có thể được tối ưu hóa bằng các cách khác Xác định các mẫu hiệu suất trên các nhóm và bộ phận Dự đoán rủi ro HR (ví dụ: khả năng rời khỏi, chỉ số kiệt sức) Đề xuất các kế hoạch phát triển được cá nhân hóa Phát hiện bất thường trong dữ liệu hiệu suất Đề xuất thành phần nhóm tối ưu Machine Learning Features:\nPhân tích dự đoán cho kế hoạch lực lượng lao động Phân tích cảm tính từ phản hồi của nhân viên Phân tích khoảng cách kỹ năng tự động Dự báo xu hướng hiệu suất 2. Public API Development\nAPI Ecosystem:\nXây dựng một bộ API toàn diện cho phép các hệ thống kinh doanh nội bộ khác tự động đẩy dữ liệu hiệu suất vào InsightHR. Integration Targets:\nCông cụ quản lý dự án (Jira, Asana, Monday.com) Hệ thống CRM (Salesforce, HubSpot) Phần mềm theo dõi thời gian (Toggl, Harvest) Nền tảng giao tiếp (Slack, Microsoft Teams) Kho lưu trữ mã (GitHub, GitLab, Bitbucket) Benefits:\nBiến InsightHR thành trung tâm xử lý dữ liệu HR tập trung Tạo hệ sinh thái quản lý đồng bộ và toàn diện Loại bỏ nhập dữ liệu thủ công Theo dõi hiệu suất theo thời gian thực 3. Advanced Features\nMobile Applications:\nỨng dụng iOS và Android gốc Thông báo đẩy Khả năng ngoại tuyến Bảo điểm điều khiển được tối ưu hóa cho di động Sao lưu DynamoDB Advanced Analytics:\nMô hình dự đoán Đánh giá kỹ năng so sánh trên toàn ngành Trình xây dựng báo cáo tùy chỉnh Xuất dữ liệu và API cho công cụ của bên thứ ba Collaboration Features:\nHệ thống đánh giá ngang hàng Phản hồi 360 độ Đặt mục tiêu và theo dõi Kế hoạch cải thiện hiệu suất Compliance \u0026amp; Governance:\nĐường dõi kiểm toán Báo cáo tuân thủ Chính sách giữ lại dữ liệu Kiểm soát truy cập nâng cao 3.3 Path To Production Tài liệu này mô tả kiến trúc sản xuất hiện tại và trạng thái hoạt động của việc triển khai nền tảng InsightHR. Nền tảng này đang hoạt động hoàn toàn ở vùng ap-southeast-1 (Singapore).\n1. Platform Architecture and Access\nPublic URL: https://insight-hr.io.vn AWS Region: ap-southeast-1 (Singapore) Frontend: Ứng dụng React được lưu trữ trên S3 (insighthr-web-app-sg) với phân phối HTTPS CloudFront. Backend: 8 nhóm hàm Lambda được truy cập thông qua API Gateway REST API. Database: DynamoDB tables được cấu hình với dung lượng On-Demand. 6 bảng cho mỗi nhóm Bảng thông tin nhân viên Bảng điểm lịch sử Bảng Absent Bảng quản lý tài khoản Authentication: Cognito User Pool. AI/Chatbot: Amazon Bedrock (Claude 3 Haiku) tích hợp cho lịch sử cuộc trò chuyện và cơ sở kiến thức để nâng cao mô hình. 2. Live Production Features\nCác tính năng chính sau đây đã được triển khai thành công và đang hoạt động:\nAuthentication: Hỗ trợ đầy đủ cho đăng nhập email/mật khẩu, quy trình đặt lại mật khẩu. User Management: Chức năng CRUD đầy đủ, bao gồm nhập hàng loạt và truy cập dựa trên vai trò. Employee Management: Hỗ trợ đầy đủ cho 300+ nhân viên và hoạt động hàng loạt. Performance Score Management: Quản lý 900+ điểm số theo quý và xem dựa trên lịch. Attendance Management: Xử lý 9,300+ bản ghi, bao gồm chức năng kiosk check-in/check-out và đánh dấu absence tự động. Performance Dashboard: Biểu đồ trực tiếp, phân tích xu hướng, đồng hồ trực tiếp và khả năng xuất CSV. AI Chatbot: Tích hợp Bedrock với lịch sử cuộc trò chuyện được bật. 3. Deployment and Verification Process\nQuy trình triển khai tiêu chuẩn và có thể lặp lại đảm bảo cập nhật nhanh chóng và có thể xác minh được:\nBuild: npm run build tạo bộ tài sản sản xuất được tối ưu hóa. Test: npm run preview xác thực bộ được xây dựng cục bộ trước khi triển khai. Deploy: aws s3 sync dist/ s3://insighthr-web-app-sg --region ap-southeast-1 đẩy tài sản vào nhóm S3. Invalidate: aws cloudfront create-invalidation --distribution-id E3MHW5VALWTOCI --paths \u0026quot;/*\u0026quot; xóa bộ đệm CDN CloudFront. Verify: Kiểm tra tính năng đầy đủ được thực hiện trên URL công khai trực tiếp. 4. Remaining Production Enhancements\nNền tảng này ở giai đoạn cuối cùng của việc nâng cao trước khi ổn định hoàn toàn, với các mục chính được lên kế hoạch hoặc đang tiến hành:\nPage Integration (In Progress)\nHợp nhất tất cả điều hướng trang quản trị. Xác minh tất cả các tính năng đều có thể truy cập từ menu chính. Kiểm tra định tuyến dựa trên vai trò trên tất cả các trang. Sửa các lỗi tích hợp. Polish and Final Deployment (Planned)\nTriển khai xử lý lỗi toàn diện và xác thực đầu vào. Tinh chỉnh thiết kế responsive để tương thích đầy đủ với di động. Tiến hành kiểm tra bảo mật chuyên dụng (thử nghiệm xâm nhập, quét lỗ hổng). Thực thi kiểm tra tải để xác thực khả năng mở rộng. Phát triển tài liệu người dùng và tài liệu đào tạo. Thực hiện các thủ tục tăng cường sản xuất cuối cùng. Monitoring and Scalability Strategy\nActive Monitoring: CloudWatch Logs được bật cho tất cả các hàm Lambda và endpoint API Gateway, cùng với CloudWatch Metrics để theo dõi hiệu suất. Planned Alarms: CloudWatch Alarms và thông báo SNS được lên kế hoạch cho tỷ lệ lỗi và độ trễ críti. Scalability: Đạt được thông qua Architecture Serverless (DynamoDB On-Demand, Lambda, CloudFront CDN). Disaster Recovery: Khôi phục Điểm trong Thời gian DynamoDB và Phiên bản S3 được lên kế hoạch để được bật cho dữ liệu/tài sản quan trọng. Mã Lambda được lưu trữ trong kiểm soát phiên bản để triển khai lại nhanh chóng. EXPECTED AWS COST BREAKDOWN BY SERVICES AWS Service Monthly Estimated Cost (USD) Amazon Bedrock $21.61 AWS Lambda $3.75 Amazon Simple Email Service (SES) $2.25 Amazon DynamoDB $1.52 Amazon Simple Storage Service $0.46 Amazon CloudWatch $0.80 Amazon API Gateway $0.06 Amazon CloudFront $0.00 Amazon Cognito $0.00 Amazon EventBridge $0.00 Amazon IAM $1.60 Amazon KMS $1.03 TOTAL MONTHLY COST $33.14 TOTAL YEARLY COST $397.79 TEAM Name Task Role Email / Contact Info Bùi Tấn Phát Dashboard, Manage Employee, Support, Content check Leader btfat3103@gmail.com Nguyễn Ngọc Long CRUD, Config Network / API Gateway, Test function, Slide Member nguyenngoclong216@gmail.com Đặng Nguyễn Minh Duy Database, CloudWatch / CloudLogs, Paper, Slide Member dangnguyenminhduy11b08@gmail.com Đỗ Đăng Khoa Log In/ Registration / Forget Password, UI / UX - Static Web, Paper Member khoado7577@gmail.com Nguyễn Huỳnh Thiên Quang Auto Scoring, AI Assistant, Slide Member quangkootenhatvutru@gmail.com RESOURCES \u0026amp; COST ESTIMATES Resource Responsibility Rate (USD) / Hour Full-Stack Developers [2] React frontend, Python Lambda backend, API integration $66 Cloud Engineers [3] AWS infrastructure setup, deployment automation, monitoring $66 Other (Please specify) Estimated platform consumption (Lambda, DynamoDB, Bedrock). Paper and present material $0.01 NOTE: Project Phase durations overlap each other.\nProject Phase Duration Man-Days Other (Please specify) Estimated Cost Phase 1: Foundation \u0026amp; Scoring Model 8 Weeks 80 - $42,246.40 (80 x $528.08) Phase 2: Project Setup \u0026amp; Dashboard 2 Weeks 40 - $21,123.20 (40 x $528.08) Phase 3: AI Agent \u0026amp; Absence Mgmt 1 Week 15 - $7,921.20 (15 x $528.08) Phase 4: Integration, Testing \u0026amp; Handover 1 Week 15 - $7,921.20 (15 x $528.08) Total Hours 12 Weeks 150 Man-Days $79,212.00 Cost Contribution distribution between Partner, Customer, AWS.\nParty Contribution (USD) % Contribution of Total Customer 0 0 Partner 0 0 AWS 200 100 ACCEPTANCE 1. Project Acceptance Criteria\nNền tảng InsightHR sẽ được coi là hoàn chỉnh và được chấp nhận khi các tiêu chí sau đây được đáp ứng.\n2. Completed Deliverables\nTất cả các tính năng chính được triển khai và triển khai sản xuất Quản lý người dùng và nhân viên với hoạt động hàng loạt Quản lý điểm hiệu suất với xem dựa trên lịch Hệ thống Attendance với đánh dấu absence tự động Bảng điều khiển tương tác với đồng hồ trực tiếp Chatbot AI với tích hợp Bedrock 3. Key Metrics Achieved\n300+ tài khoản người dùng 300 bản ghi nhân viên trên 5 bộ phận 900+ điểm hiệu suất được theo dõi 9,300+ bản ghi tham dự Chi phí AWS hàng tháng: ~$33.14 Thời gian hoạt động hệ thống: 99.9%+ Zero critical security vulnerabilities 4. Acceptance Status\nCurrent Status: Application deployed in cloudfront Production URL: https://d2z6tht6rq32uy.cloudfront.net 5. Next Steps\nSửa lỗi nhỏ và cập nhật tính năng Tiến hành kiểm tra chấp nhận của người dùng Cung cấp chuyển giao kiến thức và đào tạo "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2 Thiết lập môi trường phát triển với Linux Fedora cho các dịch vụ AWS Tham dự AWS Cloud Day 2025 và tìm hiểu về các công nghệ AWS mới Thiết lập quy trình làm việc nhóm và quản lý dự án Áp dụng phương pháp AI-DLC (AI Driven Development Lifecycle) với Kiro IDE Khám phá AWS S3 buckets và các dịch vụ AWS cơ bản Các công việc đã triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Thiết lập môi trường Linux Fedora cho các dịch vụ AWS - Khắc phục sự cố cài đặt và cấu hình Fedora - Lập kế hoạch nhóm ban đầu về các dịch vụ AWS khác nhau 15/09/2025 15/09/2025 https://cloudjourney.awsstudygroup.com/ 2 - Tiếp tục cấu hình môi trường Fedora - Đăng ký tham dự AWS Cloud Day 2025 (18/09/2025) - Lập kế hoạch và phối hợp nhóm cho các hoạt động sắp tới 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Lập kế hoạch nhóm và thiết lập quy trình làm việc - Thiết lập quy trình quản lý dự án nhóm - Thảo luận về các dịch vụ AWS: VPC, IAM roles, AWS free tier missions 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - AWS Cloud Day 2025: + Khám phá công nghệ và dịch vụ AWS + Tìm hiểu về Amazon Nova Act + Tìm hiểu về Kiro AI Agent + Tìm hiểu về phương pháp AI-DLC + Giao lưu và kết nối với cộng đồng AWS 18/09/2025 18/09/2025 Sự kiện AWS Cloud Day 2025 5 - Áp dụng phương pháp AI-DLC để tạo POCs trong Kiro IDE - Cài đặt Kiro IDE trên nền tảng Windows - Kiểm tra quy trình AI tự động 19/09/2025 19/09/2025 Tài liệu Kiro IDE 6 - Tiếp tục kiểm tra khả năng của Kiro IDE - Phát triển prompts cho Kiro AI Agent - Tinh chỉnh quy trình AI-DLC 20/09/2025 20/09/2025 Tài liệu Kiro IDE Kết quả đạt được tuần 2 Thiết lập môi trường phát triển: Cài đặt và cấu hình thành công Linux Fedora cho phát triển AWS Khám phá các tính năng của Fedora Linux bao gồm themes, tùy chỉnh và ứng dụng Khắc phục sự cố và tối ưu hóa môi trường Fedora cho công việc phát triển Môi trường phát triển Linux Fedora được cấu hình cho các dịch vụ AWS\nTham dự AWS Cloud Day 2025: Tham dự AWS Cloud Day 2025 vào ngày 18 tháng 9 năm 2025 Tìm hiểu về các công nghệ và dịch vụ AWS mới: Amazon Nova Act - Dịch vụ AI mới của AWS Kiro AI Agent - Trợ lý phát triển AI tự động AI-DLC (AI Driven Development Lifecycle) - Phương pháp SDLC mới Giao lưu với các chuyên gia AWS và thành viên cộng đồng AWS Cloud Day 2025 - Tìm hiểu về các công nghệ AWS mới\nHợp tác nhóm:\nThiết lập quy trình làm việc nhóm và quản lý dự án Lập kế hoạch và thảo luận về các dịch vụ AWS khác nhau bao gồm VPC, IAM roles Phối hợp về các nhiệm vụ AWS free tier và chia sẻ tài nguyên Chuẩn bị cho đề xuất và triển khai workshop Áp dụng phương pháp AI-DLC:\nCài đặt thành công Kiro IDE trên nền tảng Windows Áp dụng phương pháp AI-DLC để tạo các proof-of-concepts Kiểm tra khả năng quy trình AI tự động Phát triển nhiều prompts để tương tác hiệu quả với AI agent Thiết lập Kiro IDE và kiểm tra quy trình AI-DLC\nKhám phá dịch vụ AWS:\nHọc cách làm việc với S3 buckets Khám phá kiến trúc dịch vụ AWS cơ bản Hiểu về giới hạn AWS free tier và các phương pháp hay nhất Công cụ phát triển và tự động hóa:\nClone nhiều repository FCJ (First Cloud Journey) để tham khảo Phát triển extension Chromium tự động đăng ký cho việc đăng ký văn phòng hàng ngày Khắc phục sự cố và tối ưu hóa extension để có hiệu suất tốt nhất Học Hugo static site generator cho tài liệu Extension Chromium tự động đăng ký cho tự động hóa đăng ký văn phòng\nCấu hình Hugo static site generator\nGitHub và kiểm soát phiên bản: Clone và nghiên cứu nhiều repository FCJ Thực hành quy trình Git và các phương pháp hay nhất về kiểm soát phiên bản Thách thức gặp phải Gặp ít khó khăn trong tuần 2 Đã giải quyết thành công các vấn đề cài đặt và cấu hình Fedora Linux thông qua khắc phục sự cố Bài học chính Công nghệ mới:\nKhả năng và trường hợp sử dụng của Amazon Nova Act Phương pháp AI-DLC (AI Driven Development Lifecycle) và ứng dụng của nó trong phát triển phần mềm hiện đại Các tính năng của Kiro AI Agent và khả năng quy trình tự động Dịch vụ AWS:\nQuản lý S3 bucket và các phương pháp hay nhất Hợp tác nhóm về tài nguyên AWS free tier Lập kế hoạch dịch vụ AWS cho đề xuất và workshops Kỹ năng phát triển:\nQuản lý môi trường Linux Fedora Hugo static site generator Phát triển extension Chromium Quy trình phát triển dựa trên AI Mục tiêu tuần tới Tiếp tục khám phá các dịch vụ AWS chuyên sâu Áp dụng phương pháp AI-DLC cho các dự án phức tạp hơn Chuẩn bị đề xuất chi tiết cho triển khai workshop Tìm hiểu sâu hơn về VPC và IAM roles "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "AI-Driven Development Life Cycle Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian: Thứ Sáu, ngày 03 tháng 10 năm 2025\nBài thu hoạch: \u0026ldquo;AI-Driven Development Life Cycle\u0026rdquo; Mục Đích Của Sự Kiện Hiểu được sự chuyển đổi mô hình từ phát triển phần mềm truyền thống sang Chu trình Phát triển Hướng Dẫn bởi AI (AI-DLC) Khám phá cách AI biến đổi từng giai đoạn của quy trình phát triển phần mềm Học các ứng dụng thực tế của công cụ Amazon Q Developer và Kiro Khám phá các chiến lược tích hợp AI vào quy trình phát triển hiện có Phân tích các case study thực tế về triển khai phần mềm được tăng tốc bởi AI Danh Sách Diễn Giả Binh Tran - Kiến trúc sư Giải pháp Cấp cao, AWS AWS Expert Team - Chuyên gia về công cụ phát triển hỗ trợ AI Nội Dung Nổi Bật 1. Sự Chuyển Đổi Mô Hình AI-DLC Truyền thống vs Hướng dẫn bởi AI: Hiểu được sự khác biệt cơ bản giữa phương pháp SDLC thông thường và AI-DLC AI như Cộng tác viên Trung tâm: Khác với các phương pháp truyền thống coi AI như trợ lý, AI-DLC tích hợp thực thi được hỗ trợ bởi AI với sự giám sát của con người trong toàn bộ vòng đời Lợi ích Cốt lõi: Cải thiện đáng kể tốc độ phát triển, nâng cao chất lượng code và tăng tốc chu kỳ đổi mới 2. Ba Giai Đoạn của AI-DLC Giai đoạn 1: Khởi tạo (Inception)\nĐịnh nghĩa Bối cảnh: AI hỗ trợ thu thập và tổ chức yêu cầu dự án Tạo User Story: Tự động tạo và tinh chỉnh các user story Lập Kế hoạch Công việc: Phân tách tính năng thành các đơn vị công việc có thể quản lý được nhờ AI Ước lượng: Ước lượng nỗ lực thông minh dựa trên dữ liệu lịch sử và phân tích độ phức tạp Giai đoạn 2: Xây dựng (Construction)\nTạo Code: Viết code được hỗ trợ AI với các gợi ý nhận biết ngữ cảnh Kiểm thử Tự động: AI tạo bộ test toàn diện bao gồm unit, integration và edge case Nâng cao Kiến trúc: Cải thiện kiến trúc liên tục được đề xuất bởi AI Infrastructure as Code: Tự động tạo IaC và script triển khai Đảm bảo Chất lượng: Code review và quét bảo mật được hỗ trợ bởi AI Giai đoạn 3: Vận hành (Operation)\nTự động hóa Triển khai: Triển khai được điều phối bởi AI đến môi trường production Quản lý Sự cố: Phát hiện, chẩn đoán sự cố thông minh và đề xuất giải pháp Tối ưu hóa Hiệu suất: Giám sát liên tục và các tối ưu hóa được đề xuất bởi AI Vòng Phản hồi: AI phân tích các chỉ số production để thông tin cho các chu kỳ phát triển tương lai 3. Khả năng của Amazon Q Developer Tự động hóa SDLC: Hỗ trợ end-to-end từ lập kế hoạch đến bảo trì Chuyển đổi Code: Nâng cấp tự động cho Java, hiện đại hóa .NET Tích hợp Đa nền tảng: Tích hợp liền mạch với AWS Console, IDE, CLI và các nền tảng DevSecOps Cộng tác Thông minh: Hoạt động như một AI pair programmer hiểu các codebase phức tạp Tạo Tài liệu: Tự động tạo tài liệu toàn diện và unit test Nâng cao Bảo mật: Quét bảo mật tích hợp và phát hiện lỗ hổng 4. Minh họa Công cụ Kiro Tăng tốc Phát triển: Gợi ý và hoàn thành code theo thời gian thực Nhận biết Ngữ cảnh: Hiểu cấu trúc dự án và các mẫu coding Tích hợp Quy trình: Tích hợp liền mạch vào môi trường phát triển hiện có Chỉ số Năng suất: Cải thiện có thể đo lường được trong tốc độ phát triển Những Gì Học Được Chuyển đổi Tư duy AI như Đối tác, Không phải Công cụ: Các triển khai AI-DLC thành công nhất coi AI như một cộng tác viên thông minh hơn là chỉ một công cụ phát triển khác Giám sát của Con người Vẫn Quan trọng: Trong khi AI tăng tốc thực thi, phán đoán của con người hướng dẫn các quyết định chiến lược và xác thực đầu ra của AI Học Liên tục: Hệ thống AI cải thiện theo thời gian bằng cách học từ các mẫu và sở thích của nhóm Triển khai Kỹ thuật Áp dụng Dần dần: Các tổ chức có thể tích hợp dần các thực hành AI-DLC mà không làm gián đoạn quy trình hiện có Lựa chọn Công cụ: Hiểu khi nào sử dụng Amazon Q Developer so với các trợ lý coding AI khác dựa trên nhu cầu cụ thể Duy trì Chất lượng: Code được tạo bởi AI yêu cầu quy trình review phù hợp để duy trì tiêu chuẩn Tác động Kinh doanh Tốc độ Ra thị trường: AI-DLC có thể giảm chu kỳ phát triển 40-60% cho các dự án phù hợp Chất lượng Code: Các quy trình kiểm thử và review tự động dẫn đến các ứng dụng mạnh mẽ hơn Trải nghiệm Developer: Developer có thể tập trung vào giải quyết vấn đề sáng tạo thay vì các tác vụ lặp đi lặp lại Ứng Dụng Vào Công Việc Dự án Thí điểm: Chọn một dự án nội bộ nhỏ để thử nghiệm phương pháp AI-DLC Tích hợp Amazon Q: Bắt đầu sử dụng Amazon Q Developer trong các tác vụ coding hàng ngày để trải nghiệm tăng năng suất Thiết lập Hướng dẫn: Tạo hướng dẫn nhóm cho phát triển được hỗ trợ AI bao gồm tiêu chuẩn code review Đo lường Tác động: Theo dõi các chỉ số như tốc độ phát triển, tỷ lệ bug và thời gian triển khai trước và sau khi áp dụng AI Chương trình Đào tạo: Phát triển đào tạo nội bộ để giúp các thành viên nhóm tận dụng hiệu quả các công cụ phát triển AI Trải nghiệm trong event Workshop cung cấp cái nhìn toàn diện và thực tế về cách AI đang biến đổi cơ bản việc phát triển phần mềm.\nHiểu Sự Chuyển đổi Mô hình Phiên làm việc đã làm rõ sự khác biệt giữa phát triển \u0026ldquo;được hỗ trợ bởi AI\u0026rdquo; và \u0026ldquo;được hướng dẫn bởi AI\u0026rdquo;, giúp tôi hiểu đây không chỉ là về các công cụ tốt hơn mà là một sự thay đổi phương pháp cơ bản Các ví dụ thực tế đã chứng minh cách các tổ chức hàng đầu đang đạt được tăng năng suất đáng kể thông qua việc áp dụng AI-DLC Minh họa Thực hành Demo Amazon Q Developer: Xem các minh họa trực tiếp về tạo code, chuyển đổi và tạo tài liệu thật sự mở mang tầm mắt Hướng dẫn Công cụ Kiro: Thấy cách Kiro tích hợp vào quy trình phát triển cung cấp những hiểu biết thực tế cho ứng dụng ngay lập tức Các demo cho thấy cả khả năng và giới hạn của các công cụ phát triển AI hiện tại, đặt kỳ vọng thực tế Hiểu biết Chiến lược Hiểu mô hình AI-DLC ba giai đoạn (Inception, Construction, Operation) cung cấp một framework rõ ràng cho triển khai Sự nhấn mạnh vào duy trì giám sát của con người trong khi tận dụng thực thi AI đạt được sự cân bằng đúng giữa tự động hóa và kiểm soát Thảo luận về các chiến lược quản lý thay đổi để giới thiệu AI-DLC cho các nhóm phát triển đặc biệt có giá trị Networking và Thảo luận Các cuộc trò chuyện với những người tham dự khác tiết lộ các phương pháp khác nhau để áp dụng AI trên các tổ chức khác nhau Các phiên Q\u0026amp;A giải quyết các mối quan tâm thực tế về chất lượng code, bảo mật và sự thích nghi của nhóm Các trải nghiệm được chia sẻ làm nổi bật cả thành công và thách thức trong triển khai AI-DLC Một số hình ảnh từ sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện này cung cấp cả framework khái niệm và các công cụ thực tế cần thiết để bắt đầu biến đổi các quy trình phát triển của chúng tôi với phương pháp AI-DLC, định vị nhóm của chúng tôi để tăng tốc đáng kể việc cung cấp trong khi duy trì tiêu chuẩn chất lượng.\n"
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Tối ưu hóa hiệu suất băng thông hợp nhất thu nhập cố định: Kiểm tra độ trễ cho dữ liệu thị trường trái phiếu bởi Neil Ryan, George Beasley, và Vivian Lai vào ngày 17 THÁNG 7 NĂM 2025 trong Amazon EC2, Amazon Elastic Kubernetes Service, Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon RDS, Dịch vụ tài chính, Các ngành Đường dẫn cố định Bình luận Chia sẻ\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Bondtape.png)\nTrong thế giới nhịp độ nhanh của thị trường tài chính, mỗi mili giây đều có giá trị. Đối với các Nhà cung cấp Băng thông Hợp nhất Thu nhập Cố định (CTP) (sắp được lựa chọn) sẽ bắt đầu hoạt động vào đầu năm 2026, việc duy trì độ trễ thấp và thông lượng cao để cung cấp thông tin định giá kịp thời và chính xác là rất quan trọng.\nBondtape Bondtape là sự hợp tác giữa FINBOURNE Technology và Propellant.digital. Họ sẽ cùng nhau cung cấp Băng thông Hợp nhất (CT) trái phiếu đã được thị trường chứng minh, đáng tin cậy và có thể mở rộng tại Vương quốc Anh, đánh dấu một bước quan trọng hướng tới việc cải thiện tính minh bạch và hiệu quả trên thị trường thu nhập cố định toàn cầu. Sự hợp tác này sẽ tận dụng công nghệ dữ liệu doanh nghiệp của FINBOURNE, kết hợp với khung phân tích của Propellant, để cung cấp một giải pháp doanh nghiệp toàn diện.\nSử dụng nền tảng của FINBOURNE, Bondtape đã phát triển một nguyên mẫu cho giải pháp CTP của họ, được thiết kế để kiểm tra chất lượng, hài hòa hóa và phổ biến dữ liệu định giá trái phiếu một cách hiệu quả trong thời gian thực. Là một phần của bài tập, họ đã triển khai một bộ dữ liệu giao dịch đầy đủ và một bộ công cụ kiểm tra, mà sau đó Bondtape đã tiến hành kiểm tra độ trễ toàn diện.\nThách thức: Cân bằng giữa Tốc độ và Sự ổn định Mục tiêu là đánh giá cách hệ thống xử lý các cường độ tải khác nhau và liệu các điều kiện này có bất kỳ tác động có thể đo lường nào đến độ trễ xử lý hay không. Việc kiểm tra là rất quan trọng để đảm bảo rằng nguyên mẫu duy trì hiệu suất nhất quán dưới cả áp lực ngắn hạn và hoạt động kéo dài, mô phỏng các kịch bản trong thế giới thực. Điều quan trọng cần lưu ý là thời gian trong bài đăng trên blog này chỉ mang tính chất tham khảo, vì nguyên mẫu sẽ nhận được các cải tiến từ việc tinh chỉnh hiệu suất và cải thiện làm mịn khối lượng công việc được lên kế hoạch như một phần của giai đoạn tiền vận hành CTP.\nPhương pháp tiếp cận của Bondtape: Nền tảng và Môi trường kiểm tra do AWS cung cấp Nền tảng đám mây gốc của Bondtape chạy trên hai Vùng sẵn sàng cho các CT của Vương quốc Anh. Kiến trúc này phân phối tải và dữ liệu một cách hiệu quả để đảm bảo khả năng phục hồi không có thời gian chết trước sự cố của thành phần, phần cứng hoặc toàn bộ Vùng sẵn sàng. Cũng cần lưu ý rằng một \u0026lsquo;khu vực\u0026rsquo; theo thuật ngữ của AWS (ví dụ: London) bao gồm 3 hoặc nhiều Vùng sẵn sàng (AZ). Các Vùng sẵn sàng này cách nhau ít nhất 100 km và mỗi vùng đều có nguồn điện, hệ thống làm mát và kết nối dự phòng riêng.\nCác AZ cuối cùng cho CTP sẽ được tối ưu hóa cho cả độ trễ và các yếu tố môi trường. Tất cả kết nối vào và ra khỏi dịch vụ sẽ được cấu hình để có khả năng phục hồi, với tính dự phòng và chuyển đổi dự phòng tự động để giảm thiểu các kịch bản có khả năng gây gián đoạn. Bondtape được xây dựng trên cùng công nghệ nền tảng với nền tảng LUSID của FINBOURNE, xử lý trung bình 10 triệu yêu cầu xử lý dữ liệu hàng ngày (3,4 tỷ vào năm 2024) với độ tin cậy hàng đầu trong ngành.\nTận dụng khả năng mở rộng và tính linh hoạt của AWS, Bondtape đã thiết lập môi trường nguyên mẫu thử nghiệm của họ với cấu hình sau:\nMột nhóm các phiên bản Amazon Elastic Compute Cloud (EC2), được điều phối bằng Amazon Elastic Kubernetes Service (EKS). Triển khai thông lượng dữ liệu vô song của Amazon Managed Streaming for Apache Kafka (MSK) và Amazon Relational Data Service (RDS). Chạy hot/hot trên nhiều Vùng sẵn sàng của AWS trong khu vực EU-WEST-2 London (LON). Thử nghiệm khứ hồi được tiến hành từ văn phòng của FINBOURNE tại Dublin (DUB) để mô phỏng kỳ vọng độ trễ đầu cuối thực tế của người dùng cuối trên các khu vực địa lý. Bộ công cụ thử nghiệm được sử dụng để phát lại dữ liệu lịch sử ở các tốc độ quy định đã được FINBOURNE tùy chỉnh xây dựng cho Bondtape. Bondtape đã tiến hành một bài kiểm tra độ trễ toàn diện trên nguyên mẫu CTP. Họ đã sử dụng một bộ công cụ thử nghiệm được thiết kế để đưa dữ liệu định giá trái phiếu lịch sử vào nền tảng với các mức thông lượng khác nhau trong các điều kiện được kiểm soát.\nMục tiêu là đánh giá cách hệ thống xử lý các cường độ tải khác nhau và liệu các điều kiện này có bất kỳ tác động có thể đo lường nào đến độ trễ xử lý hay không. Việc có sẵn các điểm chuẩn và công cụ kiểm tra này cho phép họ đo lường hiệu quả tác động và cải tiến hiệu suất từ việc phát triển nền tảng đang diễn ra.\nBằng cách phát lại một phiên giao dịch đầy đủ 10 giờ, Bondtape nhằm xác định xem hệ thống có duy trì hiệu suất nhất quán hay có biểu hiện trôi, suy giảm hoặc tích tụ độ trễ đuôi dưới khối lượng công việc kéo dài hay không.\nTận dụng cơ sở hạ tầng có thể mở rộng và các dịch vụ AWS của FINBOURNE, nhóm Bondtape đã đo lường cách hệ thống hoạt động trong các điều kiện mà các tài nguyên được phân bổ trở nên bão hòa, và tác động (hoặc không) của các sự kiện tăng và giảm quy mô.\nKhi việc kiểm tra và đánh giá nền tảng tiếp tục cùng với sự phát triển của nó, Bondtape sẽ hợp tác chặt chẽ với AWS để đảm bảo giải pháp CTP của họ thể hiện các đặc tính hiệu suất và khả năng phục hồi cần thiết trước khi ra mắt.\nPhương pháp kiểm tra hiệu suất: Mô phỏng điều kiện thị trường Bondtape đã tiến hành hai loại kiểm tra:\nĐộ nhạy tải. Bằng cách phát lại dữ liệu trái phiếu ở các tốc độ khác nhau (1x, 2x và 3x), họ đã quan sát cách việc tăng thông lượng ảnh hưởng đến độ trễ và khả năng phản hồi của CTP, ngay cả ở trạng thái ban đầu. Tính ổn định dưới tải đại diện. Bằng cách phát lại một phiên giao dịch đầy đủ 10 giờ, Bondtape muốn xác định xem hệ thống có duy trì hiệu suất nhất quán hay có biểu hiện trôi, suy giảm hoặc tích tụ độ trễ đuôi dưới khối lượng công việc kéo dài hay không. Phương pháp này cho phép Bondtape đo lường các đặc tính độ trễ của hệ thống dưới cả áp lực ngắn hạn và hoạt động kéo dài, giúp họ hiểu rõ hơn về hành vi của nó trong các kịch bản giống như sản xuất. Họ đặt \u0026lsquo;mức chịu đựng\u0026rsquo; ban đầu là 500ms. Đối với mỗi bài kiểm tra, Bondtape đã đo thời gian khứ hồi (RTT) và tính toán các chỉ số chính bao gồm độ trễ trung bình, trung vị (P50), phân vị thứ 95 (P95) và phân vị thứ 99 (P99). Họ đã kiểm tra chất lượng mỗi sự kiện được hệ thống xử lý, bao gồm tuân thủ định dạng thông báo MiFID II, xác thực loại tài sản ISIN, đủ điều kiện ToTV (Giao dịch trên sàn giao dịch) và xác thực cờ báo cáo sau giao dịch.\nCác kết quả chính Các bài kiểm tra đã tiết lộ một số thông tin quan trọng:\nHiệu suất cơ bản: Trong điều kiện bình thường (tốc độ 1x), hệ thống duy trì độ trễ trung vị thấp, thể hiện hiệu suất vững chắc cho các khối lượng công việc thông thường. Khả năng mở rộng: Tăng tốc độ phát lại lên 2x và 3x, Bondtape quan sát thấy phân phối độ trễ rộng, cho thấy độ nhạy ngày càng tăng đối với áp lực thông lượng. Tuy nhiên, hiệu suất vẫn nằm trong giới hạn chấp nhận được. Tính ổn định lâu dài: Thử nghiệm 10 giờ cho thấy phân phối độ trễ phẳng ra, với đuôi nặng hơn ngoài 60ms. Thời gian chạy dài hơn dường như tích tụ áp lực hệ thống, làm tăng độ trễ đuôi. Các kịch bản áp suất cao: Việc phát lại dữ liệu kéo dài một tuần ở tốc độ 10x cho thấy khả năng của hệ thống trong việc xử lý khối lượng lớn trong thời gian dài, chỉ với sự gia tăng nhẹ về độ trễ. Phân phối độ trễ phẳng ra với đuôi nặng hơn ngoài 100ms. Biểu đồ tần suất ![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-1-1x-Speed.png)\nHình 1 – Tốc độ 1x\nPhân phối độ trễ cho thấy một cụm chặt chẽ quanh 30–35ms, thể hiện hiệu suất ổn định dưới tải thời gian thực.\nMột đuôi khiêm tốn bắt đầu hình thành sau 40ms, nhưng độ lan tỏa tổng thể vẫn thấp.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-2-2x-Speed.png)\nHình 2 – Tốc độ 2x\nPhân phối dịch chuyển nhẹ sang phải, với hầu hết các độ trễ nằm trong khoảng 35 – 45ms.\u0026lt;br\u0026gt; Thông lượng tăng lên tạo ra một sự lan rộng hơn nhưng vẫn có thể quản lý được.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-3-3x-Speed.png)\nHình 3 – Tốc độ 3x\nĐộ trễ tiếp tục tăng, với phân phối rộng hơn và đuôi dày hơn sau 50ms.\nMột số giá trị ngoại lệ bắt đầu xuất hiện, cho thấy những dấu hiệu sớm của độ nhạy tải.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-4-Full-Day-1x.png)\nHình 4 – Cả ngày (1x)\nPhân phối độ trễ phẳng ra với một đuôi nặng hơn ngoài 60ms.\nThời gian chạy dài hơn dường như tích tụ áp lực hệ thống, làm tăng độ trễ đuôi, nhưng việc thấy các giá trị cực đoan hơn được giải thích bởi kích thước mẫu lớn hơn.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-5-Full-Week-10x.png)\nHình 5 – Cả tuần (10x)\nPhân phối độ trễ phẳng ra với một đuôi nặng hơn ngoài 100ms.\nThời gian chạy dài hơn dường như tích tụ áp lực hệ thống, làm tăng độ trễ đuôi, nhưng việc thấy các giá trị cực đoan hơn được giải thích bởi kích thước mẫu lớn hơn.\nSự gia tăng nhẹ về độ trễ trong thử nghiệm áp lực dài hạn.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-6-CDF-Comparison.png)\nHình 6 – So sánh CDF\nCác đường cong CDF làm nổi bật rằng tốc độ bình thường và 2x đạt 95% hoàn thành dưới 50ms, trong khi các lần chạy 3x và hàng ngày cho thấy tiến độ chậm hơn.\nĐường cong kiểm tra hàng ngày phẳng ra muộn hơn, cho thấy một sự lan rộng hơn và độ trễ đuôi cao hơn.\n![alt text](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2025/07/17/Figure-7-Violin-Plot-Comparison.png)\nHình 7 – So sánh Biểu đồ Violin\nBiểu đồ violin cho thấy phân phối ngày càng rộng hơn từ 1x đến 3x, với lần chạy hàng ngày thể hiện sự lan rộng và các giá trị ngoại lệ đáng kể nhất.\nNó xác nhận rằng phân phối độ trễ trở nên biến đổi hơn dưới điều kiện tải kéo dài hoặc tăng tốc.\nKết luận và các bước tiếp theo Nhìn chung, nguyên mẫu Bondtape đã cho thấy hiệu suất đầy hứa hẹn, với tất cả các bài kiểm tra đều nằm trong ngưỡng chịu đựng 500ms. Hệ thống đã xử lý tốt các tải bình thường và tăng vừa phải, đồng thời cũng cho thấy khả năng phục hồi trong các kịch bản áp suất cao.\nCác bài kiểm tra cũng xác định các lĩnh vực cần cải thiện tiềm năng, đặc biệt là trong việc tối ưu hóa cho các trường hợp sử dụng thông lượng cao kéo dài hoặc chạy dài.\nBằng cách tận dụng sức mạnh và tính linh hoạt của AWS và các thử nghiệm nghiêm ngặt như thế này, Bondtape tự tin vào khả năng của đội ngũ trong việc xây dựng một Băng thông Hợp nhất mạnh mẽ, hiệu suất cao cho thị trường trái phiếu với một mức giá hợp lý. Các bước tiếp theo của Bondtape sẽ bao gồm việc tinh chỉnh nguyên mẫu dựa trên các kết quả thử nghiệm này và chuẩn bị cho việc triển khai trong thế giới thực.\nHãy theo dõi để biết thêm các cập nhật khi Bondtape và AWS tiếp tục đẩy lùi các giới hạn của những gì có thể trong xử lý và phân phối dữ liệu tài chính.\nNeil Ryan Hơn 20 năm làm việc trong lĩnh vực ngân hàng và thu nhập cố định cho một số ngân hàng toàn cầu bao gồm CEO tại Wells Fargo Bank International, IKB Credit Asset Management, chi nhánh London và Naspa Dublin. Neil cũng là một PCF-2 tại công ty dịch vụ quản lý quỹ được quy định của Northern Trust tại Ireland và là chủ tịch của Nhóm chuyên gia dữ liệu thị trường của EU. Trước khi gia nhập FINBOURNE, Neil là COO tại Corlytics (một công ty RegTech của Ireland) và Quaternion Risk Management (một công ty Fintech của Ireland), nơi ông đã xây dựng quan hệ đối tác với Deloitte, FINRA, FCA, Đại học Columbia (New York), Parameta và Acadia. Trước đây là Trợ lý Tổng thư ký tại Bộ Tài chính (Ireland, 2011-2016), CRO trong Bộ và là thành viên của RCG châu Âu của FSB. Ông có bằng luật của Trinity College, Dublin và LSE và bằng MBA của London Business School.\nGeorge Beasley George chịu trách nhiệm xây dựng các hệ thống quản lý danh tính và truy cập. Anh cũng giám sát tất cả các API của chúng tôi để đảm bảo chúng nhất quán, có thể kết hợp và cho phép các nhà phát triển của khách hàng nhanh chóng mang lại giá trị cho công ty của họ. Với vai trò là Cán bộ An ninh Thông tin, George giám sát việc phát triển và áp dụng liên tục các hệ thống, quy trình và các phương pháp bảo mật tốt nhất của FINBOURNE. Là người đồng sáng lập, George cũng là một người ủng hộ và là động lực chính của văn hóa cởi mở, minh bạch và hợp tác của chúng tôi và dẫn dắt một số sáng kiến nội bộ xây dựng và nuôi dưỡng văn hóa này. Trước khi đồng sáng lập FINBOURNE, George đã có sáu năm làm việc về công nghệ nền tảng có khả năng mở rộng và mạnh mẽ cao tại UBS Delta và ba năm làm việc trong lĩnh vực kỹ thuật phần mềm tại một công ty khởi nghiệp viễn thông.\nVivian Lai Vivian là Chuyên gia Thị trường Vốn tại AWS. Trước khi gia nhập AWS, cô đã có hơn 20 năm làm việc ở phía mua, bao gồm tại Bridgewater Associates, Amaranth Advisors và Pequot Capital, trong các vai trò công nghệ văn phòng trước. Vivian cũng là người đồng sáng lập tại Cerulean Analytics, được Trepp mua lại vào năm 2017, và là COO tại Adroit Trading Technologies. Cô nhận bằng Cử nhân Khoa học Máy tính và Cử nhân Quản lý tại Viện Bách khoa Rensselaer.\n"
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Phần này chứa các bài blog kỹ thuật của AWS đã được dịch từ tiếng Anh sang tiếng Việt trong khuôn khổ chương trình thực tập AWS First Cloud Journey.\nBlog 1 - Xây dựng các ứng dụng RAG hiệu quả về chi phí với Knowledge Bases của Amazon Bedrock và Amazon S3 Vectors Blog này khám phá cách xây dựng các ứng dụng Sinh dữ liệu tăng cường truy xuất (RAG) hiệu quả về chi phí bằng cách sử dụng Amazon Bedrock Knowledge Bases tích hợp với Amazon S3 Vectors. Tìm hiểu cách giảm chi phí lưu trữ véc-tơ lên đến 90% trong khi vẫn duy trì hiệu suất truy vấn dưới một giây. Bài viết bao gồm toàn bộ quy trình thiết lập bao gồm tạo knowledge base, cấu hình nguồn dữ liệu, triển khai lưu trữ véc-tơ và kiểm tra khả năng truy xuất.\nBlog 2 - Đánh giá các mô hình AI tạo sinh với Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI Blog này giới thiệu Amazon Nova LLM-as-a-Judge, một phương pháp toàn diện để đánh giá hiệu suất mô hình AI tạo sinh trên Amazon SageMaker AI. Tìm hiểu cách thực hiện đánh giá chất lượng mô hình có hệ thống bằng cách sử dụng so sánh cặp đôi, hiểu các chỉ số đánh giá bao gồm tỷ lệ thắng và khoảng tin cậy, và triển khai quy trình đánh giá tự động. Bài viết bao gồm phương pháp huấn luyện, xác thực độ thiên vị, và triển khai thực tế sử dụng công việc huấn luyện SageMaker với các ví dụ mã chi tiết.\nBlog 3 - Tối ưu hóa hiệu suất băng thông hợp nhất thu nhập cố định: Kiểm tra độ trễ cho dữ liệu thị trường trái phiếu Blog này xem xét cách tiếp cận của Bondtape trong việc xây dựng giải pháp Nhà cung cấp Băng thông Hợp nhất Thu nhập Cố định (CTP) hiệu suất cao trên AWS. Khám phá cách thiết kế hệ thống dữ liệu tài chính độ trễ thấp sử dụng Amazon EC2, Amazon EKS, Amazon MSK và Amazon RDS trên nhiều Vùng sẵn sàng. Bài viết chi tiết các phương pháp kiểm tra độ trễ toàn diện, đánh giá hiệu suất dưới các điều kiện tải khác nhau, và chiến lược duy trì hiệu suất nhất quán trong các kịch bản giao dịch thực tế.\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Khám phá và hiểu các khái niệm cơ bản về VPC (Virtual Private Cloud) Học các kiến thức cơ bản về dịch vụ EC2 và thực hành triển khai Triển khai website tĩnh sử dụng S3 và EC2 Thực hành vẽ sơ đồ kiến trúc AWS với draw.io Hiểu các chiến lược tối ưu hóa chi phí trong AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Khám phá các khái niệm và kiến trúc VPC - Thực hành mở và cấu hình VPC instances - Học vẽ sơ đồ kiến trúc AWS sử dụng draw.io 22/09/2025 22/09/2025 https://cloudjourney.awsstudygroup.com/ 2 - Thử phát triển ứng dụng website tĩnh sử dụng Kiro AI - Khắc phục các vấn đề triển khai - Học về việc xác định yêu cầu rõ ràng cho phát triển hỗ trợ bởi AI 23/09/2025 23/09/2025 3 - Thực hành tích hợp VPC với S3 - Triển khai website tĩnh đơn giản sử dụng S3 - Cấu hình S3 bucket để host website tĩnh 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Cấu hình EC2 instance để host server - Khám phá chức năng và tính năng của dịch vụ EC2 - Tìm hiểu các chiến lược tối ưu hóa chi phí AWS - Demo khả năng của dịch vụ EC2 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Ôn tập các nguyên tắc Quản lý Chi phí AWS - Xem lại các module S3, VPC và EC2 - Kiểm tra triển khai và chức năng của website tĩnh 26/09/2025 26/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành vẽ sơ đồ kiến trúc AWS với draw.io - Xem video khóa học AWS Study Group trên YouTube - Củng cố kiến thức đã học trong tuần 27/09/2025 27/09/2025 Kênh YouTube AWS Study Group Kết quả đạt được tuần 3: Kiến thức cơ bản về VPC:\nHiểu kiến trúc VPC và các khái niệm cốt lõi Cấu hình thành công các VPC instances Học cấu hình mạng VPC và security groups Thực hành tích hợp VPC với các dịch vụ AWS khác Thành thạo dịch vụ EC2:\nCó kinh nghiệm thực tế với triển khai EC2 instance Khám phá các loại và cấu hình EC2 instance Học các phương pháp kết nối và quản lý EC2 Hiểu tích hợp EC2 với VPC Triển khai Website Tĩnh:\nTriển khai thành công website tĩnh sử dụng S3 Cấu hình S3 bucket để host website Tích hợp S3 với EC2 để host server Kiểm tra chức năng và khả năng truy cập của website Vẽ Sơ đồ Kiến trúc AWS:\nHọc sử dụng draw.io để vẽ sơ đồ kiến trúc AWS Thực hành tạo sơ đồ hạ tầng AWS chuyên nghiệp Ghi chép cấu hình VPC và EC2 bằng hình ảnh Tối ưu hóa Chi phí:\nKhám phá các chiến lược quản lý chi phí AWS Học các phương pháp giảm chi phí dịch vụ AWS Hiểu các công cụ thanh toán và giám sát chi phí Kiểm soát Phiên bản và Công cụ AI:\nKhám phá các thực hành kiểm soát phiên bản Git Có kinh nghiệm với khả năng và hạn chế của Kiro AI Học tầm quan trọng của yêu cầu rõ ràng cho phát triển hỗ trợ bởi AI Thách thức gặp phải: Vấn đề Triển khai Kiro AI:\nGặp phải các vấn đề nghiêm trọng về code bị hỏng và hallucination khi sử dụng Kiro AI Dành 2-3 ngày để debug code bị hỏng Nguyên nhân gốc rễ: Yêu cầu không rõ ràng và thiếu chi tiết cho phép AI đưa ra các giả định sai Bài học rút ra: Công cụ AI yêu cầu các yêu cầu chính xác, được định nghĩa rõ ràng để tạo ra code đáng tin cậy Quyết định: Xóa repository bị hỏng và bắt đầu lại với cách tiếp cận rõ ràng hơn Xác định Yêu cầu:\nHọc được rằng yêu cầu chi tiết là quan trọng cho phát triển hỗ trợ bởi AI thành công Hiểu khoảng cách giữa hướng dẫn chung và nhu cầu triển khai cụ thể Cải thiện khả năng viết yêu cầu rõ ràng, có thể thực hiện được Kiến thức chính: VPC là nền tảng cho kiến trúc mạng và bảo mật AWS EC2 cung cấp khả năng tính toán linh hoạt với nhiều loại và cấu hình instance khác nhau S3 có thể host website tĩnh hiệu quả với cấu hình phù hợp Tích hợp giữa VPC, EC2 và S3 cho phép kiến trúc ứng dụng mạnh mẽ Tối ưu hóa chi phí là quan trọng cho việc sử dụng AWS bền vững Yêu cầu rõ ràng, chi tiết là cần thiết cho phát triển hỗ trợ bởi AI thành công Thực hành kiểm soát phiên bản giúp quản lý thay đổi code và thử nghiệm Mục tiêu tuần tới: Tiếp tục khám phá các dịch vụ AWS và tích hợp của chúng Áp dụng bài học về xác định yêu cầu Thực hành các mẫu kiến trúc AWS phức tạp hơn Cải thiện các chiến lược tối ưu hóa chi phí "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Workshop: Data Science on AWS” Địa điểm: FPT University HCM Campus\nThời gian:Thứ Năm, ngày 16 tháng 10 năm 2025\nMục Đích Của Sự Kiện Khám phá toàn bộ hành trình xây dựng một hệ thống Khoa học Dữ liệu (Data Science) hiện đại, từ lý thuyết đến thực hành. Nắm vững Quy trình Data Science đầu-cuối (end-to-end) trên AWS, bao gồm lưu trữ, xử lý và triển khai mô hình. Có được trải nghiệm thực tế với các tập dữ liệu thực tế (IMDb) và các mô hình ứng dụng (Phân tích Cảm xúc - Sentiment Analysis). Phân tích sự đánh đổi (trade-offs) về chi phí và hiệu suất giữa cơ sở hạ tầng Cloud và On-premise. Danh Sách Diễn Giả Ông Văn Hoàng Kha – Kiến trúc sư Giải pháp Đám mây, AWS Community Builder Ông Bạch Doãn Vương – Kỹ sư Cloud DevOps, AWS Community Builder Nội Dung Nổi Bật 1. Vai trò của Cloud trong Data Science và Tổng quan Quy trình Tầm quan trọng của Cloud: Phân tích lý do tại sao khoa học dữ liệu hiện đại cần dựa vào nền tảng đám mây để đạt được khả năng mở rộng (scalability) và tính tích hợp cao, thay vì bị giới hạn bởi cơ sở hạ tầng on-premise truyền thống. Quy trình Data Science trên AWS: Lưu trữ (Storage): Sử dụng Amazon S3 làm nền tảng hồ dữ liệu (data lake) cốt lõi. ETL/Xử lý (Processing): Sử dụng AWS Glue cho các tác vụ tích hợp dữ liệu phi máy chủ (serverless data integration). Mô hình hóa (Modeling): Tận dụng Amazon SageMaker làm trung tâm để xây dựng, huấn luyện và triển khai mô hình. Tổng quan về hệ thống AI/ML rộng lớn của AWS, bao gồm các dịch vụ AI, dịch vụ ML và cơ sở hạ tầng. 2. Minh họa Thực hành (Practical Demos) Demo 1: Xử lý Dữ liệu với AWS Glue: Kịch bản: Xử lý và làm sạch dữ liệu thô từ tập dữ liệu IMDb. Kỹ thuật: Trình diễn cách thực hiện kỹ thuật feature engineering và chuẩn bị dữ liệu hiệu quả. Workshop cũng làm nổi bật các phương pháp khác nhau, từ các lựa chọn ít mã (low-code) như SageMaker Canvas đến các phương pháp ưu tiên mã (code-first) sử dụng Numpy/Pandas. Demo 2: Phân tích Cảm xúc với SageMaker: Kịch bản: Huấn luyện và triển khai một mô hình học máy để phân tích cảm xúc từ dữ liệu văn bản. Quy trình: Minh họa chu trình \u0026ldquo;Huấn luyện, Tinh chỉnh, Triển khai (Train, Tune, Deploy)\u0026rdquo; trong SageMaker Studio. Phiên này cũng đề cập đến khái niệm \u0026ldquo;Mang mô hình của riêng bạn (Bring Your Own Model - BYOM)\u0026rdquo;, cho thấy tính linh hoạt với các framework như TensorFlow và PyTorch. 3. Thảo luận Chiến lược Cloud so với On-Premise: Thảo luận chuyên sâu về tối ưu hóa chi phí và các chỉ số hiệu suất. Nội dung làm nổi bật cách tính đàn hồi của đám mây (cloud elasticity) cho phép thử nghiệm các khối lượng công việc nặng mà không cần đầu tư vốn lớn ban đầu cho phần cứng on-premise. Hướng dẫn Dự án Nhỏ: Giới thiệu một dự án được thiết kế sau workshop nhằm củng cố các kỹ năng đã học. Những Gì Học Được Quy trình Kỹ thuật (Technical Workflow) Quy trình Thống nhất: Một quy trình khoa học dữ liệu mạnh mẽ không chỉ nằm ở mã nguồn; nó đòi hỏi sự tích hợp liền mạch giữa lưu trữ (S3), làm sạch (Glue) và mô hình hóa (SageMaker). Lựa chọn Công cụ: Việc hiểu rõ khi nào nên sử dụng các dịch vụ được quản lý sẵn (như Amazon Comprehend hoặc Textract) và khi nào nên xây dựng mô hình tùy chỉnh trên SageMaker là yếu tố then chốt để đạt được hiệu quả. Ứng dụng Thực tiễn (Industry Application) Bối cảnh Thực tế: Sự chuyển đổi từ lý thuyết học thuật sang ứng dụng công nghiệp nằm ở khả năng tự động hóa và mở rộng quy mô. Nhận thức về Chi phí: Các dự án dữ liệu thành công phải cân bằng giữa độ chính xác của mô hình và chi phí tính toán liên quan. Ứng Dụng Vào Công Việc Áp dụng AWS Glue: Đề xuất chuyển đổi các tập lệnh ETL cục bộ sang AWS Glue để tự động hóa, xử lý dữ liệu phi máy chủ trên các tập dữ liệu lớn hơn. Triển khai SageMaker: Di chuyển các mô hình thử nghiệm từ các sổ ghi chép Jupyter (Jupyter notebooks) cục bộ sang SageMaker Studio để chuẩn hóa quy trình huấn luyện và triển khai. Thực hiện Dự án: Thực hiện dự án nhỏ được đề xuất sau workshop để củng cố sự hiểu biết về quy trình xử lý dữ liệu IMDb. Trải nghiệm trong event Workshop “Data Science on AWS” đóng vai trò là cầu nối quan trọng giữa kiến thức học thuật và thực tiễn doanh nghiệp.\nKết nối Trực tiếp: Sự kiện đã liên kết kiến thức lý thuyết với các công nghệ đang được sử dụng bởi các doanh nghiệp hàng đầu thế giới. Góc nhìn Thực tiễn: Việc quan sát quá trình làm sạch tập dữ liệu IMDb và triển khai mô hình Phân tích Cảm xúc trực tiếp trên đám mây đã giúp đơn giản hóa sự phức tạp của AI trên nền tảng Cloud. Hướng dẫn Chuyên gia: Việc tương tác với các AWS Community Builders đã cung cấp những hiểu biết sâu sắc về cuộc tranh luận \u0026ldquo;Cloud so với On-premise\u0026rdquo;, giúp tôi nắm bắt được giá trị chiến lược của việc di chuyển lên đám mây ngoài các tính năng kỹ thuật. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, workshop đã cung cấp một khuôn khổ Data Science toàn diện, nhấn mạnh tầm quan trọng của các công cụ AWS được quản lý để đạt được tính linh hoạt, khả năng mở rộng và tối ưu hóa chi phí.\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4 Tìm hiểu sâu hơn về AWS VPC và các khái niệm networking Học về dịch vụ lưu trữ Amazon S3 và các best practices Khám phá các dịch vụ database của AWS (RDS) Tiếp tục thực hành với các dịch vụ AWS cốt lõi Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (30/9) - Ôn tập các khái niệm EC2 tuần trước\n+ Các loại instance và sizing\n+ Cấu hình security groups\n- Nghiên cứu tài liệu AWS về VPC cơ bản 30/09/2025 30/09/2025 AWS VPC Documentation Thứ Ba (1/10) - Học các khái niệm cơ bản về VPC\n+ Subnets (public vs private)\n+ Route tables\n+ Internet Gateway\n+ NAT Gateway 01/10/2025 01/10/2025 AWS VPC User Guide Thứ Tư (2/10) - Nghiên cứu dịch vụ Amazon S3\n+ Tạo và quản lý bucket\n+ Các khái niệm object storage\n+ Các storage classes của S3\n+ Kiểm soát truy cập và permissions 02/10/2025 02/10/2025 AWS S3 Documentation Thứ Năm (3/10) - Tiếp tục tìm hiểu sâu về S3\n+ Versioning và lifecycle policies\n+ Các tùy chọn mã hóa S3\n+ Static website hosting 03/10/2025 03/10/2025 AWS S3 Best Practices Thứ Sáu (4/10) - Giới thiệu về AWS RDS\n+ Các tùy chọn database engine\n+ Các loại RDS instance\n+ Khái niệm backup và restore\n- Ôn tập và củng cố kiến thức tuần 04/10/2025 04/10/2025 AWS RDS Documentation Kết quả đạt được tuần 4 Thành thạo VPC Networking\nHiểu kiến trúc VPC và các thành phần Nắm được sự khác biệt giữa public và private subnets Hiểu các khái niệm routing với route tables Hiểu cách hoạt động của Internet Gateway và NAT Gateway Thành thạo Amazon S3\nHọc các khái niệm lưu trữ S3 và use cases Hiểu các storage classes khác nhau của S3 (Standard, IA, Glacier) Thực hành tạo bucket và quản lý objects Cấu hình bucket policies và access controls Khám phá S3 versioning và lifecycle management Học về các tùy chọn mã hóa S3 (SSE-S3, SSE-KMS) Giới thiệu về Database Services\nCó cái nhìn tổng quan về dịch vụ AWS RDS Hiểu các tùy chọn database engine khác nhau (MySQL, PostgreSQL, v.v.) Học về sizing và cấu hình RDS instance Khám phá khả năng backup và restore Phát triển kỹ năng thực hành\nCải thiện hiểu biết về kiến trúc networking của AWS Nâng cao khả năng điều hướng tài liệu AWS hiệu quả Chuẩn bị cho các bài lab thực hành tuần tới Các thách thức gặp phải Các khái niệm routing trong VPC ban đầu khá phức tạp, đặc biệt là hiểu mối quan hệ giữa route tables, subnets và gateways S3 bucket policies và IAM permissions cần chú ý cẩn thận để tránh các vấn đề về quyền truy cập Cân bằng giữa học lý thuyết và thời gian thực hành Bài học quan trọng VPC là nền tảng cho kiến trúc networking và security của AWS S3 rất linh hoạt ngoài việc lưu trữ đơn giản - có thể host static websites, làm data lake, v.v. Thiết kế subnet phù hợp (public vs private) rất quan trọng cho các best practices về bảo mật Tài liệu AWS rất toàn diện nhưng cần thời gian để tiếp thu kỹ lưỡng Mục tiêu tuần tới Tiếp tục với các dịch vụ database của AWS (thực hành RDS) Bắt đầu công việc dịch blog (blog kỹ thuật AWS đầu tiên) Khám phá AWS Lambda và các khái niệm serverless Tìm hiểu sâu hơn về IAM roles và policies "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong suốt quá trình thực tập, tôi đã tham gia 7 sự kiện quan trọng, mỗi sự kiện mang lại những trải nghiệm học tập quý báu, kiến thức mới và những khoảnh khắc đáng nhớ.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025: GenAI and Data Track\nThời gian: Thứ Sáu, ngày 26 tháng 09 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Workshop về Agentic AI, Unified Data Foundation, GenAI roadmap, AI-Driven SDLC, Security, và AI Agents cho các ứng dụng business.\nEvent 2 Tên sự kiện: AI-Driven Development Life Cycle\nThời gian: Thứ Sáu, ngày 03 tháng 10 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Workshop thực tế về sự chuyển đổi mô hình AI-driven SDLC, minh họa Amazon Q Developer và khả năng công cụ Kiro cho tối ưu hóa phát triển.\nEvent 3 Tên sự kiện: Workshop: Data Science on AWS\nThời gian: Thứ Năm, ngày 16 tháng 10 năm 2025\nĐịa điểm: FPT University HCM Campus\nVai trò: Người tham dự\nMô tả ngắn: Quy trình Data Science end-to-end trên AWS, bao gồm xử lý dữ liệu với AWS Glue, phân tích cảm xúc với SageMaker, và phân tích trade-off chi phí-hiệu suất.\nEvent 4 Tên sự kiện: AWS Mastery #1: AI/ML \u0026amp; GenAI Workshop\nThời gian: Thứ Bảy, ngày 15 tháng 11 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Tổng quan toàn diện về xu hướng thị trường AI/ML, nền tảng SageMaker cho các mô hình ML, Generative AI với Amazon Bedrock, Prompt Engineering, và kiến trúc RAG.\nEvent 5 Tên sự kiện: AWS Mastery 2: AWS DevOps \u0026amp; Modern Operations\nThời gian: Thứ Hai, ngày 17 tháng 11 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Xây dựng tư duy DevOps, quy trình CI/CD hoàn chỉnh với AWS Developer Tools, Infrastructure as Code với CloudFormation và CDK, và thiết lập Observability toàn diện.\nEvent 6 Tên sự kiện: AWS Security Specialty Workshop\nThời gian: Thứ Bảy, ngày 29 tháng 11 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Khám phá sâu 5 Trụ cột Bảo mật cốt lõi (IAM, Detection, Infrastructure, Data Protection, Incident Response), tư duy Zero Trust, và các chiến lược bảo mật hướng đến tự động hóa.\nEvent 7 Tên sự kiện: CloudThinker: Agentic AI \u0026amp; Orchestration on AWS\nThời gian: Thứ Sáu, ngày 05 tháng 12 năm 2025\nĐịa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nVai trò: Người tham dự\nMô tả ngắn: Workshop kỹ thuật nâng cao về AWS Bedrock Agent Core, Agentic Workflows, điều phối multi-agent, tối ưu hóa ngữ cảnh, và thực hành xây dựng prototype CloudThinker Hack.\nNhững sự kiện này mang lại một hành trình học tập toàn diện từ kiến trúc đám mây cơ bản đến các ứng dụng AI/ML nâng cao, đáng kể nâng cao cả chuyên môn kỹ thuật và phát triển chuyên nghiệp trong suốt chương trình thực tập.\n"
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "AWS Mastery #1: AI/ML \u0026amp; GenAI Workshop Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian:Thứ Bảy, ngày 15 tháng 11 năm 2025\nBài thu hoạch “AWS AI/ML \u0026amp; GenAI Workshop” Mục Đích Của Sự Kiện Cung cấp cái nhìn toàn diện về thị trường và các xu hướng Trí tuệ Nhân tạo/Học máy (AI/ML) tại Việt Nam. Hướng dẫn thực hành xây dựng mô hình ML hoàn chỉnh (End-to-end) trên nền tảng Amazon SageMaker. Giới thiệu chuyên sâu về Generative AI với Amazon Bedrock, bao gồm các mô hình nền tảng (Foundation Models), Agents và Guardrails. Trang bị các kỹ năng cần thiết về Prompt Engineering và xây dựng ứng dụng RAG (Retrieval-Augmented Generation). Danh Sách Diễn Giả Đội ngũ chuyên gia AWS (AWS Experts) Nội Dung Nổi Bật Chào mừng \u0026amp; Tổng quan Tổng quan Thị trường: Cập nhật bức tranh toàn cảnh về lĩnh vực trí tuệ nhân tạo và học máy (AI/ML) trong bối cảnh thị trường Việt Nam. Kết nối: Thực hiện hoạt động khởi động (Ice-breaker) và kết nối để tạo không khí thoải mái cho buổi workshop. Tổng quan Dịch vụ AWS AI/ML (SageMaker) Nền tảng ML Toàn diện: Tìm hiểu quy trình làm việc chuẩn trên Amazon SageMaker, từ giai đoạn chuẩn bị dữ liệu (Data preparation), gán nhãn (Labeling) đến huấn luyện (Training) và tinh chỉnh mô hình (Tuning). Tích hợp MLOps: Hướng dẫn tích hợp các quy trình vận hành học máy (MLOps) nhằm tự động hóa quá trình triển khai và quản lý mô hình. Demo SageMaker Studio: Trực tiếp trải nghiệm giao diện và các chức năng của SageMaker Studio thông qua phần trình diễn thực tế. Generative AI với Amazon Bedrock Lựa chọn Mô hình Nền tảng (Foundation Models): So sánh và đưa ra hướng dẫn để chọn các mô hình nền tảng phù hợp như Claude, Llama, Titan dựa trên yêu cầu cụ thể. Kỹ thuật Prompt Engineering: Các phương pháp tối ưu hóa câu lệnh đầu vào, bao gồm Chain-of-Thought (chuỗi suy nghĩ) và Few-shot learning (học từ ít ví dụ). Kiến trúc RAG: Phân tích kiến trúc \u0026ldquo;Retrieval-Augmented Generation\u0026rdquo; và cách tích hợp cơ sở tri thức (Knowledge Base) của doanh nghiệp để tăng cường độ chính xác và tính xác thực cho câu trả lời của AI. Tính năng Nâng cao: Hướng dẫn sử dụng Bedrock Agents cho các luồng công việc phức tạp, đa bước (Multi-step workflows) và Guardrails để thiết lập các rào chắn đảm bảo nội dung an toàn và phù hợp. Demo Trực tiếp: Xây dựng một GenAI Chatbot hoàn chỉnh ngay tại workshop sử dụng Amazon Bedrock. Những Gì Học Được Khả năng của Nền tảng (Platform Capabilities) SageMaker là công cụ mạnh mẽ, được thiết kế để chuẩn hóa và quản lý hiệu quả quy trình làm việc cho các tác vụ Machine Learning truyền thống (dự đoán). Bedrock cung cấp giải pháp tiếp cận GenAI nhanh chóng nhất thông qua API, loại bỏ nhu cầu quản lý cơ sở hạ tầng phức tạp. Triển khai Chiến lược (Strategic Implementation) RAG và Agents là hai công nghệ mũi nhọn giúp chuyển ứng dụng GenAI từ các chức năng chat đơn thuần sang giải quyết các bài toán nghiệp vụ phức tạp của doanh nghiệp. Guardrails là thành phần không thể thiếu để đảm bảo AI hoạt động trong giới hạn an toàn, tuân thủ các quy tắc và chính sách của công ty. Ứng Dụng Vào Công Việc Triển khai MLOps: Áp dụng các quy trình chuẩn hóa đã học trên SageMaker để quản lý vòng đời (lifecycle) của mô hình học máy trong các dự án hiện tại. Xây dựng RAG: Thử nghiệm tích hợp các tài liệu nội bộ (Internal Docs) vào Bedrock Knowledge Base để phát triển trợ lý tra cứu thông tin chuyên biệt. Tối ưu hóa Prompt: Áp dụng kỹ thuật Chain-of-Thought và các kỹ thuật khác để cải thiện đáng kể chất lượng và độ sâu của câu trả lời từ các chatbot hiện có. Đánh giá Mô hình: Sử dụng các tiêu chí đã được hướng dẫn để lựa chọn mô hình nền tảng (Claude so với Llama) tối ưu nhất về chi phí và hiệu suất cho từng trường hợp sử dụng cụ thể. Trải nghiệm trong event Buổi workshop là sự kết hợp cân bằng và hiệu quả giữa Machine Learning truyền thống và Generative AI hiện đại, mang lại một nền tảng kiến thức vững chắc và đầy đủ.\nThực hành \u0026amp; Trình diễn Phần SageMaker Studio walkthrough giúp tôi hình dung rõ ràng về một môi trường làm việc chuyên nghiệp, được chuẩn hóa dành cho Data Scientist. Demo xây dựng Chatbot với Bedrock là một điểm nhấn quan trọng, chứng minh rằng việc tạo ra một ứng dụng GenAI hoàn chỉnh đã trở nên nhanh chóng và dễ tiếp cận hơn bao giờ hết. Thông tin Thị trường Phần giới thiệu về thị trường AI tại Việt Nam đã giúp tôi định vị được vị thế và cơ hội tiềm năng của doanh nghiệp trong xu hướng công nghệ chung. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tóm lại, sự kiện này đã trang bị cho tôi \u0026ldquo;bộ công cụ\u0026rdquo; toàn diện: từ SageMaker cho các mô hình dự đoán (Predictive) đến Bedrock cho các mô hình tạo sinh (Generative), sẵn sàng cho việc triển khai các dự án AI quy mô lớn sắp tới.\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "InsightHR - Workshop Nền tảng Tự động hóa HR Serverless Tổng quan InsightHR là một nền tảng tự động hóa HR hiện đại, hoàn toàn serverless được xây dựng trên AWS, minh họa các phương pháp tốt nhất cho phát triển ứng dụng cloud-native. Workshop này hướng dẫn bạn xây dựng và triển khai một ứng dụng hoàn chỉnh sẵn sàng cho production sử dụng các dịch vụ AWS.\nNhững gì bạn sẽ xây dựng Một hệ thống quản lý HR toàn diện bao gồm:\nQuản lý Nhân viên: Các thao tác CRUD đầy đủ với bộ lọc nâng cao Theo dõi Hiệu suất: Điểm hiệu suất theo quý và quản lý KPI Hệ thống Chấm công: Check-in/check-out thời gian thực với lịch sử theo dõi AI Chatbot: Truy vấn ngôn ngữ tự nhiên được hỗ trợ bởi AWS Bedrock (Claude 3) Dashboard Phân tích: Trực quan hóa hiệu suất tương tác Kiểm soát Truy cập Dựa trên Vai trò: Vai trò Admin, Manager và Employee Xác thực: Email/password và Google OAuth qua AWS Cognito Điểm nổi bật Kiến trúc ✅ 100% Serverless - Không có EC2 instances cần quản lý ✅ Có khả năng mở rộng - Tự động scale theo nhu cầu ✅ Tiết kiệm Chi phí - Chỉ trả tiền cho những gì bạn sử dụng ✅ Bảo mật - Bảo mật tích hợp với Cognito và IAM ✅ Stack Hiện đại - React + TypeScript + Python ✅ Sẵn sàng Production - Giám sát CloudWatch và custom domain Các dịch vụ AWS được sử dụng Frontend: S3 + CloudFront + Route53 Backend: Lambda + API Gateway + DynamoDB Authentication: Cognito User Pools AI/ML: Amazon Bedrock (Claude 3 Haiku) Monitoring: CloudWatch + Synthetics Canaries Security: IAM + ACM (SSL Certificates) Nội dung Workshop Tổng quan Workshop Yêu cầu tiên quyết Kiến trúc Dự án Thiết lập Môi trường AWS Thiết lập Database (DynamoDB) Dịch vụ Xác thực Dịch vụ Backend Phát triển Frontend Triển khai Kiểm thử \u0026amp; Giám sát Dọn dẹp Kết quả Học tập Sau khi hoàn thành workshop này, bạn sẽ học được:\nCách thiết kế và triển khai kiến trúc serverless Các phương pháp tốt nhất cho AWS Lambda và API Gateway Mô hình hóa và tối ưu hóa dữ liệu DynamoDB Luồng xác thực AWS Cognito Tích hợp với AWS Bedrock cho khả năng AI Cấu hình CloudFront CDN Nguyên tắc Infrastructure as Code Chiến lược triển khai production Kỹ thuật tối ưu hóa chi phí Yêu cầu tiên quyết Tài khoản AWS với quyền phù hợp Kiến thức cơ bản về JavaScript/TypeScript và Python Quen thuộc với React framework Hiểu biết về REST APIs AWS CLI đã được cài đặt và cấu hình Thời gian Ước tính Workshop Đầy đủ: 4-6 giờ Chỉ Tính năng Cốt lõi: 2-3 giờ Ước tính Chi phí Chạy workshop này sẽ phát sinh chi phí AWS tối thiểu:\nDynamoDB: ~$0.50/tháng (on-demand pricing) Lambda: Free tier bao phủ hầu hết việc sử dụng S3 + CloudFront: ~$1-2/tháng API Gateway: ~$0.10/tháng Bedrock: ~$0.0004 mỗi truy vấn Tổng cộng: ~$2-5/tháng cho development Nhớ dọn dẹp tài nguyên sau khi hoàn thành workshop để tránh phí tiếp tục.\nHỗ trợ Đối với câu hỏi hoặc vấn đề trong workshop:\nKiểm tra các phần khắc phục sự cố trong mỗi module Xem lại các liên kết tài liệu AWS được cung cấp Tham khảo GitHub repository cho các mẫu code Hãy bắt đầu! 🚀\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5 Áp dụng kiến thức VPC và S3 thông qua các bài lab thực hành Tìm hiểu sâu hơn về AWS RDS với các bài tập thực tế Bắt đầu công việc dịch blog kỹ thuật AWS Khám phá AWS Lambda và các khái niệm serverless computing Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (6/10) Ngày làm việc tại văn phòng\n- Thực hành lab: Tạo VPC tùy chỉnh\n+ Cấu hình public và private subnets\n+ Thiết lập route tables và Internet Gateway\n- Thực hành các thao tác với S3 bucket\n+ Upload và quản lý objects\n+ Cấu hình bucket policies và permissions 06/10/2025 06/10/2025 Bài tập thực hành Thứ Ba (7/10) - Xem xét kết quả VPC lab và ghi chép kiến thức\n- Nghiên cứu hướng dẫn thực hành AWS RDS\n+ Tạo database instance\n+ Cấu hình kết nối\n+ Thiết lập security group 07/10/2025 07/10/2025 AWS RDS Getting Started Thứ Tư (8/10) Ngày làm việc tại văn phòng\n- Thực hành lab: Tạo RDS instance\n+ Khởi chạy MySQL database\n+ Cấu hình security groups\n+ Test kết nối database\n- Giới thiệu về AWS Lambda\n+ Các khái niệm serverless computing\n+ Lambda function cơ bản 08/10/2025 08/10/2025 AWS Lambda Documentation Thứ Năm (9/10) - Tiếp tục khám phá Lambda\n+ Function triggers và events\n+ Lambda execution environment\n+ IAM roles cho Lambda\n- Xem xét các serverless architecture patterns 09/10/2025 09/10/2025 AWS Serverless Thứ Sáu (10/10) - Bắt đầu dịch blog kỹ thuật AWS đầu tiên\n+ Chọn bài blog phù hợp\n+ Bắt đầu công việc dịch\n+ Nghiên cứu thuật ngữ kỹ thuật\n- Xem xét thành tựu tuần và lên kế hoạch tuần tới 10/10/2025 10/10/2025 Các bài blog AWS Kết quả đạt được tuần 5 Triển khai VPC thực tế\nTạo thành công VPC tùy chỉnh với kiến trúc phù hợp Cấu hình public và private subnets chính xác Thiết lập route tables và Internet Gateway Xác thực kết nối mạng và routing Có kinh nghiệm thực tế với các thành phần VPC Kỹ năng thực hành S3\nTạo và cấu hình S3 buckets Upload và quản lý objects thành công Triển khai bucket policies để kiểm soát truy cập Thực hành các thao tác S3 thông qua AWS Console Hiểu các best practices về bảo mật S3 Kinh nghiệm với RDS Database\nKhởi chạy RDS MySQL instance đầu tiên Cấu hình database security groups đúng cách Thiết lập kết nối database Hiểu các khái niệm backup và maintenance của RDS Học cách quản lý database instance Giới thiệu Serverless Computing\nNắm được các khái niệm Lambda và serverless Hiểu function triggers và events Học về Lambda execution environment Khám phá IAM roles cho Lambda functions Xem xét các serverless architecture patterns Khởi đầu dịch Blog\nBắt đầu dịch blog kỹ thuật AWS đầu tiên Nghiên cứu thuật ngữ kỹ thuật AWS bằng tiếng Việt Phát triển quy trình dịch thuật Nâng cao kỹ năng viết kỹ thuật Các thách thức gặp phải VPC lab yêu cầu chú ý cẩn thận đến CIDR blocks của subnet và cấu hình routing Cấu hình security group cho RDS cần nhiều lần thử để kết nối hoạt động Dịch thuật ngữ kỹ thuật AWS trong khi duy trì độ chính xác và rõ ràng Cân bằng thời gian thực hành lab với học lý thuyết Bài học quan trọng Thực hành là cần thiết để củng cố kiến thức lý thuyết về VPC Cấu hình security group đúng cách rất quan trọng cho kết nối RDS Serverless computing đại diện cho sự thay đổi mô hình từ hạ tầng truyền thống Dịch thuật kỹ thuật yêu cầu hiểu sâu về cả khái niệm nguồn và đích Các dịch vụ AWS tích hợp liền mạch khi được cấu hình đúng cách Mục tiêu tuần tới Tiếp tục công việc dịch blog Khám phá thêm Lambda functions và triggers Học về API Gateway và serverless APIs Nghiên cứu CloudWatch cho monitoring và logging Tìm hiểu sâu hơn về IAM với các policies nâng cao "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "AWS Mastery 2: AWS DevOps \u0026amp; Modern Operations Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian:Thứ Hai, ngày 17 tháng 11 năm 2025\nBài thu hoạch “AWS DevOps \u0026amp; Modern Operations\u0026quot; Mục Đích Của Sự Kiện Xây dựng tư duy DevOps và nắm vững cách thức đo lường hiệu suất thông qua các chỉ số quan trọng DORA metrics. Thiết lập quy trình CI/CD hoàn chỉnh, tự động hóa bằng cách sử dụng bộ công cụ AWS Developer Tools. Hiện đại hóa việc quản lý cơ sở hạ tầng bằng mã (Infrastructure as Code - IaC) với CloudFormation và CDK. Triển khai các ứng dụng được đóng gói trong container (Docker) trên các dịch vụ như ECS, EKS và App Runner. Xây dựng hệ thống Khả năng quan sát (Observability) toàn diện cho các ứng dụng phân tán. Danh Sách Diễn Giả Đội ngũ chuyên gia AWS (AWS Experts) (Các chuyên gia chuyên sâu về DevOps, Container và Observability) Nội Dung Nổi Bật Tư duy DevOps \u0026amp; CI/CD DORA Metrics: Nhấn mạnh tầm quan trọng của các chỉ số hiệu suất như Tần suất triển khai (Deployment Frequency), Thời gian thay đổi (Lead Time for Changes) và Thời gian trung bình để phục hồi (MTTR - Mean Time to Recover). Chiến lược Git: So sánh các chiến lược quản lý mã nguồn như GitFlow và Trunk-based development. Tự động hóa Pipeline: Minh họa quy trình CI/CD đầy đủ: từ CodeCommit (lưu trữ mã), CodeBuild (xây dựng/kiểm thử), đến CodeDeploy (triển khai) được điều phối bởi CodePipeline. Chiến lược Triển khai: Giới thiệu các kỹ thuật triển khai an toàn nhằm giảm thiểu rủi ro: Blue/Green, Canary và Rolling updates. Cơ sở hạ tầng dưới dạng Mã (Infrastructure as Code - IaC) CloudFormation: Hướng dẫn quản lý hạ tầng bằng template, bao gồm khái niệm Stacks và cơ chế phát hiện sai lệch (Drift detection). AWS CDK: Sử dụng ngôn ngữ lập trình phổ biến để định nghĩa hạ tầng, tận dụng các \u0026ldquo;Constructs\u0026rdquo; và các mẫu thiết kế có thể tái sử dụng. Lựa chọn IaC: Thảo luận về các tiêu chí để lựa chọn giữa CloudFormation và CDK tùy thuộc vào yêu cầu và quy mô của dự án. Các Dịch vụ Container Phổ rộng Tính toán (Spectrum of Compute): Từ quản lý hình ảnh (image management) bằng ECR đến các tùy chọn điều phối (orchestration): ECS (đơn giản, tích hợp AWS sâu), EKS (chuẩn Kubernetes mở) và App Runner (giải pháp đơn giản hóa tối đa cho web apps/API). Triển khai Microservices: So sánh và trình diễn cách triển khai các dịch vụ nhỏ (microservices) trên các nền tảng khác nhau. Giám sát \u0026amp; Khả năng Quan sát (Monitoring \u0026amp; Observability) Observability Toàn diện: Kết hợp CloudWatch (để thu thập Metrics, Logs, Alarms) và X-Ray (cho Distributed Tracing - truy vết lỗi ứng dụng phân tán) để có cái nhìn sâu sắc và toàn diện về tình trạng hệ thống. Thực hành Tốt nhất: Thiết lập Dashboard giám sát trực quan và quy trình trực chiến (On-call) hiệu quả. Những Gì Học Được Ưu tiên Tự động hóa (Automation First) CI/CD là nền tảng văn hóa giúp giảm thiểu lỗi do con người và tăng tốc độ phát hành sản phẩm. IaC là tiêu chuẩn bắt buộc cho mọi cơ sở hạ tầng hiện đại, đảm bảo môi trường Phát triển/Kiểm thử/Sản xuất (Dev/Test/Prod) luôn đồng nhất và có thể tái tạo. Vận hành Xuất sắc (Operational Excellence) Khả năng Quan sát (Observability) quan trọng hơn Giám sát (Monitoring) đơn thuần, đặc biệt trong kiến trúc Microservices, vì nó cho phép truy vết nguyên nhân lỗi một cách nhanh chóng (tracing). Việc lựa chọn chiến lược triển khai phù hợp (như Blue/Green) là chìa khóa để đạt được thời gian ngừng hoạt động (Downtime) gần như bằng không. Ứng Dụng Vào Công Việc Tái cấu trúc Pipeline: Chuyển đổi các quy trình build thủ công hiện tại sang AWS CodePipeline tích hợp các bước kiểm thử tự động. Áp dụng CDK: Bắt đầu sử dụng AWS CDK để định nghĩa cơ sở hạ tầng cho các dự án mới, từ bỏ thói quen thao tác trực tiếp trên Console. Container hóa: Đóng gói các ứng dụng vào Docker và thử nghiệm triển khai chúng lên AWS App Runner đối với các dịch vụ nhỏ hơn. Thiết lập Truy vết: Tích hợp AWS X-Ray vào ứng dụng để theo dõi độ trễ (latency) và luồng giao tiếp giữa các microservices. Trải nghiệm trong event Sự kiện đã hệ thống hóa kiến thức một cách liền mạch, đi từ định hình tư duy (Mindset) đến giới thiệu các công cụ (Tools) và quy trình vận hành (Operations).\nQuy trình Tích hợp Phần demo \u0026ldquo;Full CI/CD pipeline walkthrough\u0026rdquo; rất ấn tượng, giúp tôi hình dung rõ ràng toàn bộ hành trình của mã nguồn từ máy lập trình viên đến môi trường Production. Tôi đã hiểu rõ sự khác biệt và các trường hợp sử dụng cụ thể của ECS so với EKS, giúp tăng sự tự tin khi đề xuất các giải pháp container hóa cho công ty. Tính Thực tiễn Cao Các bài học về Deployment strategies (như Feature flags, Canary) mang tính ứng dụng thực tế cao, giải quyết được vấn đề \u0026ldquo;ngại triển khai\u0026rdquo; của đội ngũ. Phần định hướng nghề nghiệp (Career roadmap) cuối giờ cung cấp lộ trình phát triển kỹ năng DevOps rõ ràng. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tóm lại, buổi workshop đã làm rõ mối liên kết chặt chẽ và không thể tách rời giữa Mã nguồn (Code), Cơ sở hạ tầng (IaC) và Khả năng quan sát (Observability) trong vận hành hiện đại.\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6 Tham dự Workshop Data Science on AWS tại Đại học FPT Tiếp tục công việc dịch blog AWS Khám phá các dịch vụ data analytics của AWS Học về API Gateway và serverless APIs Tìm hiểu sâu hơn về CloudWatch monitoring Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (13/10) - Tiếp tục công việc dịch blog\n+ Dịch các phần kỹ thuật\n+ Xem xét độ chính xác thuật ngữ\n- Nghiên cứu tài liệu API Gateway\n+ Các khái niệm REST API\n+ Tích hợp API Gateway với Lambda 13/10/2025 13/10/2025 AWS API Gateway Thứ Ba (14/10) - Học về CloudWatch monitoring\n+ Metrics và alarms\n+ Log groups và streams\n+ CloudWatch dashboards\n- Xem xét các serverless API patterns 14/10/2025 14/10/2025 AWS CloudWatch Thứ Tư (15/10) - Chuẩn bị cho workshop Data Science\n+ Ôn tập các khái niệm data science\n+ Nghiên cứu tổng quan AWS data services\n- Tiếp tục tiến độ dịch blog 15/10/2025 15/10/2025 Tài liệu workshop Thứ Năm (16/10) Workshop Data Science on AWS - Đại học FPT\nThời gian: 9:30 AM - 11:45 AM\nDiễn giả: Văn Hoàng Kha \u0026amp; Bạch Doãn Vương (AWS Community Builders)\nNội dung Workshop:\n- Giới thiệu \u0026amp; Tầm quan trọng của Cloud trong Data Science\n- Data Science pipeline trên AWS (S3, Glue, SageMaker)\n- Demo 1: Xử lý dữ liệu với AWS Glue (IMDb dataset)\n- Demo 2: Sentiment Analysis với SageMaker\n- Thảo luận: So sánh Cloud vs On-premise về chi phí \u0026amp; hiệu suất\n- Hướng dẫn dự án sau workshop 16/10/2025 16/10/2025 Workshop tại FPT University Thứ Sáu (17/10) - Xem xét kiến thức và ghi chú từ workshop\n- Nghiên cứu thêm về AWS Glue và SageMaker\n+ Các khái niệm ETL job\n+ SageMaker notebook instances\n- Hoàn thành bản nháp dịch blog 17/10/2025 17/10/2025 Ghi chú workshop Kết quả đạt được tuần 6 Workshop Data Science on AWS\nTham dự workshop toàn diện tại Đại học FPT Học về Data Science pipeline trên AWS Hiểu AWS Glue cho xử lý dữ liệu và ETL Khám phá Amazon SageMaker cho training ML model Chứng kiến các demo trực tiếp với dataset thực tế (IMDb) Có cái nhìn về so sánh cloud vs on-premise Kết nối với AWS Community Builders Nhận hướng dẫn cho các dự án sau workshop Kiến thức về AWS Data Services\nHiểu vai trò của S3 trong data lakes Học AWS Glue cho các thao tác ETL Khám phá khả năng của SageMaker cho ML workflows Nắm được kiến trúc data processing pipeline Hiểu các cân nhắc về chi phí và hiệu suất API Gateway và Serverless APIs\nHọc các khái niệm REST API với API Gateway Hiểu tích hợp API Gateway với Lambda Khám phá API deployment và stages Nghiên cứu API authentication và authorization Xem xét các serverless API architecture patterns CloudWatch Monitoring\nHọc về metrics và alarms Hiểu log groups và streams Khám phá CloudWatch dashboards Nghiên cứu monitoring best practices Hiểu các khái niệm observability Tiến độ dịch Blog\nĐạt tiến độ đáng kể trong bản dịch blog đầu tiên Tinh chỉnh bản dịch thuật ngữ kỹ thuật Hoàn thành bản nháp dịch blog Nâng cao kỹ năng viết kỹ thuật bằng tiếng Việt Các thách thức gặp phải Workshop đề cập các chủ đề nâng cao nhanh chóng - yêu cầu tập trung cao Hiểu các khái niệm ETL và cấu hình AWS Glue job Cân bằng việc học từ workshop với công việc dịch blog đang tiến hành Dịch thuật ngữ data science phức tạp một cách chính xác Bài học quan trọng AWS cung cấp nền tảng data science và ML toàn diện AWS Glue đơn giản hóa các thao tác ETL đáng kể SageMaker cho phép ML workflows từ đầu đến cuối Cloud cung cấp tính linh hoạt và khả năng mở rộng cho data science workloads Các demo thực hành vô cùng quý giá để hiểu các dịch vụ phức tạp Community builders cung cấp insights thực tế từ thế giới thực Mục tiêu tuần tới Hoàn thiện và xuất bản bản dịch blog đầu tiên Thực hành AWS Glue với sample datasets Khám phá SageMaker notebook instances Tiếp tục thực hành Lambda và API Gateway Xem xét và củng cố kiến thức data analytics "
},
{
	"uri": "//localhost:1313/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập với Chương trình AWS First Cloud Journey từ tháng 9 năm 2025 đến tháng 12 năm 2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức điện toán đám mây trong một môi trường học tập có cấu trúc tập trung vào các dịch vụ và công nghệ AWS.\nTôi đã tham gia các hoạt động học tập AWS toàn diện, bao gồm các bài thực hành với các dịch vụ AWS cốt lõi (EC2, S3, VPC, RDS, Lambda), tham dự nhiều sự kiện và workshop của AWS, dịch các blog kỹ thuật AWS từ tiếng Anh sang tiếng Việt, và hợp tác trong dự án nhóm triển khai giải pháp đám mây. Qua các hoạt động này, tôi đã cải thiện kỹ năng kiến trúc đám mây, tài liệu kỹ thuật, dịch thuật, giải quyết vấn đề và làm việc nhóm.\nVề tác phong, tôi luôn hoàn thành các mục tiêu học tập hàng tuần, duy trì worklog chi tiết, tích cực tham gia các sự kiện cộng đồng AWS, và hợp tác hiệu quả với các thành viên nhóm trong dự án cuối kỳ.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "** AWS Security Specialty Workshop** Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian:Thứ Bảy, ngày 29 tháng 11 năm 2025\nBài thu hoạch “AWS Security Specialty Workshop” Mục Đích Của Sự Kiện Hiểu sâu về vai trò của Trụ cột Bảo mật (Security Pillar) trong Khung kiến trúc Well-Architected của AWS. Nắm vững 5 Trụ cột Bảo mật cốt lõi: Quản lý Định danh (IAM), Phát hiện (Detection), Bảo mật Hạ tầng (Infrastructure), Bảo vệ Dữ liệu (Data Protection), và Phản ứng Sự cố (Incident Response). Cập nhật các mối đe dọa an ninh mạng hàng đầu đang tồn tại trong môi trường Cloud tại thị trường Việt Nam. Thực hành các kỹ năng như rà soát quyền hạn (IAM) và xây dựng quy trình phản ứng sự cố (IR Playbook). Danh Sách Diễn Giả Đội ngũ chuyên gia bảo mật AWS (AWS Security Experts) (Chuyên sâu về kiến trúc bảo mật và tuân thủ) Nội Dung Nổi Bật Nền tảng \u0026amp; Định danh (Trụ cột 1) Nguyên tắc Cốt lõi: Yêu cầu áp dụng nghiêm ngặt các nguyên tắc Đặc quyền Tối thiểu (Least Privilege), Zero Trust (Không tin tưởng mặc định), và Bảo mật Nhiều lớp (Defense in Depth). IAM Hiện đại: Chuyển đổi từ việc sử dụng IAM Users (với thông tin xác thực dài hạn) sang sử dụng IAM Roles và AWS Identity Center (SSO) để quản lý truy cập tập trung. Kiểm soát Truy cập: Sử dụng Service Control Policies (SCP) và Permission Boundaries để giới hạn phạm vi quyền hạn trong các môi trường đa tài khoản (multi-account). Demo Thực hành Nhỏ: Trình diễn cách xác thực (Validate) Chính sách IAM và mô phỏng quyền truy cập để phát hiện các lỗi cấu hình bảo mật. Phát hiện \u0026amp; Hạ tầng (Trụ cột 2 \u0026amp; 3) Giám sát Liên tục: Kích hoạt các dịch vụ như CloudTrail (ở cấp độ toàn tổ chức), GuardDuty và Security Hub để giám sát và đánh giá bảo mật không ngừng nghỉ. Chiến lược Ghi nhật ký: Yêu cầu ghi lại nhật ký ở mọi tầng của hệ thống: VPC Flow Logs (mạng), ALB logs (ứng dụng) và S3 logs (lưu trữ). Bảo mật Mạng: Thực hiện phân đoạn mạng (Segmentation) với VPC, kết hợp sử dụng Security Groups và NACLs. Bảo vệ khu vực biên bằng WAF, Shield và Network Firewall. Bảo vệ Dữ liệu \u0026amp; Phản ứng Sự cố (Trụ cột 4 \u0026amp; 5) Mã hóa: Thực hiện mã hóa dữ liệu trong quá trình truyền tải (in-transit) và dữ liệu đang lưu trữ (at-rest) trên các dịch vụ như S3, EBS, RDS, sử dụng dịch vụ KMS (Key Management Service). Quản lý Bí mật: Loại bỏ việc mã hóa cứng (hard-code) thông tin xác thực bằng cách sử dụng Secrets Manager và Parameter Store, kết hợp cơ chế xoay vòng (rotation) tự động. Tự động hóa Phản ứng Sự cố: Xây dựng các kịch bản phản ứng (Playbook) cho các sự cố thường gặp (như lộ khóa truy cập, mã độc) và tự động hóa quy trình cô lập tài nguyên bị ảnh hưởng bằng Lambda/Step Functions. Những Gì Học Được Tư duy Zero Trust Định danh là Hàng rào: Trong môi trường Cloud, Định danh (Identity) đã trở thành rào cản bảo vệ quan trọng nhất, thay thế cho địa chỉ IP truyền thống. Luôn tuân thủ nguyên tắc: Không bao giờ tin tưởng mặc định, phải luôn xác thực mọi yêu cầu và chỉ cấp quyền tối thiểu cần thiết. Tự động hóa là Cốt lõi (Automation is Key) Bảo mật thủ công không thể theo kịp tốc độ triển khai của Cloud. Cần phải áp dụng các phương pháp như Detection-as-Code và Auto-remediation (tự động khắc phục) để giảm thiểu rủi ro do lỗi con người và sự chậm trễ. Ứng Dụng Vào Công Việc Kiểm tra IAM: Rà soát lại toàn bộ IAM User, xóa bỏ các khóa truy cập cũ (old keys) và chuyển đổi các ứng dụng sang sử dụng IAM Role để tăng cường bảo mật. Kích hoạt GuardDuty: Bật dịch vụ GuardDuty trên tất cả các khu vực (region) và tài khoản để phát hiện sớm các hành vi truy cập và hoạt động bất thường. Triển khai Secrets Manager: Thay thế các tệp cấu hình (config file) chứa mật khẩu cơ sở dữ liệu bằng cách sử dụng lời gọi API tới Secrets Manager. Xây dựng IR Playbook: Viết quy trình xử lý sự cố chi tiết cho tình huống \u0026ldquo;IAM Key bị lộ\u0026rdquo; và thực hiện diễn tập với đội ngũ kỹ thuật. Trải nghiệm trong event Buổi workshop đi sâu vào chi tiết kỹ thuật, bao phủ toàn diện các khía cạnh bảo mật thiết yếu mà một kỹ sư Cloud hiện đại cần phải nắm vững.\nKhung làm việc Toàn diện Việc chia nội dung theo 5 Trụ cột Bảo mật đã giúp tôi hệ thống hóa lại các kiến thức bảo mật vốn rời rạc trước đây thành một khung chuẩn chỉnh, dễ áp dụng. Phần thảo luận về Các mối đe dọa hàng đầu tại Việt Nam mang tính thực tế cao, giúp đội ngũ nhận diện được các rủi ro cụ thể phù hợp với bối cảnh trong nước. Thực hành Ứng dụng Các demo về Access Analyzer và công cụ Validate IAM Policy rất hữu ích, trực tiếp giải quyết được khó khăn hàng ngày khi gỡ lỗi quyền hạn (permissions). Phần Incident Response đã làm rõ rằng \u0026ldquo;phát hiện\u0026rdquo; (detection) chỉ là một phần, \u0026ldquo;phản ứng\u0026rdquo; (response) tự động và nhanh chóng mới là yếu tố quyết định sự an toàn của hệ thống. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện đã khẳng định rõ ràng rằng bảo mật không phải là rào cản (blocker) mà là yếu tố cho phép doanh nghiệp vận hành nhanh hơn và an toàn hơn (enabler).\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7 Hoàn thiện và xuất bản bản dịch blog AWS đầu tiên Khám phá các dịch vụ container của AWS (ECS, ECR) Học về các best practices bảo mật AWS Xem xét và củng cố kiến thức các tuần trước Bắt đầu bản dịch blog thứ hai Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (20/10) - Hoàn thiện bản dịch blog đầu tiên\n+ Xem xét và chỉnh sửa cuối cùng\n+ Xác minh độ chính xác kỹ thuật\n+ Định dạng để xuất bản\n- Xuất bản bản dịch blog đầu tiên 20/10/2025 20/10/2025 Công việc dịch blog Thứ Ba (21/10) - Giới thiệu về các dịch vụ container của AWS\n+ Ôn tập Docker fundamentals\n+ Tổng quan Amazon ECS\n+ Amazon ECR (Elastic Container Registry)\n- Nghiên cứu các khái niệm container orchestration 21/10/2025 21/10/2025 AWS ECS Documentation Thứ Tư (22/10) - Tiếp tục tìm hiểu sâu về ECS\n+ ECS task definitions\n+ ECS services và clusters\n+ Fargate vs EC2 launch types\n- Xem xét container networking 22/10/2025 22/10/2025 AWS Fargate Thứ Năm (23/10) - AWS security best practices\n+ Xem xét IAM policies và roles\n+ Security groups best practices\n+ Mã hóa at rest và in transit\n+ Tổng quan AWS security services 23/10/2025 23/10/2025 AWS Security Best Practices Thứ Sáu (24/10) - Xem xét và củng cố\n+ Ôn lại các khái niệm VPC\n+ Xem xét serverless architecture\n+ Củng cố kiến thức data services\n- Chọn và bắt đầu bản dịch blog thứ hai 24/10/2025 24/10/2025 Tài liệu các tuần trước Kết quả đạt được tuần 7 Cột mốc dịch Blog\nHoàn thành thành công bản dịch blog AWS đầu tiên Xuất bản bài blog đã dịch Thiết lập quy trình dịch và tiêu chuẩn chất lượng Nâng cao kỹ năng viết kỹ thuật ở cả hai ngôn ngữ Bắt đầu bản dịch blog thứ hai Kiến thức về Container Services\nHiểu Docker fundamentals và containerization Học kiến trúc và thành phần Amazon ECS Khám phá Amazon ECR cho quản lý container image Hiểu ECS task definitions và services So sánh Fargate vs EC2 launch types Nắm được các khái niệm container orchestration Security Best Practices\nXem xét sâu IAM policies và roles Hiểu best practices cấu hình security group Học về các tùy chọn mã hóa (at rest và in transit) Khám phá AWS security services (GuardDuty, Security Hub, v.v.) Hiểu nguyên tắc least privilege Học về AWS shared responsibility model Củng cố kiến thức\nXem xét các khái niệm VPC networking Củng cố hiểu biết về serverless architecture Tăng cường kiến thức data services Kết nối các khái niệm giữa các dịch vụ AWS khác nhau Xác định các lĩnh vực cần nghiên cứu sâu hơn Các thách thức gặp phải Các khái niệm container orchestration yêu cầu nghiên cứu cẩn thận Hiểu sự khác biệt giữa ECS và EKS Cân bằng việc học mới với xem xét và củng cố Quản lý thời gian giữa dịch blog và học kỹ thuật Bài học quan trọng Containers cung cấp tính nhất quán giữa môi trường development và production ECS đơn giản hóa container orchestration trên AWS Fargate loại bỏ gánh nặng quản lý hạ tầng Bảo mật nên được xem xét ở mọi tầng của kiến trúc Xem xét và củng cố thường xuyên tăng cường hiểu biết Công việc dịch thuật làm sâu sắc thêm hiểu biết kỹ thuật Mục tiêu tuần tới Tiếp tục bản dịch blog thứ hai Khám phá AWS EKS (Kubernetes trên AWS) Học về AWS Well-Architected Framework Nghiên cứu các chiến lược tối ưu hóa chi phí AWS Chuẩn bị cho kỳ thi giữa kỳ sắp tới "
},
{
	"uri": "//localhost:1313/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường học tập\nChương trình AWS First Cloud Journey cung cấp một môi trường học tập tự định hướng xuất sắc với tài nguyên toàn diện. Sự kết hợp giữa các bài thực hành, tài liệu và dịch vụ AWS thực tế tạo ra trải nghiệm học tập đám mây chân thực. Cấu trúc chương trình cho phép linh hoạt trong khi vẫn duy trì các mục tiêu và cột mốc học tập rõ ràng.\n2. Sự hỗ trợ từ Mentor / Team chương trình\nTeam FCJ và các mentor cung cấp hướng dẫn xuất sắc thông qua các sự kiện và workshop được tổ chức tốt. Các buổi AWS Cloud Mastery Series đặc biệt có giá trị, cung cấp kiến thức chuyên sâu về AI/ML, DevOps và Security. Các diễn giả từ AWS và đối tác ngành chia sẻ những hiểu biết thực tế bổ sung hiệu quả cho tài liệu tự học.\n3. Sự phù hợp với chuyên ngành \u0026amp; mục tiêu nghề nghiệp\nNội dung chương trình phù hợp hoàn hảo với chương trình giảng dạy điện toán đám mây hiện đại và nhu cầu ngành. Học các dịch vụ AWS thực hành kết hợp với dịch blog kỹ thuật cung cấp cả chiều sâu kỹ thuật và kỹ năng giao tiếp cần thiết cho vai trò kỹ sư đám mây. Thành phần dự án nhóm bổ sung kinh nghiệm hợp tác có giá trị.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nChương trình cung cấp cơ hội học tập đa dạng: kỹ năng kỹ thuật thông qua khám phá dịch vụ AWS, kỹ năng tài liệu thông qua duy trì worklog, kỹ năng dịch thuật thông qua dự án blog, và làm việc nhóm thông qua dự án cuối kỳ. Tham dự nhiều sự kiện AWS (Cloud Day, Data Science Workshop, Cloud Mastery Series) cung cấp tiếp xúc với xu hướng ngành hiện tại và cơ hội networking.\n5. Cộng đồng \u0026amp; Hợp tác\nCộng đồng AWS FCJ hỗ trợ và hợp tác tốt. Các sự kiện như buổi Kick-off và Cloud Mastery Series tạo cơ hội kết nối với những người học khác, chuyên gia AWS và các chuyên gia ngành. Giai đoạn dự án nhóm thúc đẩy sự hợp tác mạnh mẽ và chia sẻ kiến thức giữa các thành viên.\n6. Cấu trúc chương trình \u0026amp; Tài nguyên\nChương trình cung cấp cấu trúc rõ ràng với các mục tiêu học tập hàng tuần, quyền truy cập tài liệu AWS toàn diện và cơ hội thực hành thực tế. Sự tiến triển từ các dịch vụ nền tảng đến các chủ đề nâng cao (AI/ML, DevOps, Security) được thiết kế tốt. Quyền truy cập vào các dịch vụ AWS để thực hành là vô giá.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nNhững khía cạnh hài lòng nhất là trải nghiệm thực hành với các dịch vụ AWS thực tế và tham dự AWS Cloud Mastery Series. Có thể triển khai cơ sở hạ tầng đám mây thực tế và thấy các khái niệm từ tài liệu trở nên sống động là vô cùng bổ ích. Các cơ hội networking tại sự kiện AWS và kết nối với các chuyên gia ngành cũng là điểm nổi bật.\nĐiều bạn nghĩ chương trình cần cải thiện cho các thành viên sau?\nNên cung cấp hướng dẫn có cấu trúc hơn cho giai đoạn dự án nhóm, có thể với các điểm kiểm tra cột mốc. Các workshop bổ sung về chứng chỉ AWS cụ thể (như Cloud Practitioner hoặc Solutions Architect Associate) sẽ có giá trị. Nhiều cơ hội hơn cho sự hợp tác và chia sẻ kiến thức giữa các thành viên trong suốt chương trình sẽ nâng cao trải nghiệm học tập.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ tham gia chương trình này không? Vì sao?\nChắc chắn có. Chương trình AWS FCJ cung cấp trải nghiệm học tập đám mây thực hành vô song với quyền truy cập vào các dịch vụ AWS thực tế, các workshop do chuyên gia dẫn dắt và một cộng đồng hỗ trợ. Nó hoàn hảo cho bất kỳ ai nghiêm túc về việc xây dựng sự nghiệp trong điện toán đám mây. Sự kết hợp giữa học tập tự định hướng và các sự kiện có cấu trúc cung cấp sự linh hoạt trong khi đảm bảo phát triển kỹ năng toàn diện.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm chương trình?\nGiới thiệu hệ thống ghép đôi mentor nơi các thành viên có kinh nghiệm có thể hướng dẫn người mới Tạo cơ sở kiến thức hoặc wiki chung nơi các thành viên có thể ghi lại giải pháp cho các thách thức phổ biến Tổ chức các buổi gặp mặt trực tuyến thường xuyên hơn để các thành viên chia sẻ tiến độ và kiến thức Cung cấp ý tưởng dự án mẫu hoặc template để giúp khởi động giai đoạn dự án nhóm Xem xét thêm tài nguyên chuẩn bị thi chứng chỉ AWS và nhóm học tập Bạn có muốn tiếp tục chương trình này trong tương lai?\nCó, tôi rất quan tâm đến việc tiếp tục với các lộ trình học AWS nâng cao, có thể tập trung vào các lĩnh vực chuyên biệt như AI/ML trên AWS, thực hành DevOps hoặc bảo mật đám mây. Một mạng lưới cựu sinh viên hoặc track nâng cao cho các sinh viên tốt nghiệp FCJ sẽ có giá trị cho việc học tập và phát triển nghề nghiệp liên tục.\nGóp ý khác (tự do chia sẻ):\nChương trình AWS First Cloud Journey vượt quá mong đợi của tôi về độ sâu học tập và kinh nghiệm thực tế. Sự kết hợp giữa tự học, bài thực hành, workshop do chuyên gia dẫn dắt và hợp tác nhóm tạo ra một hành trình học tập toàn diện. Cảm ơn đặc biệt đến team FCJ vì đã tổ chức các sự kiện chất lượng cao và cung cấp hỗ trợ liên tục trong suốt chương trình. Trải nghiệm này đã củng cố đáng kể kỹ năng điện toán đám mây và sự sẵn sàng nghề nghiệp của tôi.\n"
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.7-event7/",
	"title": "Event7",
	"tags": [],
	"description": "",
	"content": "CloudThinker: Agentic AI \u0026amp; Orchestration trên AWS Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian:Thứ Sáu, ngày 05 tháng 12 năm 2025\nBài thu hoạch “CloudThinker: Agentic AI \u0026amp; Orchestration trên AWS” Mục Đích Của Sự Kiện Nghiên cứu chuyên sâu về AWS Bedrock Agent Core và các khả năng cốt lõi của dịch vụ này. Khám phá các trường hợp sử dụng thực tế (Use Case) để xây dựng Quy trình làm việc của Tác nhân (Agentic Workflows). Nắm vững các khái niệm nâng cao như Điều phối Tác nhân (Agentic Orchestration) và Tối ưu hóa Ngữ cảnh (Context Optimization) ở cấp độ kỹ thuật chuyên sâu (L300). Trải nghiệm thực hành trực tiếp thông qua workshop CloudThinker Hack. Danh Sách Diễn Giả Anh Nguyễn Gia Hưng – Head of Solutions Architect, AWS Anh Kiên Nguyễn – Solutions Architect, AWS Anh Việt Phạm – Founder \u0026amp; CEO Anh Thắng Tôn – Co-founder \u0026amp; COO, CloudThinker Anh Henry Bùi – Head of Engineering, CloudThinker Anh Kha Văn – Điều phối Workshop Nội Dung Nổi Bật 1. Nền tảng AWS và Agentic AI Khai mạc: Anh Nguyễn Gia Hưng mở đầu sự kiện, nhấn mạnh vai trò ngày càng quan trọng của Agentic AI trong bối cảnh công nghệ đám mây hiện nay. Bedrock Agent Core: Anh Kiên Nguyễn cung cấp tổng quan kỹ thuật về AWS Bedrock Agent Core, giải thích cách dịch vụ này đơn giản hóa quá trình tạo ra các Agent có khả năng lập kế hoạch và thực thi nhiệm vụ thông qua các lời gọi API. 2. Ứng dụng Thực tế Xây dựng Agentic Workflow: Anh Việt Phạm trình diễn một trường hợp sử dụng cụ thể, minh họa quy trình thiết kế và triển khai một luồng công việc tác nhân (Agentic workflow) từ đầu đến cuối trên nền tảng AWS. Giới thiệu CloudThinker: Anh Thắng Tôn giới thiệu về hệ sinh thái CloudThinker và tầm nhìn của công ty đối với các giải pháp đám mây tích hợp AI. 3. Chuyên sâu (Level 300) Điều phối Tác nhân \u0026amp; Tối ưu hóa Ngữ cảnh: Đây là phần chuyên sâu kỹ thuật của buổi sáng. Anh Henry Bùi thảo luận về các chiến lược nâng cao để điều phối nhiều tác nhân (orchestrate multi-agents) và tối ưu hóa ngữ cảnh trong Amazon Bedrock, đảm bảo độ chính xác cao trong các tương tác phức tạp. 4. Thực hành (Hands-on) CloudThinker Hack: Dưới sự hướng dẫn của anh Kha Văn, phiên thực hành kéo dài 60 phút cho phép người tham dự áp dụng trực tiếp kiến thức đã học để xây dựng một prototype agent sử dụng framework của CloudThinker và dịch vụ AWS. Bài học chính (Key Takeaways) Sự Tiến hóa của AI Từ Chat sang Hành động: Lĩnh vực công nghệ đang chứng kiến sự chuyển dịch mạnh mẽ từ các chatbot chỉ phản hồi thụ động sang các Agent chủ động có khả năng thực hiện điều phối phức tạp và gọi API để hoàn thành nhiệm vụ. Ngữ cảnh là Yếu tố then chốt: Khi các quy trình làm việc ngày càng phức tạp, cửa sổ ngữ cảnh (context window) tiêu chuẩn không còn đủ. Việc áp dụng các chiến lược \u0026ldquo;Tối ưu hóa ngữ cảnh\u0026rdquo; là thiết yếu để giảm chi phí vận hành và đồng thời tăng độ chính xác của Agent. Kiến trúc Mô hình Điều phối: Việc quản lý một hệ thống bao gồm nhiều Agent đòi hỏi một lớp Điều phối (Orchestration Layer) mạnh mẽ để phân bổ và quyết định Agent nào sẽ xử lý phần nào của yêu cầu người dùng. Ứng dụng vào công việc Prototype Agent: Sử dụng AWS Bedrock Agent để xây dựng các công cụ nội bộ đơn giản, có khả năng kết nối với các API sẵn có của công ty (ví dụ: kiểm tra tình trạng server hoặc thống kê ngày phép). Nghiên cứu mô hình Ngữ cảnh: Nghiên cứu sâu các kỹ thuật tối ưu hóa ngữ cảnh được chia sẻ bởi anh Henry Bùi để áp dụng vào các hệ thống RAG hiện tại nhằm cải thiện hiệu suất. Tham gia Hackathon: Khuyến khích đội ngũ kỹ thuật tham gia các buổi hackathon thực tế tương tự để cập nhật nhanh chóng và trực quan nhất các tính năng mới của AWS. Trải nghiệm sự kiện Sự kiện có tính kỹ thuật rất cao và tập trung chuyên sâu vào một chủ đề duy nhất.\nChiều sâu Kỹ thuật: Phiên L300 về Orchestration đặc biệt có giá trị, giúp tôi hiểu được cách mở rộng ứng dụng AI vượt ra ngoài các bản demo đơn giản. Tính Tương tác: Phần \u0026ldquo;CloudThinker Hack\u0026rdquo; đã giúp tôi củng cố ngay lập tức kiến thức lý thuyết bằng thực hành, biến đây thành một trong những buổi học hiệu quả nhất. Một số hình ảnh khi tham gia sự kiện Thêm hình ảnh sự kiện của bạn tại đây Tổng thể, sự kiện này đã cung cấp một khung kiến trúc rõ ràng cho việc phát triển các Hệ thống AI Tác nhân có khả năng điều phối và thực thi phức tạp trên nền tảng đám mây AWS.\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8 Chuẩn bị toàn diện cho kỳ thi giữa kỳ AWS Cloud Practitioner Ôn tập tất cả các dịch vụ AWS đã học trong các tuần trước Củng cố hiểu biết về AWS fundamentals Luyện tập câu hỏi và tình huống kiểu thi Hoàn thành thành công kỳ thi giữa kỳ Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (27/10) Ôn thi giữa kỳ - Compute \u0026amp; Storage\n- Ôn tập EC2 fundamentals\n+ Instance types và pricing\n+ AMI và EBS concepts\n+ Security groups\n- Ôn tập S3 storage\n+ Storage classes\n+ Bucket policies\n+ Versioning và lifecycle 27/10/2025 27/10/2025 Tài liệu AWS Cloud Practitioner Thứ Ba (28/10) Ôn thi giữa kỳ - Networking \u0026amp; Database\n- Ôn tập VPC concepts\n+ Subnets và routing\n+ Internet Gateway và NAT\n+ Security groups vs NACLs\n- Ôn tập RDS và database services\n+ Database engines\n+ Backup và restore\n- Đăng ký ngày làm việc văn phòng (29/10) 28/10/2025 28/10/2025 Tài liệu AWS Thứ Tư (29/10) Nghỉ - Mưa lớn\n- Không thể đến văn phòng do thời tiết xấu\n- Học nhẹ tại nhà\n+ Xem lại ghi chú\n+ Luyện tập câu hỏi 29/10/2025 29/10/2025 Ghi chú học tập Thứ Năm (30/10) Ngày làm việc văn phòng - Ôn tập cuối cùng\n- Chuẩn bị thi tập trung\n- Ôn tập serverless services\n+ Lambda functions\n+ API Gateway\n- Ôn tập data analytics services\n+ AWS Glue\n+ SageMaker basics\n- Luyện tập câu hỏi thi\n- Giải đáp thắc mắc với mentors\n- Đăng ký thi giữa kỳ (31/10) 30/10/2025 30/10/2025 Tài liệu chuẩn bị thi Thứ Sáu (31/10) Thi giữa kỳ AWS Cloud Practitioner\n- Hoàn thành kỳ thi giữa kỳ\n- Nội dung thi bao gồm:\n+ AWS global infrastructure\n+ Core services (EC2, S3, VPC, RDS)\n+ Serverless computing\n+ Security và IAM\n+ Pricing và billing\n+ AWS Well-Architected Framework basics 31/10/2025 31/10/2025 Đề thi giữa kỳ Kết quả đạt được tuần 8 Chuẩn bị thi toàn diện\nÔn tập có hệ thống tất cả các dịch vụ AWS từ các tuần trước Củng cố hiểu biết về AWS fundamentals Luyện tập câu hỏi và tình huống kiểu thi Xác định và giải quyết các khoảng trống kiến thức Chuẩn bị ghi chú học tập toàn diện Ôn tập các dịch vụ AWS\nCompute: EC2 instance types, pricing models, AMI, EBS Storage: S3 storage classes, bucket policies, lifecycle management Networking: VPC architecture, subnets, routing, security Database: RDS engines, backup strategies, read replicas Serverless: Lambda functions, API Gateway, event-driven architecture Data Analytics: AWS Glue ETL, SageMaker basics Security: IAM policies, roles, security groups, encryption Monitoring: CloudWatch metrics, alarms, logs Hoàn thành thi giữa kỳ\nHoàn thành thành công kỳ thi giữa kỳ AWS Cloud Practitioner Thể hiện hiểu biết về các dịch vụ AWS cốt lõi Áp dụng kiến thức vào các tình huống thực tế Cho thấy sự hiểu biết về AWS best practices Khả năng thích ứng\nXử lý gián đoạn thời tiết bất ngờ một cách chuyên nghiệp Điều chỉnh lịch học để phù hợp với hoàn cảnh Duy trì sự tập trung bất chấp thách thức Các thách thức gặp phải Mưa lớn vào thứ Tư làm gián đoạn kế hoạch làm việc tại văn phòng Áp lực thời gian để ôn tập tài liệu rộng trước kỳ thi Cân bằng giữa độ rộng và độ sâu trong chuẩn bị thi Quản lý stress thi cử trong khi duy trì hiệu quả học tập Bài học quan trọng Ôn tập có hệ thống là cần thiết cho chuẩn bị thi toàn diện Kinh nghiệm thực hành hỗ trợ đáng kể cho hiểu biết lý thuyết Các dịch vụ AWS có liên kết với nhau - hiểu mối quan hệ là quan trọng Ghi chép và lưu trữ thường xuyên trong suốt quá trình học mang lại hiệu quả Khả năng thích ứng quan trọng khi đối mặt với hoàn cảnh bất ngờ Mục tiêu tuần tới Tiếp tục lịch học AWS bình thường sau kỳ thi Tiếp tục công việc dịch blog thứ hai Bắt đầu chuẩn bị dự án nhóm (bắt đầu Tuần 9) Khám phá các dịch vụ AWS DevOps Học về các chiến lược tối ưu hóa chi phí AWS "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9 Chuyển đổi từ học AWS cá nhân sang làm việc dự án nhóm Thành lập nhóm dự án và thiết lập quy trình cộng tác Xác định phạm vi và yêu cầu dự án nhóm Bắt đầu lập kế hoạch và thiết kế kiến trúc dự án Tiếp tục công việc dịch blog Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (3/11) - Xem xét và suy ngẫm sau kỳ thi giữa kỳ\n- Tiếp tục bản dịch blog thứ hai\n+ Dịch các phần kỹ thuật\n+ Xem xét thuật ngữ\n- Chuẩn bị cho khởi động dự án nhóm 03/11/2025 03/11/2025 Công việc dịch blog Thứ Ba (4/11) - Chuẩn bị cuối cùng cho dự án nhóm\n- Xem xét các dịch vụ AWS cho ý tưởng dự án\n- Nghiên cứu các kiến trúc dự án tiềm năng\n+ Serverless applications\n+ Web applications trên AWS\n+ Data processing pipelines 04/11/2025 04/11/2025 AWS architecture patterns Thứ Tư (5/11) Khởi động dự án nhóm\n- Thành lập nhóm và giới thiệu\n- Buổi brainstorming dự án ban đầu\n- Thảo luận ý tưởng và phạm vi dự án\n- Xác định điểm mạnh và sở thích của thành viên\n- Thiết lập kênh giao tiếp\n+ Nhóm chat\n+ Chia sẻ tài liệu\n+ Lịch họp 05/11/2025 05/11/2025 Cộng tác nhóm Thứ Năm (6/11) Lập kế hoạch dự án nhóm\n- Xác định phạm vi và mục tiêu dự án\n- Chọn phương pháp kiến trúc dự án\n- Xác định các dịch vụ AWS cần thiết\n- Tạo timeline dự án ban đầu\n- Phân công vai trò và trách nhiệm sơ bộ\n- Thiết lập repository và tài liệu dự án 06/11/2025 06/11/2025 Tài liệu lập kế hoạch Thứ Sáu (7/11) Yêu cầu \u0026amp; Thiết kế dự án\n- Ghi chép yêu cầu dự án\n- Tạo sơ đồ kiến trúc\n- Lập kế hoạch phân bổ tài nguyên AWS\n- Thảo luận phương pháp triển khai\n- Xác định các thách thức tiềm năng\n- Lập kế hoạch cho các nhiệm vụ phát triển tuần tới 07/11/2025 07/11/2025 Tài liệu dự án Kết quả đạt được tuần 9 Khởi động dự án nhóm\nThành lập nhóm dự án thành công Thiết lập kênh giao tiếp nhóm hiệu quả Xác định phạm vi và mục tiêu dự án rõ ràng Tạo timeline dự án ban đầu Phân công vai trò dựa trên điểm mạnh của thành viên Thiết lập cơ sở hạ tầng dự án (repository, tài liệu) Lập kế hoạch dự án\nGhi chép yêu cầu dự án toàn diện Thiết kế kiến trúc hệ thống ban đầu Xác định các dịch vụ AWS cần thiết cho triển khai Tạo sơ đồ kiến trúc Lập kế hoạch chiến lược phân bổ tài nguyên Thiết lập quy trình phát triển Cộng tác nhóm\nXây dựng mối quan hệ với các thành viên nhóm Thiết lập lịch họp thường xuyên Tạo hệ thống tài liệu chia sẻ Xác định giao thức giao tiếp Thúc đẩy môi trường cộng tác Tiến độ dịch Blog\nTiếp tục công việc dịch blog thứ hai Đạt tiến độ đáng kể trong các phần kỹ thuật Duy trì tiêu chuẩn chất lượng dịch thuật Các thách thức gặp phải Chuyển đổi từ học cá nhân sang cộng tác nhóm Điều chỉnh lịch trình và khả năng của các thành viên nhóm Cân bằng các mức độ kỹ năng và kinh nghiệm khác nhau trong nhóm Xác định phạm vi dự án thực tế trong giới hạn thời gian Phối hợp nhiều quan điểm khác nhau về hướng dự án Bài học quan trọng Giao tiếp nhóm hiệu quả là nền tảng cho cộng tác thành công Xác định vai trò rõ ràng ngăn ngừa nhầm lẫn và chồng chéo Lập kế hoạch sớm tiết kiệm thời gian trong quá trình triển khai Sự đa dạng trong nhóm mang lại các quan điểm khác nhau có giá trị Tài liệu quan trọng cho sự phối hợp nhóm Kiểm tra thường xuyên giữ cho mọi người đồng bộ Mục tiêu tuần tới Bắt đầu triển khai dự án Thiết lập cơ sở hạ tầng AWS cho dự án Phát triển các thành phần dự án cốt lõi Duy trì các cuộc họp và phối hợp nhóm thường xuyên Duy trì tài liệu dự án Chuẩn bị cho AWS Cloud Mastery Series #1 (15/11) "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10 Tiếp tục phát triển dự án nhóm Triển khai các tính năng dự án cốt lõi Tham dự AWS Cloud Mastery Series #1 về AI/ML/GenAI Duy trì phối hợp và tài liệu nhóm Điều chỉnh quy trình làm việc sau sự cố chấn thương Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (10/11) Phát triển dự án nhóm\n- Họp nhóm và xem xét tiến độ\n- Tiếp tục triển khai dự án\n- Phát triển các tính năng cốt lõi\n- Code review và tích hợp\n- Cập nhật tài liệu dự án 10/11/2025 10/11/2025 Repository dự án Thứ Ba (11/11) Ngày làm việc văn phòng - Project Sprint\n- Phiên phát triển tập trung tại văn phòng\n- Triển khai các thành phần dự án chính\n- Cộng tác nhóm và pair programming\n- Giải quyết các thách thức kỹ thuật\n- Test và debug các tính năng\n- Phối hợp với các thành viên nhóm 11/11/2025 11/11/2025 Phát triển dự án Thứ Tư (12/11) Phối hợp dự án nhóm\n- Họp nhóm từ xa\n- Cập nhật tiến độ và đồng bộ trạng thái\n- Giải quyết các vấn đề và trở ngại\n- Lập kế hoạch các nhiệm vụ phát triển còn lại\n- Chuẩn bị cho sự kiện AWS cuối tuần 12/11/2025 12/11/2025 Cộng tác nhóm Thứ Năm (13/11) Phát triển \u0026amp; Testing dự án\n- Tiếp tục triển khai tính năng\n- Viết và chạy tests\n- Sửa lỗi và cải thiện\n- Cập nhật tài liệu\n- Xem xét chất lượng code 13/11/2025 13/11/2025 Công việc phát triển Thứ Sáu (14/11) Tai nạn chấn thương tay\n- Tai nạn xảy ra trong ngày\n- Nhập viện và nhận điều trị y tế\n- Được bó bột cho chấn thương tay\n- Không thể tiếp tục công việc bình thường\n- Thông báo cho nhóm về tình hình 14/11/2025 14/11/2025 Điều trị y tế Thứ Bảy (15/11) AWS Cloud Mastery Series #1 - AI/ML/GenAI\nThời gian: 8:30 AM - 12:00 PM\nĐịa điểm: Văn phòng AWS Vietnam, Tòa nhà Bitexco Financial Tower\nMặc dù bị thương, vẫn tham dự sự kiện\nBuổi sáng:\n- Chào mừng \u0026amp; Bối cảnh AI/ML tại Việt Nam\n- Tổng quan AWS AI/ML Services\n+ Nền tảng Amazon SageMaker\n+ Chuẩn bị và gán nhãn dữ liệu\n+ Training, tuning, deployment model\n+ Khả năng MLOps\n+ Demo trực tiếp: SageMaker Studio\nSau giờ nghỉ:\n- Generative AI với Amazon Bedrock\n+ Foundation Models (Claude, Llama, Titan)\n+ Kỹ thuật Prompt Engineering\n+ RAG (Retrieval Augmented Generation)\n+ Bedrock Agents\n+ Guardrails\n+ Demo trực tiếp: GenAI chatbot với Bedrock 15/11/2025 15/11/2025 AWS Cloud Mastery #1 Kết quả đạt được tuần 10 Tiến độ dự án nhóm\nTriển khai các tính năng dự án cốt lõi Thực hiện sprint phát triển nhóm thành công Tích hợp nhiều thành phần Thực hiện code reviews và testing Duy trì tài liệu dự án Phối hợp hiệu quả bất chấp thách thức AWS Cloud Mastery Series #1 - AI/ML/GenAI\nTham dự workshop AI/ML toàn diện tại văn phòng AWS Học nền tảng ML end-to-end Amazon SageMaker Hiểu vòng đời ML model (training, tuning, deployment) Khám phá khả năng MLOps Chứng kiến demo trực tiếp SageMaker Studio Học Generative AI với Amazon Bedrock Hiểu Foundation Models (Claude, Llama, Titan) Học kỹ thuật Prompt Engineering Khám phá kiến trúc RAG Hiểu Bedrock Agents và Guardrails Xem demo trực tiếp GenAI chatbot Khả năng thích ứng và Kiên cường\nXử lý chấn thương bất ngờ một cách chuyên nghiệp Thông báo cho nhóm kịp thời về tình hình Tham dự sự kiện AWS bất chấp hạn chế thể chất Thể hiện cam kết với việc học Điều chỉnh quy trình làm việc để phù hợp với chấn thương Các thách thức gặp phải Chấn thương tay vào thứ Sáu ảnh hưởng đáng kể đến khả năng code Hạn chế thể chất ảnh hưởng đến việc gõ phím và công việc thực hành Cân bằng nhu cầu y tế với cam kết dự án Tham dự sự kiện AWS với chấn thương đòi hỏi nỗ lực thêm Phối hợp với nhóm trong khi quản lý phục hồi Bài học quan trọng Kỹ thuật:\nSageMaker cung cấp nền tảng ML toàn diện MLOps rất quan trọng cho hệ thống ML production Generative AI mở ra khả năng mới với Foundation Models Prompt Engineering là kỹ năng quan trọng cho ứng dụng GenAI RAG nâng cao khả năng LLM với kiến thức tùy chỉnh Bedrock đơn giản hóa phát triển ứng dụng GenAI Cá nhân:\nKhả năng thích ứng rất quan trọng khi đối mặt với thách thức bất ngờ Sự hỗ trợ của nhóm vô cùng quý giá trong thời điểm khó khăn Cam kết học tập vượt qua hạn chế thể chất Giao tiếp là chìa khóa khi hoàn cảnh thay đổi Sức khỏe và an toàn luôn nên được ưu tiên Mục tiêu tuần tới Tiếp tục công việc dự án với quy trình điều chỉnh Tập trung vào các nhiệm vụ phù hợp với hạn chế thể chất Tham dự cuộc hẹn tái khám bác sĩ (21/11) Tham dự AWS Cloud Mastery Series #2 về DevOps (17/11) Duy trì phối hợp và giao tiếp nhóm Dần dần tiếp tục các hoạt động bình thường khi phục hồi cho phép "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11 Tham dự AWS Cloud Mastery Series #2 về DevOps Tiếp tục dự án nhóm với quy trình điều chỉnh Tham dự cuộc tái khám bác sĩ lần đầu Tập trung vào các nhiệm vụ phù hợp với hạn chế thể chất Duy trì động lực học tập bất chấp thách thức Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (17/11) AWS Cloud Mastery Series #2 - DevOps (Cả ngày)\nThời gian: 8:30 AM - 5:00 PM\nĐịa điểm: Văn phòng AWS Vietnam, Tòa nhà Bitexco Financial Tower\nBuổi sáng (8:30-12:00):\n- Chào mừng \u0026amp; DevOps Mindset (DORA metrics)\n- AWS DevOps Services - CI/CD Pipeline\n+ CodeCommit, CodeBuild, CodeDeploy, CodePipeline\n+ Git strategies, deployment patterns\n+ Demo: Full CI/CD pipeline\n- Infrastructure as Code\n+ CloudFormation templates\n+ AWS CDK\n+ Demo: IaC deployment\nBuổi chiều (13:00-17:00):\n- Container Services trên AWS\n+ Docker fundamentals\n+ ECR, ECS, EKS\n+ App Runner\n+ Demo: Microservices deployment\n- Monitoring \u0026amp; Observability\n+ CloudWatch, X-Ray\n+ Demo: Full-stack observability\n- DevOps Best Practices \u0026amp; Case Studies\n- Q\u0026amp;A \u0026amp; Kết thúc 17/11/2025 17/11/2025 AWS Cloud Mastery #2 Thứ Ba (18/11) Công việc dự án - Quy trình điều chỉnh\n- Xem xét kiến thức DevOps từ sự kiện\n- Họp nhóm (từ xa)\n- Tập trung vào các nhiệm vụ tài liệu\n- Code review và hoạt động lập kế hoạch\n- Phối hợp với nhóm về triển khai 18/11/2025 18/11/2025 Cộng tác nhóm Thứ Tư (19/11) Phối hợp dự án\n- Tiếp tục công việc dự án điều chỉnh\n- Các nhiệm vụ tài liệu và thiết kế\n- Giao tiếp và lập kế hoạch nhóm\n- Xem xét tiến độ dự án\n- Xác định các nhiệm vụ phù hợp với khả năng hiện tại 19/11/2025 19/11/2025 Công việc dự án Thứ Năm (20/11) Lập kế hoạch \u0026amp; Tài liệu dự án\n- Cập nhật tài liệu dự án\n- Xem xét và tinh chỉnh kiến trúc\n- Lập kế hoạch cho các tính năng sắp tới\n- Các cuộc họp phối hợp nhóm\n- Chuẩn bị cho cuộc hẹn bác sĩ 20/11/2025 20/11/2025 Công việc tài liệu Thứ Sáu (21/11) Tái khám bác sĩ lần 1\n- Cuộc hẹn theo dõi đầu tiên\n- Đánh giá y tế về tiến độ phục hồi\n- Nhận hướng dẫn về chăm sóc tiếp tục\n- Thảo luận về timeline phục hồi hoàn toàn\n- Công việc dự án nhẹ sau cuộc hẹn 21/11/2025 21/11/2025 Theo dõi y tế Kết quả đạt được tuần 11 AWS Cloud Mastery Series #2 - DevOps\nTham dự workshop DevOps toàn diện cả ngày Học văn hóa DevOps và DORA metrics Hiểu các dịch vụ AWS CI/CD (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) Khám phá Git strategies và deployment patterns Chứng kiến demo full CI/CD pipeline Học Infrastructure as Code với CloudFormation và CDK Xem demo triển khai IaC Hiểu container services (Docker, ECR, ECS, EKS, App Runner) Chứng kiến demo triển khai microservices Học monitoring và observability với CloudWatch và X-Ray Xem demo full-stack observability Học DevOps best practices và case studies thực tế Quy trình dự án điều chỉnh\nĐiều chỉnh thành công phong cách làm việc để phù hợp với chấn thương Tập trung vào các nhiệm vụ tài liệu và lập kế hoạch Duy trì phối hợp và giao tiếp nhóm Đóng góp cho dự án thông qua code reviews Giữ động lực dự án bất chấp hạn chế thể chất Theo dõi y tế\nTham dự cuộc hẹn tái khám bác sĩ đầu tiên Nhận đánh giá về tiến độ phục hồi Có được hướng dẫn cho chăm sóc tiếp tục Hiểu timeline cho phục hồi hoàn toàn Duy trì quan điểm tích cực Tiếp tục học tập\nTiếp thu kiến thức DevOps toàn diện Áp dụng kiến thức vào bối cảnh dự án nhóm Duy trì sự tham gia với hệ sinh thái AWS Thể hiện cam kết bất chấp thách thức Các thách thức gặp phải Hạn chế thể chất tiếp tục ảnh hưởng đến coding thực hành Cân bằng tham dự sự kiện cả ngày với nhu cầu phục hồi Điều chỉnh đóng góp dự án theo khả năng hiện tại Quản lý mệt mỏi từ các buổi học kéo dài Phối hợp các cuộc hẹn y tế với cam kết dự án Bài học quan trọng Kỹ thuật - DevOps:\nTự động hóa CI/CD rất quan trọng cho phát triển hiện đại Infrastructure as Code cho phép triển khai có thể tái tạo Container orchestration đơn giản hóa quản lý ứng dụng Observability cần thiết cho hệ thống production Văn hóa DevOps nhấn mạnh cộng tác và tự động hóa AWS cung cấp bộ công cụ DevOps toàn diện Cá nhân:\nPhục hồi cần thời gian và kiên nhẫn Thích ứng cho phép tiếp tục năng suất Tài liệu và lập kế hoạch là đóng góp có giá trị Sự hỗ trợ của nhóm tạo điều kiện tiếp tục tham gia Học tập có thể tiếp tục bất chấp hạn chế thể chất Chăm sóc y tế cần thiết cho phục hồi đúng cách Mục tiêu tuần tới Tiếp tục công việc dự án điều chỉnh Chuẩn bị cho AWS Cloud Mastery Series #3 về Security (29/11) Tập trung vào tài liệu và kiến trúc dự án Dần dần tăng sự tham gia thực hành khi phục hồi cho phép Duy trì phối hợp và giao tiếp nhóm Chuẩn bị cho cuộc tái khám bác sĩ lần 2 (5/12) "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12 Hoàn thành dự án nhóm và chuẩn bị thuyết trình cuối cùng Tham dự AWS Cloud Mastery Series #3 về Security Suy ngẫm về chương trình AWS First Cloud Journey 12 tuần Củng cố kiến thức và ghi chép thành tựu Lập kế hoạch cho hành trình học AWS tiếp tục Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Thứ Hai (24/11) Hoàn thiện dự án\n- Họp nhóm để lập kế hoạch sprint cuối cùng\n- Hoàn thành các tính năng dự án còn lại\n- Dọn dẹp và tối ưu hóa code\n- Chuẩn bị tài liệu dự án\n- Lập kế hoạch cấu trúc thuyết trình cuối 24/11/2025 24/11/2025 Repository dự án Thứ Ba (25/11) Testing \u0026amp; Tài liệu dự án\n- Testing toàn diện tất cả tính năng\n- Sửa lỗi và điều chỉnh cuối cùng\n- Hoàn thành tài liệu kỹ thuật\n- Chuẩn bị tài liệu người dùng\n- Tạo slides thuyết trình 25/11/2025 25/11/2025 Công việc dự án Thứ Tư (26/11) Chuẩn bị thuyết trình\n- Hoàn thiện nội dung thuyết trình\n- Luyện tập thuyết trình nhóm\n- Chuẩn bị các kịch bản demo\n- Xem xét điểm nổi bật dự án\n- Phối hợp vai trò thuyết trình 26/11/2025 26/11/2025 Tài liệu thuyết trình Thứ Năm (27/11) Suy ngẫm \u0026amp; Củng cố chương trình\n- Xem xét hành trình 12 tuần\n- Ghi chép các bài học quan trọng\n- Củng cố kiến thức AWS\n- Chuẩn bị cho workshop Security\n- Cập nhật portfolio và CV 27/11/2025 27/11/2025 Suy ngẫm cá nhân Thứ Sáu (28/11) Hoàn thiện dự án cuối cùng\n- Cải thiện phút chót\n- Tập dượt thuyết trình\n- Đảm bảo tất cả deliverables sẵn sàng\n- Phối hợp nhóm\n- Chuẩn bị cho sự kiện cuối tuần 28/11/2025 28/11/2025 Chuẩn bị cuối cùng Thứ Bảy (29/11) AWS Cloud Mastery Series #3 - Security\nThời gian: 8:30 AM - 12:00 PM\nĐịa điểm: Văn phòng AWS Vietnam, Tòa nhà Bitexco Financial Tower\nChủ đề: AWS Well-Architected Security Pillar\nNội dung:\n- Khai mạc \u0026amp; Nền tảng Security\n+ Security Pillar trong Well-Architected\n+ Least Privilege, Zero Trust, Defense in Depth\n+ Shared Responsibility Model\n- Trụ cột 1: Identity \u0026amp; Access Management\n+ IAM best practices\n+ IAM Identity Center\n+ MFA, credential rotation\n+ Demo: IAM Policy validation\n- Trụ cột 2: Detection\n+ CloudTrail, GuardDuty, Security Hub\n+ VPC Flow Logs\n+ EventBridge automation\n- Trụ cột 3: Infrastructure Protection\n+ VPC segmentation\n+ Security Groups vs NACLs\n+ WAF, Shield, Network Firewall\n- Trụ cột 4: Data Protection\n+ KMS encryption\n+ Secrets Manager\n+ Data classification\n- Trụ cột 5: Incident Response\n+ IR lifecycle\n+ Playbooks\n+ Auto-response với Lambda\n- Kết thúc \u0026amp; Q\u0026amp;A 29/11/2025 29/11/2025 AWS Cloud Mastery #3 Kết quả đạt được tuần 12 Hoàn thành dự án nhóm\nHoàn thành thành công dự án nhóm Giao tất cả tính năng và chức năng dự án Tạo tài liệu toàn diện Chuẩn bị thuyết trình chuyên nghiệp Thể hiện cộng tác nhóm hiệu quả AWS Cloud Mastery Series #3 - Security\nTham dự workshop Cloud Mastery cuối cùng về Security Học AWS Well-Architected Security Pillar Hiểu các nguyên tắc security (Least Privilege, Zero Trust, Defense in Depth) Học Shared Responsibility Model Khám phá IAM best practices và Identity Center Hiểu các dịch vụ phát hiện security (CloudTrail, GuardDuty, Security Hub) Học bảo vệ hạ tầng (VPC, Security Groups, WAF, Shield) Khám phá bảo vệ dữ liệu với KMS và Secrets Manager Hiểu vòng đời incident response và tự động hóa Hoàn thành cả ba workshop Cloud Mastery Series Suy ngẫm chương trình 12 tuần\nHoàn thành chương trình AWS First Cloud Journey Có được kiến thức AWS toàn diện trên nhiều lĩnh vực Tham dự 6 sự kiện và workshop AWS lớn Dịch 2+ blog kỹ thuật AWS Hoàn thành dự án nhóm thành công Vượt qua thách thức bao gồm chấn thương và điều chỉnh quy trình Xây dựng nền tảng vững chắc cho sự nghiệp AWS Các kỹ năng chính đã phát triển\nCác dịch vụ AWS cốt lõi (EC2, S3, VPC, RDS, Lambda) Kiến trúc serverless và ứng dụng GenAI Data science và ML trên AWS (SageMaker, Bedrock) Thực hành DevOps và CI/CD pipelines Security best practices và Well-Architected Framework Cộng tác nhóm và quản lý dự án Tài liệu kỹ thuật và kỹ năng thuyết trình Kiên cường và khả năng thích ứng Các thách thức gặp phải Hoàn thành dự án trong khi quản lý phục hồi chấn thương Cân bằng deliverables cuối cùng với tham dự sự kiện Áp lực thời gian để hoàn thành dự án Phối hợp nhóm cho thuyết trình cuối Suy ngẫm về hành trình học tập rộng lớn Bài học quan trọng Kỹ thuật:\nAWS cung cấp nền tảng cloud toàn diện Security phải được xem xét ở mọi tầng Well-Architected Framework hướng dẫn best practices Tự động hóa là chìa khóa cho security có thể mở rộng Incident response yêu cầu chuẩn bị và thực hành Kỹ năng cloud cần thiết cho sự nghiệp công nghệ hiện đại Cá nhân:\nHọc tập nhất quán dẫn đến tăng trưởng đáng kể Thách thức có thể vượt qua với quyết tâm Sự hỗ trợ của nhóm vô cùng quý giá Thực hành củng cố kiến thức lý thuyết Tài liệu bảo tồn việc học Học tập liên tục cần thiết trong cloud computing Tóm tắt chương trình - 12 tuần phát triển Tuần 1-4: AWS Fundamentals (EC2, S3, VPC, RDS)\nTuần 5-7: Advanced Services (Lambda, Containers, Security)\nTuần 8: Thi giữa kỳ\nTuần 9-12: Dự án nhóm + Cloud Mastery Series (AI/ML, DevOps, Security)\nCác sự kiện lớn đã tham dự:\nAWS FCJ Kick-off (6/9) AWS Cloud Day 2025 (GenAI and Data track) Data Science on AWS Workshop (16/10) AWS Cloud Mastery #1 - AI/ML/GenAI (15/11) AWS Cloud Mastery #2 - DevOps (17/11) AWS Cloud Mastery #3 - Security (29/11) Thành tựu:\nHoàn thành chương trình học AWS toàn diện Vượt qua kỳ thi giữa kỳ Dịch các blog kỹ thuật AWS Hoàn thành dự án nhóm Tham dự 6 sự kiện AWS lớn Vượt qua chấn thương và điều chỉnh quy trình Xây dựng nền tảng AWS vững chắc Bước tiếp theo Chuẩn bị cho các kỳ thi chứng chỉ AWS Tiếp tục tinh chỉnh dự án nhóm Áp dụng kỹ năng AWS trong các dự án thực tế Duy trì tham gia với cộng đồng AWS Khám phá các dịch vụ AWS nâng cao Theo đuổi cơ hội nghề nghiệp trong cloud computing "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]