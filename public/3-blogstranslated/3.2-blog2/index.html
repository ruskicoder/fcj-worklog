<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.150.0"><meta name=description content><meta name=author content="khoado7577@gmail.com"><link rel=icon href=/fcj-worklog/images/favicon.png type=image/png><title>Blog 2 :: Internship Report</title><link href=/fcj-worklog/css/nucleus.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/fontawesome-all.min.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/hybrid.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/featherlight.min.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/perfect-scrollbar.min.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/auto-complete.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/atom-one-dark-reasonable.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/theme.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/hugo-theme.css?1765298327 rel=stylesheet><link href=/fcj-worklog/css/theme-workshop.css?1765298327 rel=stylesheet><script src=/fcj-worklog/js/jquery-3.3.1.min.js?1765298327></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=/fcj-worklog/3-blogstranslated/3.2-blog2/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=/><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=/fcj-worklog/js/lunr.min.js?1765298327></script><script type=text/javascript src=/fcj-worklog/js/auto-complete.js?1765298327></script><script type=text/javascript>var baseurl="https://ruskicoder.github.io/fcj-worklog/"</script><script type=text/javascript src=/fcj-worklog/js/search.js?1765298327></script></div><div class=highlightable><ul class=topics><li data-nav-id=/fcj-worklog/1-worklog/ title=Worklog class=dd-item><a href=/fcj-worklog/1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/fcj-worklog/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.9-week9/ title="Week 9 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.9-week9/><b>1.9. </b>Week 9 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.11-week11/ title="Week 11 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.11-week11/><b>1.11. </b>Week 11 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=/fcj-worklog/1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/fcj-worklog/2-proposal/ title=Proposal class=dd-item><a href=/fcj-worklog/2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=/fcj-worklog/3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/fcj-worklog/3-blogstranslated/3.1-blog1/ title="Blog 1" class=dd-item><a href=/fcj-worklog/3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/3-blogstranslated/3.2-blog2/ title="Blog 2" class="dd-item
active"><a href=/fcj-worklog/3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=/fcj-worklog/3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/fcj-worklog/4-eventparticipated/ title="Events Attended" class=dd-item><a href=/fcj-worklog/4-eventparticipated/><b>4. </b>Events Attended
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/fcj-worklog/4-eventparticipated/4.1-event1/ title="Event 1" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.2-event2/ title="Event 2" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.2-event2/><b>4.2. </b>Event 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.3-event3/ title="Event 3" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.3-event3/><b>4.3. </b>Event 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.4-event4/ title="Event 4" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.4-event4/><b>4.4. </b>Event 4
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.5-event5/ title="Event 5" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.5-event5/><b>4.5. </b>Event 5
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.6-event6/ title="Event 6" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.6-event6/><b>4.6. </b>Event 6
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/4-eventparticipated/4.7-event7/ title="Event 7" class=dd-item><a href=/fcj-worklog/4-eventparticipated/4.7-event7/><b>4.7. </b>Event 7
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/fcj-worklog/5-workshop/ title=Workshop class=dd-item><a href=/fcj-worklog/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/fcj-worklog/5-workshop/5.1-workshop-overview/ title="Workshop Overview" class=dd-item><a href=/fcj-worklog/5-workshop/5.1-workshop-overview/><b>5.1. </b>Workshop Overview
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.2-prerequisite/ title=Prerequisites class=dd-item><a href=/fcj-worklog/5-workshop/5.2-prerequisite/><b>5.2. </b>Prerequisites
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.3-architecture/ title="Project Architecture" class=dd-item><a href=/fcj-worklog/5-workshop/5.3-architecture/><b>5.3. </b>Project Architecture
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.4-setup-aws/ title="Setup AWS Environment" class=dd-item><a href=/fcj-worklog/5-workshop/5.4-setup-aws/><b>5.4. </b>Setup AWS Environment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.5-database-setup/ title="Database Setup (DynamoDB)" class=dd-item><a href=/fcj-worklog/5-workshop/5.5-database-setup/><b>5.5. </b>Database Setup (DynamoDB)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.6-authentication/ title="Authentication Service" class=dd-item><a href=/fcj-worklog/5-workshop/5.6-authentication/><b>5.6. </b>Authentication Service
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.7-backend-services/ title="Backend Services" class=dd-item><a href=/fcj-worklog/5-workshop/5.7-backend-services/><b>5.7. </b>Backend Services
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.8-frontend/ title="Frontend Development" class=dd-item><a href=/fcj-worklog/5-workshop/5.8-frontend/><b>5.8. </b>Frontend Development
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.9-deployment/ title=Deployment class=dd-item><a href=/fcj-worklog/5-workshop/5.9-deployment/><b>5.9. </b>Deployment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.10-testing/ title="Testing & Monitoring" class=dd-item><a href=/fcj-worklog/5-workshop/5.10-testing/><b>5.10. </b>Testing & Monitoring
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/5-workshop/5.11-cleanup/ title=Cleanup class=dd-item><a href=/fcj-worklog/5-workshop/5.11-cleanup/><b>5.11. </b>Cleanup
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/fcj-worklog/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=/fcj-worklog/6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/fcj-worklog/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=/fcj-worklog/7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://ruskicoder.github.io/fcj-worklog/3-blogstranslated/3.2-blog2/ selected>English</option><option id=vi value=https://ruskicoder.github.io/fcj-worklog/vi/3-blogstranslated/3.2-blog2/>Tiếng Việt</option></select>
<svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=/fcj-worklog/>Internship Report</a> > <a href=/fcj-worklog/3-blogstranslated/>Translated Blogs</a> > Blog 2</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#đánh-giá-các-mô-hình-ai-tạo-sinh-với-amazon-nova-llm-as-a-judge-trên-amazon-sagemaker-ai>Đánh giá các mô hình AI tạo sinh với Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI</a><ul><li><a href=#cách-nova-llm-as-a-judge-được-huấn-luyện><strong>Cách Nova LLM-as-a-Judge được huấn luyện</strong></a></li><li><a href=#tổng-quan-về-quy-trình-công-việc-đánh-giá><strong>Tổng quan về quy trình công việc đánh giá</strong></a></li><li><a href=#tìm-hiểu-cách-hoạt-động-của-amazon-nova-llm-as-a-judge><strong>Tìm hiểu cách hoạt động của Amazon Nova LLM-as-a-Judge</strong></a></li><li><a href=#tìm-hiểu-các-chỉ-số-đánh-giá-của-amazon-nova-llm-as-a-judge><strong>Tìm hiểu các chỉ số đánh giá của Amazon Nova LLM-as-a-Judge</strong></a></li><li><a href=#tổng-quan-về-giải-pháp><strong>Tổng quan về giải pháp</strong></a></li><li><a href=#các-điều-kiện-tiên-quyết><strong>Các điều kiện tiên quyết</strong></a></li><li><a href=#thiết-lập-mô-hình><strong>Thiết lập mô hình</strong></a></li><li><a href=#chuẩn-bị-bộ-dữ-liệu><strong>Chuẩn bị bộ dữ liệu</strong></a></li><li><a href=#tạo-bộ-dữ-liệu-đánh-giá-amazon-nova-llm-as-a-judge><strong>Tạo bộ dữ liệu đánh giá Amazon Nova LLM-as-a-Judge</strong></a></li><li><a href=#khởi-chạy-công-việc-đánh-giá-nova-llm-as-a-judge><strong>Khởi chạy công việc đánh giá Nova LLM-as-a-Judge</strong></a></li><li><a href=#kết-quả-từ-công-việc-đánh-giá-amazon-nova-llm-as-a-judge><strong>Kết quả từ công việc đánh giá Amazon Nova LLM-as-a-Judge</strong></a></li><li><a href=#dọn-dẹp><strong>Dọn dẹp</strong></a></li><li><a href=#làm-thế-nào-bạn-có-thể-sử-dụng-khung-đánh-giá-này><strong>Làm thế nào bạn có thể sử dụng khung đánh giá này</strong></a></li><li><a href=#kết-luận><strong>Kết luận</strong></a></li><li><a href=#về-các-tác-giả><strong>Về các tác giả</strong></a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 2</h1><h2 id=đánh-giá-các-mô-hình-ai-tạo-sinh-với-amazon-nova-llm-as-a-judge-trên-amazon-sagemaker-ai>Đánh giá các mô hình AI tạo sinh với Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI</h2><p>bởi Surya Kari, Joel Carlson, Michael Cai, Morteza Ziyadi, Pradeep Natarajan, và Saurabh Sahu | vào ngày 17 tháng 7 2025 | trong <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/amazon-nova/>Amazon Nova</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/sagemaker/>Amazon SageMaker</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/sagemaker/amazon-sagemaker-ai/>Amazon SageMaker AI</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/post-types/announcements/>Thông báo</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/>Trí tuệ nhân tạo</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/foundation-models/>Các mô hình nền tảng</a> | <a href=https://aws.amazon.com/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/>Permalink</a> | <a href=https://aws.amazon.com/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/#Comments>Bình luận</a> | <a href=https://aws.amazon.com/vi/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/>Chia sẻ</a></p><p>Việc đánh giá hiệu suất của các <a href=https://aws.amazon.com/what-is/large-language-model/>mô hình ngôn ngữ lớn</a> (LLM) vượt ra ngoài các chỉ số thống kê như độ phức tạp (perplexity) hay điểm đánh giá song ngữ (BLEU). Đối với hầu hết các kịch bản <a href=https://aws.amazon.com/what-is/generative-ai/>AI tạo sinh</a> trong thế giới thực, điều quan trọng là phải hiểu liệu một mô hình có đang tạo ra các kết quả đầu ra tốt hơn so với một mô hình cơ sở hoặc một phiên bản trước đó hay không. Điều này đặc biệt quan trọng đối với các ứng dụng như tóm tắt, tạo nội dung, hoặc các tác tử thông minh, nơi các phán đoán chủ quan và tính đúng đắn tinh tế đóng một vai trò trung tâm.</p><p>Khi các tổ chức đẩy mạnh việc triển khai các mô hình này trong môi trường sản xuất, chúng tôi nhận thấy nhu cầu ngày càng tăng từ khách hàng muốn đánh giá chất lượng mô hình một cách có hệ thống, vượt qua các phương pháp đánh giá truyền thống. Các phương pháp hiện tại như đo lường độ chính xác và đánh giá dựa trên quy tắc, mặc dù hữu ích, không thể giải quyết hoàn toàn các nhu cầu đánh giá tinh tế này, đặc biệt khi các tác vụ đòi hỏi phán đoán chủ quan, hiểu biết theo ngữ cảnh, hoặc sự phù hợp với các yêu cầu kinh doanh cụ thể. Để thu hẹp khoảng cách này, LLM-như-một-giám-khảo đã nổi lên như một phương pháp đầy hứa hẹn, sử dụng khả năng lý luận của các LLM để đánh giá các mô hình khác một cách linh hoạt hơn và ở quy mô lớn.</p><p>Hôm nay, chúng tôi vui mừng giới thiệu một phương pháp toàn diện để đánh giá mô hình thông qua khả năng <a href=https://aws.amazon.com/ai/generative-ai/nova/>Amazon Nova</a> LLM-as-a-Judge trên <a href=https://aws.amazon.com/sagemaker-ai/>Amazon SageMaker AI</a>, một dịch vụ được quản lý toàn phần của <a href=https://aws.amazon.com/aws/>Amazon Web Services</a> (AWS) để xây dựng, huấn luyện và triển khai các <a href=https://aws.amazon.com/ai/machine-learning/>mô hình học máy</a> (ML) ở quy mô lớn. Amazon Nova LLM-as-a-Judge được thiết kế để cung cấp các đánh giá mạnh mẽ, không thiên vị về kết quả đầu ra của AI tạo sinh trên các họ mô hình. Nova LLM-as-a-Judge có sẵn dưới dạng các quy trình công việc được tối ưu hóa trên SageMaker AI, và với nó, bạn có thể bắt đầu đánh giá hiệu suất mô hình so với các trường hợp sử dụng cụ thể của mình trong vài phút. Không giống như nhiều bộ đánh giá thể hiện sự thiên vị về mặt kiến trúc, Nova LLM-as-a-Judge đã được xác thực nghiêm ngặt để đảm bảo tính khách quan và đã đạt được hiệu suất hàng đầu trên các bộ tiêu chuẩn đánh giá chính trong khi phản ánh sát sao sở thích của con người. Với độ chính xác vượt trội và độ thiên vị tối thiểu, nó đặt ra một tiêu chuẩn mới cho việc đánh giá LLM đáng tin cậy, cấp độ sản xuất.</p><p>Khả năng Nova LLM-as-a-Judge cung cấp các so sánh cặp đôi giữa các phiên bản mô hình, để bạn có thể tự tin đưa ra các quyết định dựa trên dữ liệu về việc cải tiến mô hình.</p><h3 id=cách-nova-llm-as-a-judge-được-huấn-luyện><strong>Cách Nova LLM-as-a-Judge được huấn luyện</strong></h3><p>Nova LLM-as-a-Judge được xây dựng thông qua một quy trình huấn luyện nhiều bước bao gồm các giai đoạn huấn luyện có giám sát và học tăng cường, sử dụng các bộ dữ liệu công khai được gán nhãn với sở thích của con người. Đối với thành phần độc quyền, nhiều người gán nhãn đã độc lập đánh giá hàng ngàn ví dụ bằng cách so sánh các cặp phản hồi LLM khác nhau cho cùng một câu lệnh. Để xác minh tính nhất quán và công bằng, tất cả các gán nhãn đều trải qua các cuộc kiểm tra chất lượng nghiêm ngặt, với các phán quyết cuối cùng được hiệu chỉnh để phản ánh sự đồng thuận rộng rãi của con người thay vì một quan điểm cá nhân.</p><p>Dữ liệu huấn luyện được thiết kế để vừa đa dạng vừa mang tính đại diện. Các câu lệnh bao trùm một loạt các hạng mục, bao gồm kiến thức thực tế, sáng tạo, lập trình, toán học, các lĩnh vực chuyên ngành, và độc tính, để mô hình có thể đánh giá các kết quả đầu ra trên nhiều kịch bản thực tế. Dữ liệu huấn luyện bao gồm dữ liệu từ hơn 90 ngôn ngữ và chủ yếu bao gồm tiếng Anh, Nga, Trung, Đức, Nhật và Ý. Điều quan trọng là, một nghiên cứu về độ thiên vị nội bộ đánh giá hơn 10.000 phán đoán ưu tiên của con người so với 75 mô hình của bên thứ ba đã xác nhận rằng Amazon Nova LLM-as-a-Judge chỉ cho thấy độ thiên vị tổng hợp là 3% so với các chú thích của con người. Mặc dù đây là một thành tựu đáng kể trong việc giảm thiểu sự thiên vị có hệ thống, chúng tôi vẫn khuyến nghị thỉnh thoảng kiểm tra tại chỗ để xác thực các so sánh quan trọng.</p><p>Trong hình dưới đây, bạn có thể thấy độ thiên vị của Nova LLM-as-a-Judge so với sở thích của con người khi đánh giá các kết quả đầu ra của Amazon Nova so với các kết quả đầu ra từ các mô hình khác. Ở đây, độ thiên vị được đo bằng sự khác biệt giữa sở thích của giám khảo và sở thích của con người qua hàng ngàn ví dụ. Giá trị dương cho thấy giám khảo hơi thiên vị các mô hình Amazon Nova, và giá trị âm cho thấy điều ngược lại. Để định lượng độ tin cậy của các ước tính này, các khoảng tin cậy 95% đã được tính toán bằng cách sử dụng sai số chuẩn cho sự khác biệt của các tỷ lệ, giả định các phân phối nhị thức độc lập.</p><p><img src=#ZgotmplZ alt></p><p>Amazon Nova LLM-as-a-Judge đạt được hiệu suất tiên tiến trong số các mô hình đánh giá, thể hiện sự tương đồng cao với các phán đoán của con người trên một loạt các tác vụ. Ví dụ, nó đạt độ chính xác 45% trên JudgeBench (so với 42% của Meta J1 8B) và 68% trên PPE (so với 60% của Meta J1 8B). Dữ liệu từ J1 8B của Meta được lấy từ bài viết <a href=https://arxiv.org/html/2505.10320v1>Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning</a>.</p><p>Những kết quả này làm nổi bật sức mạnh của Amazon Nova LLM-as-a-Judge trong các đánh giá liên quan đến chatbot, như được thể hiện trong bộ tiêu chuẩn PPE. Việc đo lường hiệu suất của chúng tôi tuân theo các thực tiễn tốt nhất hiện nay, báo cáo kết quả đã được đối chiếu cho các phản hồi được hoán đổi vị trí trên JudgeBench, CodeUltraFeedback, Eval Bias, và LLMBar, trong khi sử dụng kết quả một lượt cho PPE.</p><table><thead><tr><th style=text-align:left>Mô hình</th><th style=text-align:left>Eval Bias</th><th style=text-align:left>Judge Bench</th><th style=text-align:left>LLM Bar</th><th style=text-align:left>PPE</th><th style=text-align:left>CodeUltraFeedback</th></tr></thead><tbody><tr><td style=text-align:left>Nova LLM-as-a-Judge</td><td style=text-align:left>0.76</td><td style=text-align:left>0.45</td><td style=text-align:left>0.67</td><td style=text-align:left>0.68</td><td style=text-align:left>0.64</td></tr><tr><td style=text-align:left>Meta J1 8B</td><td style=text-align:left>–</td><td style=text-align:left>0.42</td><td style=text-align:left>–</td><td style=text-align:left>0.60</td><td style=text-align:left>–</td></tr><tr><td style=text-align:left>Nova Micro</td><td style=text-align:left>0.56</td><td style=text-align:left>0.37</td><td style=text-align:left>0.55</td><td style=text-align:left>0.6</td><td style=text-align:left>–</td></tr></tbody></table><p>Trong bài đăng này, chúng tôi trình bày một phương pháp tinh gọn để triển khai các đánh giá Amazon Nova LLM-as-a-Judge bằng SageMaker AI, diễn giải các chỉ số kết quả, và áp dụng quy trình này để cải thiện các ứng dụng AI tạo sinh của bạn.</p><h3 id=tổng-quan-về-quy-trình-công-việc-đánh-giá><strong>Tổng quan về quy trình công việc đánh giá</strong></h3><p>Quy trình đánh giá bắt đầu bằng việc chuẩn bị một bộ dữ liệu trong đó mỗi ví dụ bao gồm một câu lệnh và hai kết quả đầu ra thay thế của mô hình. Định dạng JSONL trông như sau:</p><p>{<br>&ldquo;prompt&rdquo;:&ldquo;Explain photosynthesis.&rdquo;,<br>&ldquo;response_A&rdquo;:&ldquo;Answer A&mldr;&rdquo;,<br>&ldquo;response_B&rdquo;:&ldquo;Answer B&mldr;&rdquo;<br>}<br>{<br>&ldquo;prompt&rdquo;:&ldquo;Summarize the article.&rdquo;,<br>&ldquo;response_A&rdquo;:&ldquo;Answer A&mldr;&rdquo;,<br>&ldquo;response_B&rdquo;:&ldquo;Answer B&mldr;&rdquo;<br>}</p><p>Sau khi chuẩn bị bộ dữ liệu này, bạn sử dụng <strong>công thức đánh giá được cung cấp của SageMaker</strong>, công thức này định cấu hình chiến lược đánh giá, chỉ định mô hình nào sẽ được sử dụng làm giám khảo, và xác định các cài đặt suy luận như nhiệt độ (temperature) và top_p.</p><p>Việc đánh giá chạy bên trong một công việc huấn luyện của SageMaker sử dụng các container Amazon Nova dựng sẵn. SageMaker AI cung cấp tài nguyên tính toán, điều phối việc đánh giá, và ghi các chỉ số đầu ra cùng các hình ảnh trực quan hóa vào <a href=https://aws.amazon.com/s3/>Amazon Simple Storage Service</a> (Amazon S3).</p><p>Khi hoàn tất, bạn có thể tải xuống và phân tích kết quả, bao gồm các phân phối ưu tiên, tỷ lệ thắng, và các khoảng tin cậy.</p><h3 id=tìm-hiểu-cách-hoạt-động-của-amazon-nova-llm-as-a-judge><strong>Tìm hiểu cách hoạt động của Amazon Nova LLM-as-a-Judge</strong></h3><p>Amazon Nova LLM-as-a-Judge sử dụng một phương pháp đánh giá gọi là giám khảo ưu tiên tổng thể nhị phân. <strong>Giám khảo ưu tiên tổng thể nhị phân</strong> là một phương pháp trong đó một mô hình ngôn ngữ so sánh hai kết quả đầu ra cạnh nhau và chọn ra cái tốt hơn hoặc tuyên bố hòa. Đối với mỗi ví dụ, nó đưa ra một sự ưu tiên rõ ràng. Khi bạn tổng hợp các phán đoán này trên nhiều mẫu, bạn sẽ nhận được các chỉ số như tỷ lệ thắng và khoảng tin cậy. Phương pháp này sử dụng khả năng lý luận của chính mô hình để đánh giá các phẩm chất như sự liên quan và độ rõ ràng một cách trực tiếp và nhất quán.</p><ul><li>Mô hình giám khảo này nhằm cung cấp các ưu tiên tổng thể chung có độ trễ thấp trong các tình huống mà phản hồi chi tiết không cần thiết</li><li>Kết quả đầu ra của mô hình này là một trong hai [[A>B]] hoặc [[B>A]]</li><li>Các trường hợp sử dụng cho mô hình này chủ yếu là những trường hợp yêu cầu các ưu tiên cặp đôi chung, tự động và có độ trễ thấp, chẳng hạn như chấm điểm tự động để lựa chọn điểm kiểm tra (checkpoint) trong các quy trình huấn luyện</li></ul><h3 id=tìm-hiểu-các-chỉ-số-đánh-giá-của-amazon-nova-llm-as-a-judge><strong>Tìm hiểu các chỉ số đánh giá của Amazon Nova LLM-as-a-Judge</strong></h3><p>Khi sử dụng khung Amazon Nova LLM-as-a-Judge để so sánh các kết quả đầu ra từ hai mô hình ngôn ngữ, SageMaker AI tạo ra một bộ toàn diện các chỉ số định lượng. Bạn có thể sử dụng các chỉ số này để đánh giá mô hình nào hoạt động tốt hơn và độ tin cậy của việc đánh giá. Kết quả được chia thành ba loại chính: <strong>các chỉ số ưu tiên cốt lõi, các chỉ số tin cậy thống kê, và các chỉ số sai số chuẩn.</strong></p><p>Các <strong>chỉ số ưu tiên cốt lõi</strong> báo cáo tần suất kết quả đầu ra của mỗi mô hình được mô hình giám khảo ưa thích. Chỉ số a_scores đếm số lượng ví dụ mà Mô hình A được ưu tiên, và b_scores đếm các trường hợp Mô hình B được chọn là tốt hơn. Chỉ số ties ghi lại các trường hợp mà mô hình giám khảo đánh giá cả hai phản hồi đều bằng nhau hoặc không thể xác định một sự ưu tiên rõ ràng. Chỉ số inference_error đếm các trường hợp mà giám khảo không thể tạo ra một phán đoán hợp lệ do dữ liệu bị định dạng sai hoặc lỗi nội bộ.</p><p>Các <strong>chỉ số tin cậy</strong> thống kê định lượng khả năng các ưu tiên quan sát được phản ánh sự khác biệt thực sự về chất lượng mô hình thay vì biến thiên ngẫu nhiên. Chỉ số winrate báo cáo tỷ lệ trên tất cả các so sánh hợp lệ mà trong đó Mô hình B được ưa thích. lower_rate và upper_rate xác định các giới hạn dưới và trên của khoảng tin cậy 95% cho tỷ lệ thắng này. Ví dụ, một winrate là 0.75 với khoảng tin cậy từ 0.60 đến 0.85 cho thấy rằng, ngay cả khi tính đến sự không chắc chắn, Mô hình B vẫn được ưa thích hơn Mô hình A một cách nhất quán. Trường score thường khớp với số lần thắng của Mô hình B nhưng cũng có thể được tùy chỉnh cho các chiến lược đánh giá phức tạp hơn.</p><p>Các <strong>chỉ số sai số chuẩn</strong> cung cấp một ước tính về sự không chắc chắn thống kê trong mỗi lần đếm. Chúng bao gồm a_scores_stderr, b_scores_stderr, ties_stderr, inference_error_stderr, và score_stderr. Các giá trị sai số chuẩn nhỏ hơn cho thấy kết quả đáng tin cậy hơn. Các giá trị lớn hơn có thể chỉ ra sự cần thiết phải có thêm dữ liệu đánh giá hoặc kỹ thuật câu lệnh nhất quán hơn.</p><p>Việc diễn giải các chỉ số này đòi hỏi sự chú ý đến cả các ưu tiên quan sát được và các khoảng tin cậy:</p><ul><li>Nếu winrate cao hơn đáng kể so với 0.5 và khoảng tin cậy không bao gồm 0.5, thì Mô hình B được ưu tiên hơn về mặt thống kê so với Mô hình A.</li><li>Ngược lại, nếu winrate thấp hơn 0.5 và khoảng tin cậy hoàn toàn nằm dưới 0.5, thì Mô hình A được ưa thích hơn.</li><li>Khi khoảng tin cậy chồng lấp với 0.5, kết quả là không có kết luận và nên tiến hành đánh giá thêm.</li><li>Các giá trị cao trong inference_error hoặc sai số chuẩn lớn cho thấy có thể đã có vấn đề trong quá trình đánh giá, chẳng hạn như sự không nhất quán trong định dạng câu lệnh hoặc kích thước mẫu không đủ.</li></ul><p>Sau đây là một ví dụ về kết quả chỉ số từ một lần chạy đánh giá:</p><p>{<br>&ldquo;a_scores&rdquo;: 16.0,<br>&ldquo;a_scores_stderr&rdquo;: 0.03,<br>&ldquo;b_scores&rdquo;: 10.0,<br>&ldquo;b_scores_stderr&rdquo;: 0.09,<br>&ldquo;ties&rdquo;: 0.0,<br>&ldquo;ties_stderr&rdquo;: 0.0,<br>&ldquo;inference_error&rdquo;: 0.0,<br>&ldquo;inference_error_stderr&rdquo;: 0.0,<br>&ldquo;score&rdquo;: 10.0,<br>&ldquo;score_stderr&rdquo;: 0.09,<br>&ldquo;winrate&rdquo;: 0.38,<br>&ldquo;lower_rate&rdquo;: 0.23,<br>&ldquo;upper_rate&rdquo;: 0.56<br>}</p><p>Trong ví dụ này, Mô hình A được ưa thích 16 lần, Mô hình B được ưa thích 10 lần, và không có trường hợp hòa hoặc lỗi suy luận nào. Tỷ lệ thắng 0.38 cho thấy Mô hình B được ưa thích trong 38% các trường hợp, với khoảng tin cậy 95% dao động từ 23% đến 56%. Vì khoảng này bao gồm 0.5, kết quả này cho thấy việc đánh giá không có kết luận, và có thể cần thêm dữ liệu để làm rõ mô hình nào hoạt động tốt hơn về tổng thể.</p><p>Các chỉ số này, được tạo tự động như một phần của quá trình đánh giá, cung cấp một nền tảng thống kê nghiêm ngặt để so sánh các mô hình và đưa ra các quyết định dựa trên dữ liệu về việc triển khai mô hình nào.</p><h3 id=tổng-quan-về-giải-pháp><strong>Tổng quan về giải pháp</strong></h3><p>Giải pháp này trình bày cách đánh giá các mô hình AI tạo sinh trên <strong>Amazon SageMaker AI</strong> bằng cách sử dụng <strong>khả năng Nova LLM-as-a-Judge</strong>. Mã Python được cung cấp sẽ hướng dẫn bạn qua toàn bộ quy trình công việc.</p><p>Đầu tiên, nó chuẩn bị một bộ dữ liệu bằng cách lấy mẫu các câu hỏi từ SQuAD và tạo ra các phản hồi ứng viên từ Qwen2.5 và <strong>Claude 3.7</strong> của Anthropic. Những kết quả đầu ra này được lưu trong một tệp JSONL chứa câu lệnh và cả hai phản hồi.</p><p>Chúng tôi đã truy cập <strong>Claude 3.7 Sonnet</strong> của Anthropic trong <strong>Amazon Bedrock</strong> bằng client bedrock-runtime. Chúng tôi đã truy cập <strong>Qwen2.5 1.5B</strong> bằng một <strong>điểm cuối</strong> (endpoint) <strong>Hugging Face được lưu trữ trên SageMaker</strong>.</p><p>Tiếp theo, một <strong>Trình ước tính PyTorch</strong> (PyTorch Estimator) khởi chạy một công việc đánh giá bằng cách sử dụng một công thức Amazon Nova LLM-as-a-Judge. Công việc này chạy trên các phiên bản GPU như ml.g5.12xlarge và tạo ra các chỉ số đánh giá, bao gồm tỷ lệ thắng, khoảng tin cậy, và số lần ưu tiên. Kết quả được lưu vào Amazon S3 để phân tích.</p><p>Cuối cùng, một hàm trực quan hóa sẽ hiển thị các biểu đồ và bảng, tóm tắt mô hình nào được ưa thích hơn, mức độ ưu tiên mạnh như thế nào, và độ tin cậy của các ước tính. Thông qua phương pháp từ đầu đến cuối này, bạn có thể đánh giá các cải tiến, theo dõi các sự suy giảm hiệu suất, và đưa ra các quyết định dựa trên dữ liệu về việc triển khai các mô hình tạo sinh—tất cả mà không cần gán nhãn thủ công.</p><h3 id=các-điều-kiện-tiên-quyết><strong>Các điều kiện tiên quyết</strong></h3><p>Bạn cần hoàn thành các điều kiện tiên quyết sau đây trước khi có thể chạy sổ tay:</p><ol><li>Thực hiện các yêu cầu tăng hạn ngạch sau đây cho SageMaker AI. Đối với trường hợp sử dụng này, bạn cần yêu cầu tối thiểu 1 phiên bản g5.12xlarge. Trên bảng điều khiển <a href=https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html>Service Quotas</a>, hãy yêu cầu các hạn ngạch SageMaker AI sau, 1 phiên bản G5 (g5.12xlarge) để sử dụng cho công việc huấn luyện</li><li>(Tùy chọn) Bạn có thể tạo một miền <a href=https://aws.amazon.com/sagemaker-ai/studio/>Amazon SageMaker Studio</a> (tham khảo <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-quick-start.html>Sử dụng thiết lập nhanh cho Amazon SageMaker AI</a>) để truy cập các <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-jl-user-guide.html>sổ tay Jupyter</a> với vai trò nói trên. (Bạn cũng có thể sử dụng JupyterLab trong môi trường cục bộ của mình.)</li></ol><ul><li><p>Tạo một <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html#:~:text=the%20following%20procedures.-%5B%E2%80%A6%5Dxecution%20role,-Use%20the%20following%20%5C%28">vai trò</a> <a href=https://aws.amazon.com/iam/>AWS Identity and Access Management</a> (IAM) với các chính sách được quản lý là AmazonSageMakerFullAccess, AmazonS3FullAccess, và AmazonBedrockFullAccess để cấp quyền truy cập cần thiết cho SageMaker AI và Amazon Bedrock để chạy các ví dụ.</p></li><li><p>Gán <a href=https://docs.aws.amazon.com/directoryservice/latest/admin-guide/edit_trust.html>mối quan hệ tin cậy</a> sau đây cho vai trò IAM của bạn:</p><pre><code>{
</code></pre><p>&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,<br>&ldquo;Statement&rdquo;: [<br>{<br>&ldquo;Sid&rdquo;: &ldquo;&rdquo;,<br>&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,<br>&ldquo;Principal&rdquo;: {<br>&ldquo;Service&rdquo;: [<br>&ldquo;bedrock.amazonaws.com&rdquo;,<br>&ldquo;sagemaker.amazonaws.com&rdquo;<br>]<br>},<br>&ldquo;Action&rdquo;: &ldquo;sts:AssumeRole&rdquo;<br>}<br>]<br>}</p></li></ul><ol start=3><li>Sao chép (Clone) kho lưu trữ GitHub với các tài sản cho việc triển khai này. Kho lưu trữ này bao gồm một sổ tay tham chiếu đến các tài sản huấn luyện:</li></ol><p>git clone <a href=https://github.com/aws-samples/amazon-nova-samples.git>https://github.com/aws-samples/amazon-nova-samples.git</a><br>cd customization/SageMakerTrainingJobs/Amazon-Nova-LLM-As-A-Judge/<br>4. Tiếp theo, chạy sổ tay Nova Amazon-Nova-LLM-as-a-Judge-Sagemaker-AI.ipynb để bắt đầu sử dụng việc triển khai Amazon Nova LLM-as-a-Judge trên Amazon SageMaker AI.</p><h3 id=thiết-lập-mô-hình><strong>Thiết lập mô hình</strong></h3><p>Để tiến hành một cuộc đánh giá Amazon Nova LLM-as-a-Judge, bạn cần tạo ra các kết quả đầu ra từ các mô hình ứng viên mà bạn muốn so sánh. Trong dự án này, chúng tôi đã sử dụng hai phương pháp khác nhau: triển khai mô hình Qwen2.5 1.5B trên Amazon SageMaker và gọi mô hình Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock. Đầu tiên, chúng tôi đã triển khai Qwen2.5 1.5B, một mô hình ngôn ngữ đa ngôn ngữ có trọng số mở, trên một điểm cuối (endpoint) SageMaker chuyên dụng. Điều này được thực hiện bằng cách sử dụng giao diện triển khai HuggingFaceModel. Để triển khai mô hình Qwen2.5 1.5B, chúng tôi đã cung cấp một tập lệnh tiện lợi để bạn gọi: python3 deploy_sm_model.py</p><p>Khi đã được triển khai, việc suy luận có thể được thực hiện bằng một hàm trợ giúp bao bọc API dự đoán của SageMaker:</p><p># Khởi tạo predictor một lần<br>predictor = HuggingFacePredictor(endpoint_name=&ldquo;qwen25-&lt;endpoint_name_here>&rdquo;)<br>def generate_with_qwen25(prompt: str, max_tokens: int = 500, temperature: float = 0.9) -> str:<br>"""<br>Gửi một câu lệnh đến mô hình Qwen2.5 đã triển khai trên SageMaker và trả về phản hồi được tạo ra.<br>Args:<br>prompt (str): Câu lệnh/câu hỏi đầu vào để gửi đến mô hình.<br>max_tokens (int): Số lượng token tối đa để tạo ra.<br>temperature (float): Nhiệt độ lấy mẫu cho việc tạo ra.<br>Returns:<br>str: Văn bản do mô hình tạo ra.<br>"""<br>response = predictor.predict({<br>&ldquo;inputs&rdquo;: prompt,<br>&ldquo;parameters&rdquo;: {<br>&ldquo;max_new_tokens&rdquo;: max_tokens,<br>&ldquo;temperature&rdquo;: temperature<br>}<br>})<br>return response[0][&ldquo;generated_text&rdquo;]<br>answer = generate_with_qwen25(&ldquo;What is the Grotto at Notre Dame?&rdquo;)<br>print(answer)</p><p>Song song đó, chúng tôi đã tích hợp mô hình Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock. Amazon Bedrock cung cấp một lớp API được quản lý để truy cập các <a href=https://aws.amazon.com/what-is/foundation-models/>mô hình nền tảng</a> (FM) độc quyền mà không cần quản lý cơ sở hạ tầng. Hàm tạo của Claude đã sử dụng client bedrock-runtime của <a href=https://aws.amazon.com/sdk-for-python/>AWS SDK for Python</a> (Boto3), nhận một câu lệnh từ người dùng và trả về phần hoàn thành văn bản của mô hình:</p><p># Khởi tạo client Bedrock một lần<br>bedrock = boto3.client(&ldquo;bedrock-runtime&rdquo;, region_name=&ldquo;us-east-1&rdquo;)<br># ID mô hình (Claude 3.7 Sonnet) thông qua Bedrock<br>MODEL_ID = &ldquo;us.anthropic.claude-3-7-sonnet-20250219-v1:0&rdquo;<br>def generate_with_claude4(prompt: str, max_tokens: int = 512, temperature: float = 0.7, top_p: float = 0.9) -> str:<br>"""<br>Gửi một câu lệnh đến mô hình Claude 4-tier qua Amazon Bedrock và trả về phản hồi được tạo ra.<br>Args:<br>prompt (str): Tin nhắn người dùng hoặc câu lệnh đầu vào.<br>max_tokens (int): Số lượng token tối đa để tạo ra.<br>temperature (float): Nhiệt độ lấy mẫu cho việc tạo ra.<br>top_p (float): Lấy mẫu hạt nhân top-p.<br>Returns:<br>str: Nội dung văn bản do Claude tạo ra.<br>"""<br>payload = {<br>&ldquo;anthropic_version&rdquo;: &ldquo;bedrock-2023-05-31&rdquo;,<br>&ldquo;messages&rdquo;: [{&ldquo;role&rdquo;: &ldquo;user&rdquo;, &ldquo;content&rdquo;: prompt}],<br>&ldquo;max_tokens&rdquo;: max_tokens,<br>&ldquo;temperature&rdquo;: temperature,<br>&ldquo;top_p&rdquo;: top_p<br>}<br>response = bedrock.invoke_model(<br>modelId=MODEL_ID,<br>body=json.dumps(payload),<br>contentType=&ldquo;application/json&rdquo;,<br>accept=&ldquo;application/json&rdquo;<br>)<br>response_body = json.loads(response[&lsquo;body&rsquo;].read())<br>return response_body[&ldquo;content&rdquo;][0][&ldquo;text&rdquo;]<br>answer = generate_with_claude4(&ldquo;What is the Grotto at Notre Dame?&rdquo;)<br>print(answer)</p><p>Khi bạn đã tạo và kiểm tra cả hai hàm, bạn có thể chuyển sang tạo dữ liệu đánh giá cho Nova LLM-as-a-Judge.</p><h3 id=chuẩn-bị-bộ-dữ-liệu><strong>Chuẩn bị bộ dữ liệu</strong></h3><p>Để tạo một bộ dữ liệu đánh giá thực tế nhằm so sánh các mô hình Qwen và Claude, chúng tôi đã sử dụng Bộ dữ liệu Trả lời câu hỏi Stanford (<strong>SQuAD</strong>), một bộ tiêu chuẩn được áp dụng rộng rãi trong lĩnh vực hiểu ngôn ngữ tự nhiên được phân phối theo giấy phép CC BY-SA 4.0. SQuAD bao gồm hàng ngàn cặp câu hỏi-trả lời được đóng góp từ cộng đồng, bao trùm một loạt các bài viết trên Wikipedia. Bằng cách lấy mẫu từ bộ dữ liệu này, chúng tôi đảm bảo rằng các câu lệnh đánh giá của mình phản ánh các tác vụ trả lời câu hỏi thực tế, chất lượng cao, đại diện cho các ứng dụng trong thế giới thực.</p><p>Chúng tôi bắt đầu bằng cách tải một tập hợp con nhỏ các ví dụ để giữ cho quy trình công việc nhanh chóng và có thể tái tạo. Cụ thể, chúng tôi đã sử dụng thư viện datasets của Hugging Face để tải xuống và tải 20 ví dụ đầu tiên từ phần huấn luyện của SQuAD:</p><p>from datasets import load_dataset<br>squad = load_dataset(&ldquo;squad&rdquo;, split=&ldquo;train[:20]&rdquo;)</p><p>Lệnh này truy xuất một lát cắt của bộ dữ liệu đầy đủ, chứa 20 mục với các trường có cấu trúc bao gồm ngữ cảnh, câu hỏi, và câu trả lời. Để xác minh nội dung và kiểm tra một ví dụ, chúng tôi đã in ra một câu hỏi mẫu và câu trả lời đúng của nó:</p><p>print(squad[3][&ldquo;question&rdquo;])<br>print(squad[3][&ldquo;answers&rdquo;][&ldquo;text&rdquo;][0])</p><p>Đối với bộ đánh giá, chúng tôi đã chọn sáu câu hỏi đầu tiên từ tập hợp con này:</p><p>questions = [squad[i][&ldquo;question&rdquo;] for i in range(6)]</p><h3 id=tạo-bộ-dữ-liệu-đánh-giá-amazon-nova-llm-as-a-judge><strong>Tạo bộ dữ liệu đánh giá Amazon Nova LLM-as-a-Judge</strong></h3><p>Sau khi chuẩn bị một bộ câu hỏi đánh giá từ SQuAD, chúng tôi đã tạo ra các kết quả đầu ra từ cả hai mô hình và tập hợp chúng vào một bộ dữ liệu có cấu trúc để được sử dụng bởi quy trình công việc Amazon Nova LLM-as-a-Judge. Bộ dữ liệu này đóng vai trò là đầu vào cốt lõi cho các công thức đánh giá của SageMaker AI. Để làm điều này, chúng tôi lặp qua từng câu lệnh hỏi và gọi hai hàm tạo đã được xác định trước đó:</p><ul><li>generate_with_qwen25() cho các phần hoàn thành từ mô hình Qwen2.5 được triển khai trên SageMaker</li><li>generate_with_claude() cho các phần hoàn thành từ Claude 3.7 Sonnet của Anthropic trong Amazon Bedrock</li></ul><p>Đối với mỗi câu lệnh, quy trình công việc đã cố gắng tạo ra một phản hồi từ mỗi mô hình. Nếu một lệnh gọi tạo phản hồi thất bại do lỗi API, hết thời gian chờ, hoặc vấn đề khác, hệ thống đã bắt ngoại lệ và lưu trữ một thông báo lỗi rõ ràng cho biết sự thất bại. Điều này đảm bảo rằng quá trình đánh giá có thể tiến hành một cách trơn tru ngay cả khi có lỗi tạm thời:</p><p>import json<br>output_path = &ldquo;llm_judge.jsonl&rdquo;<br>with open(output_path, &ldquo;w&rdquo;) as f:<br>for q in questions:<br>try:<br>response_a = generate_with_qwen25(q)<br>except Exception as e:<br>response_a = f"[Qwen2.5 generation failed: {e}]"</p><pre><code>    try:  
        response\_b \= generate\_with\_claude4(q)  
    except Exception as e:  
        response\_b \= f&quot;\[Claude 3.7 generation failed: {e}\]&quot;  
    row \= {  
        &quot;prompt&quot;: q,  
        &quot;response\_A&quot;: response\_a,  
        &quot;response\_B&quot;: response\_b  
    }  
    f.write(json.dumps(row) \+ &quot;\\n&quot;)  
</code></pre><p>print(f"JSONL file created at: {output_path}")</p><p>Quy trình công việc này đã tạo ra một tệp JSON Lines có tên là llm_judge.jsonl. Mỗi dòng chứa một bản ghi đánh giá duy nhất được cấu trúc như sau:</p><p>{<br>&ldquo;prompt&rdquo;: &ldquo;What is the capital of France?&rdquo;,<br>&ldquo;response_A&rdquo;: &ldquo;The capital of France is Paris.&rdquo;,<br>&ldquo;response_B&rdquo;: &ldquo;Paris is the capital city of France.&rdquo;<br>}</p><p>Sau đó, tải tệp llm_judge.jsonl này lên một bucket S3 mà bạn đã xác định trước:</p><p>upload_to_s3(<br>&ldquo;llm_judge.jsonl&rdquo;,<br>&ldquo;s3://&lt;YOUR_BUCKET_NAME>/datasets/byo-datasets-dev/custom-llm-judge/llm_judge.jsonl&rdquo;<br>)</p><h3 id=khởi-chạy-công-việc-đánh-giá-nova-llm-as-a-judge><strong>Khởi chạy công việc đánh giá Nova LLM-as-a-Judge</strong></h3><p>Sau khi chuẩn bị bộ dữ liệu và tạo công thức đánh giá, bước cuối cùng là khởi chạy công việc huấn luyện SageMaker thực hiện việc đánh giá Amazon Nova LLM-as-a-Judge. Trong quy trình công việc này, công việc huấn luyện hoạt động như một quy trình tự khép kín, được quản lý toàn phần, tải mô hình, xử lý bộ dữ liệu, và tạo ra các chỉ số đánh giá tại vị trí Amazon S3 được chỉ định của bạn.</p><p>Chúng tôi sử dụng lớp trình ước tính PyTorch từ SageMaker Python SDK để đóng gói cấu hình cho lần chạy đánh giá. Trình ước tính xác định các tài nguyên tính toán, hình ảnh container, công thức đánh giá, và các đường dẫn đầu ra để lưu trữ kết quả:</p><p>estimator = PyTorch(<br>output_path=output_s3_uri,<br>base_job_name=job_name,<br>role=role,<br>instance_type=instance_type,<br>training_recipe=recipe_path,<br>sagemaker_session=sagemaker_session,<br>image_uri=image_uri,<br>disable_profiler=True,<br>debugger_hook_config=False,<br>)</p><p>Khi trình ước tính được cấu hình, bạn khởi tạo công việc đánh giá bằng phương thức fit(). Lệnh gọi này gửi công việc đến mặt phẳng điều khiển của SageMaker, cung cấp cụm máy tính, và bắt đầu xử lý bộ dữ liệu đánh giá:</p><p>estimator.fit(inputs={&ldquo;train&rdquo;: evalInput})</p><h3 id=kết-quả-từ-công-việc-đánh-giá-amazon-nova-llm-as-a-judge><strong>Kết quả từ công việc đánh giá Amazon Nova LLM-as-a-Judge</strong></h3><p>Đồ họa sau đây minh họa kết quả của công việc đánh giá Amazon Nova LLM-as-a-Judge.</p><p><img src=#ZgotmplZ alt></p><p>Để giúp các chuyên gia nhanh chóng diễn giải kết quả của một cuộc đánh giá Nova LLM-as-a-Judge, chúng tôi đã tạo ra một <strong>hàm tiện ích</strong> sản xuất một hình ảnh trực quan duy nhất, toàn diện, tóm tắt các chỉ số chính. Hàm này, plot_nova_judge_results, sử dụng Matplotlib và Seaborn để hiển thị một hình ảnh với sáu bảng, mỗi bảng làm nổi bật một khía cạnh khác nhau của kết quả đánh giá.</p><p>Hàm này nhận vào từ điển chỉ số đánh giá—được tạo ra khi công việc đánh giá hoàn tất—và tạo ra các thành phần trực quan sau:</p><ul><li><strong>Biểu đồ cột phân phối điểm</strong> – Cho thấy Mô hình A được ưa thích bao nhiêu lần, Mô hình B được ưa thích bao nhiêu lần, có bao nhiêu trường hợp hòa, và tần suất giám khảo không đưa ra được quyết định (lỗi suy luận). Điều này cung cấp một cảm nhận tức thì về mức độ quyết đoán của cuộc đánh giá và liệu có mô hình nào đang chiếm ưu thế hay không.</li><li><strong>Tỷ lệ thắng với khoảng tin cậy 95%</strong> – Vẽ biểu đồ tỷ lệ thắng tổng thể của Mô hình B so với Mô hình A, bao gồm một thanh lỗi phản ánh các giới hạn dưới và trên của khoảng tin cậy 95%. Một đường tham chiếu dọc tại 50% đánh dấu điểm không có sự ưu tiên. Nếu khoảng tin cậy không cắt qua đường này, bạn có thể kết luận rằng kết quả có ý nghĩa thống kê.</li><li><strong>Biểu đồ tròn về sở thích</strong> – Hiển thị trực quan tỷ lệ số lần Mô hình A, Mô hình B, hoặc không mô hình nào được ưa thích. Điều này giúp nhanh chóng hiểu được sự phân phối ưu tiên trong số các phán đoán hợp lệ.</li><li><strong>Biểu đồ cột so sánh điểm số của A và B</strong> – So sánh số lượng ưu tiên thô cho mỗi mô hình cạnh nhau. Một nhãn rõ ràng chú thích biên độ chênh lệch để nhấn mạnh mô hình nào có nhiều chiến thắng hơn.</li><li><strong>Đồng hồ đo tỷ lệ thắng</strong> – Mô tả tỷ lệ thắng dưới dạng một đồng hồ đo hình bán nguyệt với một kim chỉ vào hiệu suất của Mô hình B so với phạm vi lý thuyết 0–100%. Hình ảnh trực quan này giúp các bên liên quan không chuyên về kỹ thuật hiểu được tỷ lệ thắng trong nháy mắt.</li><li><strong>Bảng thống kê tóm tắt</strong> – Tổng hợp các chỉ số số học—bao gồm tổng số lần đánh giá, số lỗi, tỷ lệ thắng, và khoảng tin cậy—vào một bảng nhỏ gọn, sạch sẽ. Điều này giúp dễ dàng tham chiếu các giá trị số chính xác đằng sau các biểu đồ.</li></ul><p>Vì hàm này xuất ra một hình ảnh Matplotlib tiêu chuẩn, bạn có thể nhanh chóng lưu hình ảnh, hiển thị nó trong các sổ tay Jupyter, hoặc nhúng nó vào các tài liệu khác.</p><h3 id=dọn-dẹp><strong>Dọn dẹp</strong></h3><p>Hoàn thành các bước sau để dọn dẹp tài nguyên của bạn:</p><ol><li><p>Xóa Điểm cuối (Endpoint) Qwen 2.5 1.5B của bạn</p><p>import boto3</p></li></ol><p># Tạo một client dịch vụ SageMaker cấp thấp.</p><p>sagemaker_client = boto3.client(&lsquo;sagemaker&rsquo;, region_name=&lt;region>)</p><p># Xóa điểm cuối</p><p>sagemaker_client.delete_endpoint(EndpointName=endpoint_name)</p><ol start=2><li>Nếu bạn đang sử dụng một sổ tay JupyterLab của SageMaker Studio, hãy tắt phiên bản sổ tay JupyterLab.</li></ol><h3 id=làm-thế-nào-bạn-có-thể-sử-dụng-khung-đánh-giá-này><strong>Làm thế nào bạn có thể sử dụng khung đánh giá này</strong></h3><p>Quy trình công việc Amazon Nova LLM-as-a-Judge cung cấp một cách thức <strong>đáng tin cậy, có thể lặp lại</strong> để so sánh hai mô hình ngôn ngữ trên dữ liệu của riêng bạn. Bạn có thể tích hợp điều này vào các quy trình lựa chọn mô hình để quyết định phiên bản nào hoạt động tốt nhất, hoặc bạn có thể lên lịch nó như một phần của việc đánh giá liên tục để phát hiện sự suy giảm hiệu suất theo thời gian.</p><p>Đối với các đội ngũ xây dựng các hệ thống có tính tác tử hoặc chuyên biệt theo lĩnh vực, phương pháp này cung cấp cái nhìn sâu sắc hơn so với chỉ riêng các chỉ số tự động. Bởi vì toàn bộ quy trình chạy trên các công việc huấn luyện của SageMaker, nó có thể mở rộng nhanh chóng và tạo ra các báo cáo trực quan rõ ràng có thể được chia sẻ với các bên liên quan.</p><h3 id=kết-luận><strong>Kết luận</strong></h3><p>Bài đăng này trình bày cách <strong>Nova LLM-as-a-Judge</strong>—một mô hình đánh giá chuyên biệt có sẵn thông qua <strong>Amazon SageMaker AI</strong>—có thể được sử dụng để đo lường một cách có hệ thống hiệu suất tương đối của các hệ thống AI tạo sinh. Hướng dẫn này chỉ ra cách chuẩn bị các bộ dữ liệu đánh giá, khởi chạy các công việc huấn luyện SageMaker AI với các công thức Nova LLM-as-a-Judge, và diễn giải các chỉ số kết quả, bao gồm tỷ lệ thắng và phân phối ưu tiên. Giải pháp SageMaker AI được quản lý toàn phần giúp đơn giản hóa quy trình này, để bạn có thể chạy các cuộc đánh giá mô hình có thể mở rộng, lặp lại và phù hợp với sở thích của con người.</p><p>Chúng tôi khuyến nghị bạn bắt đầu hành trình đánh giá LLM của mình bằng cách khám phá <a href=https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html>tài liệu và các ví dụ chính thức của Amazon Nova</a>. Cộng đồng AWS AI/ML cung cấp các tài nguyên phong phú, bao gồm các hội thảo và hướng dẫn kỹ thuật, để hỗ trợ hành trình triển khai của bạn.</p><p>Để tìm hiểu thêm, hãy truy cập:</p><ul><li><a href=https://docs.aws.amazon.com/nova/>Tài liệu Amazon Nova</a></li><li><a href=https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-nova-mm.html>Tổng quan về Amazon Bedrock Nova</a></li><li><a href=https://docs.aws.amazon.com/nova/latest/userguide/customize-fine-tune.html>Tinh chỉnh các mô hình Amazon Nova</a></li><li><a href=https://docs.aws.amazon.com/nova/latest/userguide/customization.html>Hướng dẫn tùy chỉnh Amazon Nova</a></li></ul><h3 id=về-các-tác-giả><strong>Về các tác giả</strong></h3><p><img src=#ZgotmplZ alt><br><strong>Surya Kari</strong> là một Nhà khoa học dữ liệu AI tạo sinh cấp cao tại AWS, chuyên phát triển các giải pháp tận dụng các mô hình nền tảng tiên tiến. Anh có kinh nghiệm sâu rộng làm việc với các mô hình ngôn ngữ tiên tiến bao gồm DeepSeek-R1, họ Llama, và Qwen, tập trung vào việc tinh chỉnh và tối ưu hóa chúng. Chuyên môn của anh mở rộng đến việc triển khai các quy trình huấn luyện hiệu quả và các chiến lược triển khai bằng AWS SageMaker. Anh hợp tác với khách hàng để thiết kế và triển khai các giải pháp AI tạo sinh, giúp họ điều hướng việc lựa chọn mô hình, các phương pháp tinh chỉnh, và các chiến lược triển khai để đạt được hiệu suất tối ưu cho các trường hợp sử dụng cụ thể của họ.</p><p><strong><img src=#ZgotmplZ alt></strong></p><p><strong>Joel Carlson</strong> là một Nhà khoa học ứng dụng cấp cao trong đội ngũ mô hình hóa nền tảng Amazon AGI. Anh chủ yếu làm việc về việc phát triển các phương pháp mới để cải thiện khả năng LLM-as-a-Judge của họ mô hình Nova.</p><p><strong><img src=#ZgotmplZ alt></strong></p><p><strong>Saurabh Sahu</strong> là một nhà khoa học ứng dụng trong đội ngũ mô hình hóa Nền tảng Amazon AGI. Anh nhận bằng Tiến sĩ Kỹ thuật Điện từ Đại học Maryland College Park vào năm 2019. Anh có nền tảng về học máy đa phương thức, làm việc về nhận dạng giọng nói, phân tích tình cảm và hiểu âm thanh/video. Hiện tại, công việc của anh tập trung vào việc phát triển các công thức để cải thiện hiệu suất của các mô hình LLM-as-a-judge cho các tác vụ khác nhau.</p><p><strong><img src=#ZgotmplZ alt></strong></p><p><strong>Morteza Ziyadi</strong> là một Quản lý Khoa học Ứng dụng tại Amazon AGI, nơi anh lãnh đạo nhiều dự án về các công thức sau huấn luyện và các mô hình ngôn ngữ lớn (Đa phương thức) trong đội ngũ mô hình hóa Nền tảng Amazon AGI. Trước khi gia nhập Amazon AGI, anh đã có bốn năm làm việc tại Microsoft Cloud và AI, nơi anh lãnh đạo các dự án tập trung vào việc phát triển các mô hình tạo mã từ ngôn ngữ tự nhiên cho các sản phẩm khác nhau. Anh cũng đã từng là giảng viên thỉnh giảng tại Đại học Northeastern. Anh nhận bằng Tiến sĩ từ Đại học Nam California (USC) vào năm 2017 và từ đó đã tích cực tham gia với tư cách là người tổ chức hội thảo và người phản biện cho nhiều hội nghị NLP, Thị giác máy tính và học máy.</p><p><strong><img src=#ZgotmplZ alt></strong></p><p><strong>Pradeep Natarajan</strong> là một Nhà khoa học chính cấp cao trong đội ngũ mô hình hóa Nền tảng Amazon AGI, làm việc về các công thức sau huấn luyện và các mô hình ngôn ngữ lớn Đa phương thức. Anh có hơn 20 năm kinh nghiệm trong việc phát triển và ra mắt nhiều hệ thống học máy quy mô lớn. Anh có bằng Tiến sĩ Khoa học Máy tính từ Đại học Nam California.</p><p><strong><img src=#ZgotmplZ alt></strong></p><p><strong>Michael Cai</strong> là một Kỹ sư phần mềm trong Đội ngũ Tùy chỉnh Amazon AGI, hỗ trợ việc phát triển các giải pháp đánh giá. Anh nhận bằng Thạc sĩ Khoa học Máy tính từ Đại học New York vào năm 2024. Trong thời gian rảnh, anh thích in 3D và khám phá công nghệ đổi mới.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=/fcj-worklog/3-blogstranslated/3.1-blog1/ title="Blog 1"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=/fcj-worklog/3-blogstranslated/3.3-blog3/ title="Blog 3" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1e3px;overflow:scroll;position:absolute;top:-1e3px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=/fcj-worklog/js/clipboard.min.js?1765298327></script><script src=/fcj-worklog/js/perfect-scrollbar.min.js?1765298327></script><script src=/fcj-worklog/js/perfect-scrollbar.jquery.min.js?1765298327></script><script src=/fcj-worklog/js/jquery.sticky.js?1765298327></script><script src=/fcj-worklog/js/featherlight.min.js?1765298327></script><script src=/fcj-worklog/js/highlight.pack.js?1765298327></script><script>hljs.initHighlightingOnLoad()</script><script src=/fcj-worklog/js/modernizr.custom-3.6.0.js?1765298327></script><script src=/fcj-worklog/js/learn.js?1765298327></script><script src=/fcj-worklog/js/hugo-learn.js?1765298327></script><link href=/fcj-worklog/mermaid/mermaid.css?1765298327 rel=stylesheet><script src=/fcj-worklog/mermaid/mermaid.js?1765298327></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>